[["index.html", "Multivariable and vector calculus Preface", " Multivariable and vector calculus Preface Multivariable and vector calculus forms the underpinnings of almost all applications of mathematics. It is the driving force for research in both pure and applied mathematics, as well as biology, chemistry, computer graphics, economics, engineering, physics, statistics and psychology. As its name suggests, multivariable and vector calculus is the extension of single variable calculus to more than one variable. That is, in single variable calculus we study functions of a single independent variable, for instance, \\[\\begin{align*} y = f(x). \\end{align*}\\] In multivariable calculus we study functions of two or more independent variables, such as \\[\\begin{align*} z=f(x, y) \\quad \\text{or} \\quad w=f(x, y, z). \\end{align*}\\] These functions are not only interesting in their own right, but they are also essential for describing the physical world. Indeed, many real world complex structures are modelled by functions of more than one independent variable: In thermodynamics, pressure depends on volume and temperature. In electricity and magnetism, the magnetic and electric fields are functions of the three space variables \\((x,y,z)\\) and one time variable \\(t\\). In economics, functions can depend on a large number of independent variables, for example, a manufacturer’s cost might depend on the prices of 42 different commodities. In modelling fluid or heat flow, the velocity field depends on position and time. Single variable calculus is a highly geometric subject and multivariable calculus is the same, maybe even more so. In single variable calculus we study graphs of functions \\(y=f(x)\\) and learn to relate derivatives and integrals to these graphs. Here, we will also study graphs, but of functions of several variables, and relate them to derivatives and integrals. One key difference is that more variables means more geometric dimensions. This makes visualisation of graphs harder, but more rewarding and beneficial. In single variable calculus the Fundamental Theorem of Calculus is a central result and relates derivatives to integrals. We will see something similar in multivariable calculus and the capstone to these notes are three fundamental theorems (Green’s, Stokes’ and Gauss’) that do this. At the end of each chapter there is a section containing a selection of practice problems to help aid and guide your understanding. For further practice problem and reading, there are many wonderful and beautiful texts on multivariable and vector calculus, for instance, James Stewart (2015), Earl W. Swokowski et al. (1994) and Maurice D. Weir and Joel Hass (2009). A word of warning: The best web browser to view this site on is a Chromium or WebKit based browser (such as Google Chrome, Microsoft Edge, Opera or Safari), as these seem to render the mathematical equations in a font fitting with the surrounding text. One can read the content of this site perfectly well with other web browsers (such as Firefox and Internet Explorer), but sometimes the mathematical formulas may not appear in the same font setting as the surrounding text. Acknowledgements: This manuscript is written in R Markdown, with the typesetting receiving influenced from Yihui Xie (2016). The mathematical content is based of lecture notes from California Polytechnic State University by Prof. E. P. J. Pearse, the University of Birmingham by Prof. C. Good, Prof. C. Hoffman and Dr. D. O. E. Silva, and the University of St Andrews by Dr. J. M. Fraser. They have also been inspired by James Stewart (2015), Earl W. Swokowski et al. (1994) and Maurice D. Weir and Joel Hass (2009). References "],["intro.html", "Chapter 1 Foundations (Prerequisites)", " Chapter 1 Foundations (Prerequisites) This chapter briefly recalls some of the basic mathematical ideas and notation that will be used throughout these notes. It is by no means complete and is designed to give you a rough guide as to what knowledge you should have before reading these notes. Primarily this section covers topics usually discussed in calculus and pre‑calculus. We begin with a recollection of standard mathematical symbols. We recall essential ideas from vector geometry and the notion of a function, followed by a recap on differentiation and integration, including how to determine and classify critical points. This is followed by on overview of parametric curves. Our penultimate section discusses fundamental aspects of sequences and series leading to a recap on series expansions of functions. This section is presented without proofs. However, justifications of all statements can be found in James Stewart (2015), Earl W. Swokowski et al. (1994) and Maurice D. Weir and Joel Hass (2009). References "],["symbolsandsets.html", "1.1 Mathematical symbols and sets", " 1.1 Mathematical symbols and sets Below is a list of commonly used mathematical symbols. Symbol Definition \\(\\mathbb{N}\\) the set of natural numbers \\(\\mathbb{N}_{0}\\) the set of non‑negative integers \\(\\mathbb{Z}\\) the set of integers \\(\\mathbb{Q}\\) the set of rational numbers \\(\\mathbb{R}\\) the set of real numbers \\(\\mathbb{R}^+\\) the set of positive real numbers \\(\\mathbb{R}_{0}^+\\) the set of non-negative real numbers \\(\\mathbb{R}^2\\) Euclidean plane \\(\\mathbb{R}^3\\) Euclidean \\(3\\)-space \\(\\sum\\) summation (sigma notation) \\(\\prod\\) product \\(\\in\\) belongs to \\(=\\) equals \\(\\,{\\colon}\\mathrel{\\mkern-5mu}=\\) definition (equals) \\(&lt;\\) less than \\(&gt;\\) greater than \\(\\leq\\) less than or equal to \\(\\geq\\) greater than or equal to \\(\\pm\\) plus or minus \\(\\mp\\) minus or plus \\(\\circ\\) composition (of functions) \\(\\mapsto\\) maps to/goes to \\(\\lvert \\cdot \\rvert\\) absolute value Sets and relations Sets and relations are fundamental to mathematics. We will take a set to be a collection of objects which we term the members or elements of the set. Generally we use capital letters to denote sets and small letters to denote elements. We write \\(a \\in A\\) to mean that an element \\(a\\) is a member of a set \\(A\\) and \\(a \\not\\in A\\) to mean it is not a member of \\(A\\). We denote the set of points \\(x\\) for which a given condition is true by \\(\\{ x \\, \\colon\\) condition\\(\\}\\), for instance, \\(\\{ x \\in \\mathbb{R} \\, \\colon \\, x^2 &gt; 2 \\}\\) denotes the set of real numbers whose square is strictly greater than two. Often we use the following notation for intervals. Let \\(a\\) and \\(b \\in \\mathbb{R}\\), with \\(a &lt; b\\): the interval \\(\\{x \\in \\mathbb{R} \\, \\colon \\, a \\leq x \\leq b \\}\\) is denoted by \\([a, b]\\) and called the closed interval from \\(a\\) to \\(b\\); the interval \\(\\{ x \\in \\mathbb{R} \\, \\colon \\, a &lt; x &lt; b \\}\\) is denoted by \\((a, b)\\) and called the open interval from \\(a\\) to \\(b\\); the interval \\(\\{ x \\in \\mathbb{R} \\, \\colon \\, a \\leq x &lt; b \\}\\) is denoted by \\([a, b)\\) and called the left‑closed right‑open interval from \\(a\\) to \\(b\\); the interval \\(\\{ x \\in \\mathbb{R} \\, \\colon \\, a &lt; x \\leq b \\}\\) is denoted by \\((a, b]\\) and called the left‑open right‑closed interval from \\(a\\) to \\(b\\). We say that \\(A\\) is a subset of \\(B\\) if every element of \\(A\\) is an element of \\(B\\). Note that \\(2 \\in \\mathbb{Z}\\), but \\(\\{ 2 \\} \\subseteq \\mathbb{Z}\\). Further, if \\(A \\subseteq B\\) and \\(A \\neq B\\), then we say \\(A\\) is a proper subset of \\(B\\). Other essential operations on sets are intersections, unions, set differences, symmetric difference. Intersection \\(A \\cap B \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, x \\in A \\; \\text{and} \\; x \\in B \\}\\) Union \\(A \\cup B \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, x \\in A \\; \\text{or} \\; x \\in B\\}\\) Set difference \\(A \\setminus B \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, x \\in A \\; \\text{and} \\; x \\not\\in B \\}\\) Complement \\(A^{c} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, x \\in U \\; \\text{and} \\; x \\notin U\\}\\), where \\(U\\) is the universal set under consideration Symmetric difference \\(A \\triangle B = (A \\setminus B) \\cup (B \\setminus A)\\) More generally, if we have a collection of sets \\(A_{i}\\), index by another set \\(I\\), we can form their intersection and union: \\[\\begin{align*} \\bigcap_{i \\in I} A_{i} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, x \\in A_{i} \\; \\text{for all} \\; i \\in I \\} \\quad \\text{and} \\quad \\bigcup_{i \\in I} A_{i} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ x \\,\\colon\\, \\text{there exists} \\; i \\in I \\; \\text{such that} \\; x \\in A_{i} \\}. \\end{align*}\\] The Cartesian product \\(A \\times B\\) of two sets \\(A\\) and \\(B\\) is the set of all ordered pairs \\[\\begin{align*} A \\times B \\,{\\colon}\\mathrel{\\mkern-5mu}=\\{ (a, b) \\,\\colon\\, a \\in A \\; \\text{and} \\; b \\in B \\}. \\end{align*}\\] The power set of \\(A\\), written \\(\\mathcal{P}(A)\\), is the set of all subsets of \\(A\\), that is \\(\\mathcal{P}(A) = \\{X \\, \\colon \\, X \\subseteq A \\}\\). Bounds of sets of real numbers and the axiom of completeness Many of the difficulties that are encountered with real numbers stem from the fact that a set of real numbers need not contain a maximum or minimum element. To get around this, we introduce infima and suprema. Definition 1.1 (bounds, suprema and infima) Let \\(X\\) denote a non-empty set of real numbers. We call \\(s \\in \\mathbb{R}\\) an upper bound for \\(X\\) if \\(x \\leq s\\) for all \\(x \\in X\\). Similarly \\(s\\) is a lower bound for \\(X\\) if \\(x \\geq s\\) for all \\(x \\in X\\). A set that has an upper (respectively lower) bound is termed bounded above (respectively below). A set of numbers that has both a lower and an upper bound is called bounded. (Thus, A is bounded if there exists a real number \\(M\\) such that \\(\\lvert x \\rvert \\leq M\\) for all \\(x \\in X\\).) A real number \\(s\\) is called the supremum or least upper bound of \\(X\\), written \\(\\sup(X)\\), if \\(s\\) is an upper bound of \\(X\\) and no real number less than \\(s\\) is an upper bound of \\(X\\). Similarly, a real number \\(s\\) is called the infimum or greatest lower bound of \\(X\\), written \\(\\inf(X)\\), if \\(s\\) is a lower bound bound of \\(X\\) and no real number greater than \\(s\\) is a lower bound of \\(X\\). We think of \\(\\sup(X)\\) and \\(\\inf(X)\\) as the generalised maximum and minimum of the set X, but it is important to realise that \\(\\sup(X)\\) and \\(\\inf(X)\\) need not be members of \\(X\\); but how do we know they exist. It is through the axiom of completeness that we can guarantee their existence. The axiom states that every non‑empty set of real numbers that is bounded above has a supremum. The axiom of completeness is what distinguishes the real numbers from the rational numbers. It is equivalent to asserting the existence of real numbers since we can essentially regard any real number as the supremum of a set of rational numbers. For example, let \\[\\begin{align*} X = \\{ x \\in \\mathbb{Q} \\, \\colon \\, x \\geq 0 \\; \\text{and} \\; x^{2} &lt; 2 \\} \\supseteq \\{ 1, 1.4, 1.41, 1.414, 1.4142, \\dots \\}. \\end{align*}\\] Clearly \\(X\\) is bounded above (by \\(10\\), say) so by the axiom of completeness \\(X\\) has a supremum. It is easy to check that \\((\\sup(X))^{2} = 2\\), and so the axiom guarantees the existence of \\(\\sqrt{2}\\) as a real number, but \\(\\sup(X) \\not\\in \\mathbb{Q}\\) as there is no rational number which when squared yields the value \\(2\\). "],["vcs.html", "1.2 Vectors and coordinate systems", " 1.2 Vectors and coordinate systems Vectors Quantities such as length, area and volume have magnitude only and can be completely understood by a single real number together with an appropriate unit of measurement. Such quantities are called scalar quantities, and the corresponding real number is called a scalar. Other quantities such as such as velocity, acceleration and force, which have both magnitude and direction are often represented by a directional directed line segment, or more formally a vector. Given two points \\(p\\) and \\(q\\) we use the notation \\(\\overrightarrow{pq}\\) to denote the vector with initial point \\(p\\) and terminal point \\(q\\), and indicate the direction of the of the vector by placing an arrow above the two letters. The magnitude of \\(\\overrightarrow{pq}\\) is given by the length of the straight line segment joining \\(p\\) to \\(q\\) and is commonly denoted by \\(\\lvert \\overrightarrow{pq} \\rvert\\). When the initial and terminal points of a vector and not explicitly stated we use boldface letters, such as \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), to denote a vector. In calculus a vector is determined only by its magnitude and direction, and not by it location, and as such, two vectors with the same magnitude and direction are said to be equal. Thus, translating a vector from one location to another, provided neither the magnitude nor direction is changed, does not alter the properties of the vector. If \\(\\mathbf{v}\\) is a given vector in \\(\\mathbb{R}^{2}\\) or \\(\\mathbb{R}^{3}\\), then as discussed above, there are many vectors that \\(\\mathbf{v}\\) is equivalent to. However, there is precisely one vector with initial point the origin which is equivalent to \\(\\mathbf{v}\\). Thus, each vector determines a unique order list of real numbers, \\((v_{1}, v_{2})\\), if \\(\\mathbf{v}\\) is a vector in \\(\\mathbb{R}^{2}\\), and \\((v_{1}, v_{2}, v_{3})\\), if \\(\\mathbf{v}\\) is a vector in \\(\\mathbb{R}^{3}\\). Conversely, every ordered list of real numbers \\((v_{1}, v_{2})\\) or \\((v_{1}, v_{2}, v_{3})\\), determine a vector, namely \\(\\overrightarrow{oa}\\) where \\(o\\) represents the origin and \\(a\\) has the coordinates \\((v_{1}, v_{2})\\) if we are working in \\(\\mathbb{R}^{2}\\), or \\((v_{1}, v_{2}, v_{3})\\) if we are working in \\(\\mathbb{R}^{3}\\). In other words there is a one‑to‑one correspondence between ordered lists of real numbers and vectors. This leads us to the following definition which gives a standard way to represent vectors. Definition 1.2 (vector component form) If \\(u = (u_{1}, u_{2}) \\in \\mathbb{R}^{2}\\), \\(v = (v_{1}, v_{2}, v_{3})\\), \\(\\mathbf{u} = \\overrightarrow{ou}\\) and \\(\\mathbf{v} = \\overrightarrow{ov}\\), then the component forms of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are given by \\(\\langle u_{1}, u_{2} \\rangle\\) and \\(\\langle v_{1}, v_{2}, v_{3} \\rangle\\), respectively. With this notation at hand, we have a convenient way to compute the magnitude of a vector. Namely, if \\(\\mathbf{u} = \\langle u_{1}, u_{2} \\rangle\\) and \\(\\mathbf{v} = \\langle v_{1}, v_{2}, v_{2} \\rangle\\), then \\[\\begin{align*} \\lvert \\mathbf{u} \\rvert = (u_{1}^{2} + u_{2}^{2})^{1/2} \\quad \\text{and} \\quad \\lvert \\mathbf{v} \\rvert = (v_{1}^{2} + v_{2}^{2} + v_{3}^{2})^{1/2}, \\end{align*}\\] We often refer to \\(\\lvert \\mathbf{u} \\rvert\\), and \\(\\lvert \\mathbf{v} \\rvert\\), as the norm of \\(\\mathbf{u}\\), and \\(\\mathbf{v}\\), respectively. Two useful vector operations are vector addition and scalar multiplication. Vector addition Letting \\(\\mathbf{u} = \\langle u_{1}, u_{2} \\rangle\\) and \\(\\mathbf{u} = \\langle u_{1}, u_{2} \\rangle\\) denote two vectors in \\(\\mathbb{R}^{2}\\), we define the sum of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) by \\(\\mathbf{u} + \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle u_{1} + v_{1}, u_{2} + v_{2} \\rangle\\). Similarly, if \\(\\mathbf{p} = \\langle p_{1}, p_{2}, p_{3} \\rangle\\) and \\(\\mathbf{q} = \\langle q_{1}, q_{2}, q_{3} \\rangle\\), then the sum of \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) is defined by \\(\\mathbf{p} + \\mathbf{q} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle p_{1} + q_{1}, p_{2} + q_{2}, p_{3} + q_{3} \\rangle\\). A geometric interpretation of this is letting \\(\\mathbf{u}\\) be fixed, and then translating \\(\\mathbf{v}\\) so that its initial point is the same as the terminal point of \\(\\mathbf{u}\\). Note we can only add vectors of the same dimension. Scalar multiplication This vector operation allows us to stretch and compress vectors. Given a scalar (real number) \\(k\\) and a vector \\(\\mathbf{v}\\), then we define \\(k \\mathbf{v}\\) to be the vector whose magnitude is \\(\\lvert k \\rvert\\) times the magnitude \\(\\lvert \\mathbf{v} \\rvert\\) of \\(\\mathbf{v}\\) and whose direction is either the same as that of \\(\\mathbf{v}\\), if \\(k &gt; 0\\), or opposite to that of \\(\\mathbf{v}\\), if \\(k &lt; 0\\). We refer to \\(k \\mathbf{v}\\) as the scalar multiple of \\(\\mathbf{v}\\). Note, two vectors are parallel, if and only if they are scalar multiples of each other. Two special types of vectors are the zero vector and unit vectors. The zero vector, denoted by \\(\\mathbf{0}\\), is the unique vector with magnitude zero and has component form \\(\\langle 0, 0 \\rangle\\) in \\(\\mathbb{R}^{2}\\), and \\(\\langle 0, 0, 0 \\rangle\\) in \\(\\mathbb{R}^{3}\\). A unit vector is a vector with magnitude one. In \\(\\mathbb{R}^{2}\\) there are two standard unit vectors, namely \\[\\begin{align*} \\mathbf{i} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle 1, 0 \\rangle \\quad \\text{and} \\quad \\mathbf{j} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle 0, 1 \\rangle, \\end{align*}\\] from which all two dimensional vectors can be built using vector addition and scalar multiplication; and in \\(\\mathbf{R}^{3}\\) there are three standard unit vectors, namely \\[\\begin{align*} \\mathbf{i} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle 1, 0, 0 \\rangle, \\quad \\mathbf{j} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle 0, 1, 0 \\rangle \\quad \\text{and} \\quad \\mathbf{k} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\langle 0, 0, 1 \\rangle \\end{align*}\\] from which all three dimensional vectors can be built using vector addition and scalar multiplication. Proposition 1.1 (properties of vector addition and scalar multiplication) Let \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) denote three vectors of the same dimension, and let \\(a\\) and \\(b\\) denote two scalars (real numbers). \\(\\mathbf{u} + \\mathbf{v} = \\mathbf{v} + \\mathbf{u}\\) \\((\\mathbf{u} + \\mathbf{v}) + \\mathbf{w} = \\mathbf{u} + (\\mathbf{v} + \\mathbf{w})\\) \\(\\mathbf{u} + \\mathbf{0} = \\mathbf{u}\\) \\(\\mathbf{u} + (- \\mathbf{u}) = \\mathbf{0}\\) \\(0 \\, \\mathbf{u} = \\mathbf{0}\\) \\(1 \\, \\mathbf{u} = \\mathbf{u}\\) \\(a \\, (b \\, \\mathbf{u}) = (a \\, b) \\, \\mathbf{u}\\) \\(a \\, (\\mathbf{u} + \\mathbf{v}) = a \\, \\mathbf{u} + b \\mathbf{v}\\) \\((a + b) \\, \\mathbf{u} = a \\, \\mathbf{u} + b \\mathbf{v}\\) We will conclude our recollection of vector geometry with a short discussion on two heavily used concepts the dot product and the cross product. Geometrically the dot product of two vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), written \\(\\mathbf{u} \\cdot \\mathbf{v}\\), is the length of the shadow that \\(\\mathbf{v}\\) casts on \\(\\mathbf{u}\\) multiplied by the magnitude \\(\\lvert \\mathbf{u} \\rvert\\) of \\(\\mathbf{u}\\). Algebraically, we can write this as \\[\\begin{align*} \\mathbf{u} \\cdot \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\lvert \\mathbf{u} \\rvert \\lvert \\mathbf{v} \\rvert \\cos(\\theta), \\end{align*}\\] where \\(\\theta\\) denotes the acute angle between \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). As such, two non‑zero vectors are orthogonal if and only if their dot product equals zero. Further, from this identity, one can show that \\[\\begin{align*} \\lvert \\mathbf{u} + \\mathbf{v} \\rvert \\leq \\lvert \\mathbf{u} \\rvert + \\lvert \\mathbf{v} \\rvert. \\end{align*}\\] This inequality is known as a triangle inequality. Letting \\(\\mathbf{u} = \\langle u_{1}, u_{2} \\rangle\\) and \\(\\mathbf{v} = \\langle v_{1}, v_{2} \\rangle\\), a convenient way to compute their dot product is \\(\\mathbf{u} \\cdot \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=u_{1}v_{1} + u_{2}v_{2}\\), and if \\(\\mathbf{u} = \\langle u_{1}, u_{2}, u_{3} \\rangle\\) and \\(\\mathbf{v} = \\langle v_{1}, v_{2}, v_{3} \\rangle\\), then \\(\\mathbf{u} \\cdot \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=u_{1}v_{1} + u_{2}v_{2} + u_{3}v_{3}\\). Proposition 1.2 (properties of the dot product) Let \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) denote three vectors of the same dimension, and let \\(a\\) denote a scalar (real number). \\(\\mathbf{u} \\cdot \\mathbf{v} = \\mathbf{v} \\cdot \\mathbf{u}\\) \\((c\\,\\mathbf{u}) \\cdot \\mathbf{v} = \\mathbf{u} \\cdot (c\\,\\mathbf{v}) = c\\,(\\mathbf{u} \\cdot \\mathbf{v})\\) \\(\\mathbf{u} \\cdot ( \\mathbf{v} + \\mathbf{w} ) = \\mathbf{u} \\cdot \\mathbf{v} + \\mathbf{u} \\cdot \\mathbf{w}\\) \\(\\mathbf{u} \\cdot \\mathbf{u} = \\lvert \\mathbf{u} \\rvert^{2}\\) \\(\\mathbf{0} \\cdot \\mathbf{u} = 0\\) Another important vector product we will be concerned with is the cross product of two vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), denoted by \\(\\mathbf{u} \\times \\mathbf{v}\\). It is often used in physics and engineering to describe rotational effects produced by forces. Unlike the dot product which is a scalar, the cross product is a vector. Geometrically, it is a vector orthogonal to both \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), whose magnitude equals the area of the parallelogram determined by \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). Algebraically, if \\(\\mathbf{u} = \\langle u_{1}, u_{2} \\rangle\\) and \\(\\mathbf{v} = \\langle v_{1}, v_{2} \\rangle\\), then \\[\\begin{align*} \\mathbf{u} \\times \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\begin{vmatrix} u_{1} &amp; u_{2}\\\\ v_{1} &amp; v_{2} \\end{vmatrix} = (u_{1}v_{2} - u_{2}v_{1}) \\mathbf{k}, \\end{align*}\\] and if \\(\\mathbf{u} = \\langle u_{1}, u_{2}, u_{3} \\rangle\\) and \\(\\mathbf{v} = \\langle v_{1}, v_{2}, v_{3} \\rangle\\), then \\[\\begin{align*} \\mathbf{u} \\times \\mathbf{v} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\begin{vmatrix} \\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k}\\\\ u_{1} &amp; u_{2} &amp; u_{3}\\\\ v_{1} &amp; v_{2} &amp; v_{3} \\end{vmatrix} = (u_{2}v_{3} - u_{3}v_{2})\\mathbf{i} + (u_{3}v_{1}-u_{1}v_{3})\\mathbf{j} + (u_{1}v_{2} - u_{2}v_{1}) \\mathbf{k}. \\end{align*}\\] Further, \\(\\lvert \\mathbf{u} \\times \\mathbf{v} \\rvert = \\lvert u \\rvert \\, \\lvert v \\rvert \\, \\lvert \\sin(\\theta) \\rvert\\), where \\(\\theta\\) denotes the acute angle between \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). Thus, two non‑zero vectors are parallel, if and only if their cross product is equal to the zero vector. Proposition 1.3 (properties of the cross product) Let \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) denote three vectors of the same dimension, and let \\(a\\) and \\(b\\) denote two scalars (real numbers). \\(r \\, \\mathbf{u} \\times s \\, \\mathbf{v} = r s \\, (\\mathbf{u} \\times \\mathbf{v})\\) \\(\\mathbf{u} \\times (\\mathbf{v} + \\mathbf{w}) = (\\mathbf{u} \\times \\mathbf{v}) + (\\mathbf{u} \\times \\mathbf{w})\\) \\((\\mathbf{u} + \\mathbf{v}) \\times \\mathbf{w} = (\\mathbf{u} \\times \\mathbf{w}) + (\\mathbf{v} \\times \\mathbf{w})\\) \\(\\mathbf{u} \\times \\mathbf{v} = - \\mathbf{v} \\times \\mathbf{u}\\) \\(\\mathbf{0} \\times \\mathbf{u} = \\mathbf{0}\\) \\(\\mathbf{u} \\times (\\mathbf{v} \\times \\mathbf{w}) = (\\mathbf{u} \\cdot \\mathbf{w}) \\, \\mathbf{v} - (\\mathbf{u}\\cdot \\mathbf{v}) \\, \\mathbf{w}\\) Coordinate systems In two dimensions, when representing \\(\\mathbb{R}^{2}\\), we usually use Cartesian coordinates, namely where we view the plane with rectangular eyes. Namely we designate a point to represent the origin, and then classify their distance from the origin via a horizontal distance and a vertical distance. Formally, the ordered pair \\((a, b)\\) denotes the point whose distance from the \\(x\\)- and \\(y\\)-axes are \\(b\\) and \\(a\\), respectively. However, investigating planar curves (for instances, circles, ellipses and spirals) with Cartesian coordinates can be cumbersome. Another method for representing points in the plane is to use polar coordinates. In this new scheme we represent a point \\(p \\in \\mathbb{R}^{2}\\) by a radial distance denoted by \\(r\\), namely the length of the straight line segment connecting the origin to \\(p\\) and a radial coordinate \\(\\theta\\) called the azimuth, that is the angle measured in a counter clockwise direction from the positive \\(x\\)-axis, see Figure 1.1. To distinguish a polar representation \\((r, \\theta)\\) of a point \\(p\\) from a Cartesian representation \\((x, y)\\) of \\(p\\), we prefix the ordered pair \\((r, \\theta)\\) by \\(P\\). FIGURE 1.1: Illustration of a polar representation of a point \\(p\\) in the plane \\(\\mathbb{R}^{2}\\). Show/hide image source code %%Image generated using LaTeX package tikz.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\draw [dashed] (0, 3) -- (4,3); \\draw [dashed] (4, 0) -- (4,3); \\draw [thick, Cerulean] (0, 0) -- (4,3); \\draw [dashed, Cerulean, &lt;-&gt;] (-0.15,0.2) -- (3.85,3.2); \\draw[Cerulean, fill=Cerulean] (4,3) circle(1.5pt); \\draw[Black, fill=Black] (0,0) circle(1.5pt); \\node at (4,-0.15) {$x$}; \\node at (-0.15,3) {$y$}; \\node at (-0.15,-0.15) {$o$}; \\node [Cerulean] at (1.9,2) {$r$}; \\node [Cerulean] at (0.9,0.3) {$\\theta$}; \\node at (5.3,3.2) {${\\color{Cerulean}P(r, \\theta)} = (x, y)$}; \\draw[dashed, Cerulean, -&gt;] (1.35,0) arc (0:36:1.35); \\draw [thick, -&gt;] (-0.1, 0) -- (5,0); \\draw [thick, -&gt;] (0, -0.1) -&gt; (0,4); \\end{tikzpicture} \\end{preview} \\end{document} However, unlike Cartesian coordinates, the polar representation of a point is not necessarily unique. For instance, take the Cartesian point \\((3, 4)\\). This has a countable number of polar representations, for instance, \\[\\begin{align*} P(5, \\arctan(3/4)) = P(5, \\arctan(3/4) + 2 k \\pi) = P(-5, \\arctan(3/4) + (2 k+1) \\pi) \\end{align*}\\] for \\(k \\in \\mathbb{Z}\\). Therefore, when a unique representation is needed for a given point besides the origin, it is usual to limit the radial distance \\(r\\) to the positive real numbers and the azimuth to the interval \\((-\\pi, \\pi]\\). "],["functionsfoundations.html", "1.3 Functions", " 1.3 Functions The concept of a function lies at the foundations of calculus. The effect that a change in one variable has on the value of another, lies at the heart of calculus and how we model real world phenomena. Functions relate elements of different sets. A function, mapping or transformation \\(f\\) from a set \\(A\\) to a set \\(B\\) is a rule or formula that associates to each element \\(a \\in A\\) exactly one element \\(f(a) \\in B\\). We write \\(f \\, \\colon \\, A \\to B\\) to mean that \\(f\\) is a function from the set \\(A\\) to the set \\(B\\), and call \\(A\\) the domain of \\(f\\), denoted by \\(\\mathrm{Dom}(f)\\), and \\(B\\) the codomain of \\(f\\). The set of points \\(\\{ f(a) \\, \\colon \\, a \\in A \\}\\) is known as the range of \\(f\\), denoted by \\(\\mathrm{Ran}(f)\\). Two functions \\(f\\) and \\(g\\) are equal if and only if they have the same domain, the same range, and \\(f(x) = g(x)\\) for all \\(x\\) in the domain of \\(f\\), and hence the domain of \\(g\\). Three, types of functions which feature heavily in real analysis, and hence calculus, are those which are injective, surjective and bijective. Injective A function \\(f \\, \\colon \\, A \\to B\\) is injective, if distinct elements of \\(A\\) always map to distinct images in \\(B\\). Namely, for all \\(x\\) and \\(y \\in A\\), if \\(x \\neq y\\), then \\(f(x) \\neq f(y)\\). Surjective A function \\(f \\, \\colon \\, A \\to B\\) is surjective if, for every \\(b \\in B\\), there exists a (not necessarily unique) element \\(a \\in A\\) such that \\(b = f(a)\\). Bijective A mapping is bijective if it is both injective and surjective. Given two functions \\(f \\, \\colon \\, A \\to B\\) and \\(g \\, \\colon \\, B \\to C\\), we often want to combine these functions to give us a new function from \\(A\\) to \\(C\\) whose effect on an element \\(a \\in A\\) is that of first applying \\(f\\) to \\(a\\) and then applying \\(g\\) to the result. This is known as the composition of \\(g\\) with \\(f\\). Formally, the composition of \\(g\\) with \\(f\\), denoted \\(g \\circ f\\), is a mapping with domain \\(A\\), codomain \\(C\\), and rule \\(g \\circ f(a) = g(f(a))\\), for all \\(a \\in A\\). We note that the operation of composition is associative, that is, if \\(f \\, \\colon \\, A \\to B\\), \\(g \\, \\colon \\, B \\to C\\) and \\(h \\, \\colon \\, C \\to D\\), then \\(h \\circ (g \\circ f)\\) and \\((h \\circ g) \\circ f\\) are equal. Given a function \\(f \\, \\colon \\, A \\to B\\) it is often useful to be able to talk about its inverse, if it exists. That is, a function \\(g \\, \\colon \\, B \\to A\\) such that \\(g \\circ f = \\mathrm{id}_{A}\\) and \\(f \\circ g = \\mathrm{id}_{B}\\), where \\(\\mathbb{id}_{A} \\, \\colon A \\to A\\) and \\(\\mathbb{id}_{B} \\, \\colon B \\to B\\) are the identity functions on \\(A\\) and \\(B\\), respectively, and are defined by \\(\\mathrm{id}_{A}(a) = a\\) and \\(\\mathrm{id}_{B}(b) =b\\), for all \\(a \\in A\\) and \\(b \\in B\\). Note that not every function has an inverse, and when a function \\(f\\) has an inverse, then we say that the function is invertible and denote its inverse by \\(f^{-1}\\). The following gives a characterisation of when a function is invertible. Theorem 1.1 (invertible if and only if bijective) A function is invertible if and only if it is bijective. In calculus, we tend to focus on functions whose domain and codomain are subsets of the real line \\(\\mathbb{R}\\). Here there are several common classes of functions. Unless otherwise stated in the following, let \\(f\\) denote a real valued function (that is a function with codomain \\(\\mathbb{R}\\)) with domain \\(D \\subseteq \\mathbb{R}\\). If \\(D\\) is centred about zero, then \\(f\\) is called even if \\(f(x) = f(-x)\\) for all \\(x \\in D\\). If \\(D\\) is centred about zero, then \\(f\\) is called odd if \\(f(-x) = -f(x)\\) for all \\(x \\in D\\). If \\(f\\) is defined by \\(f(x) = mx + c\\), for some fixed constants \\(m\\) and \\(c\\), then \\(f\\) is called linear. If \\(f\\) is defined by \\(f(x) = x^{a}\\), for some fixed constant \\(a\\), then \\(f\\) is called a power function. We call \\(f\\) a polynomial if f is defined by \\(f(x) = a_{n}x^{n} + a_{n-1}x^{n-1} + \\dots + a_{1}x + a_{0}\\), where \\(n\\) is a fixed non‑negative integer and \\(a_{n}\\), \\(a_{n-1}\\), …, \\(a_{1}\\), \\(a_{0}\\) are fixed constants called the coefficients of the polynomial. If the leading coefficient \\(a_{n} \\neq 0\\), then \\(n\\) is called the degree of the polynomial. A rational function is a quotient of polynomials. A function \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is called periodic if there exists a positive number \\(p\\) such that \\(f(x + p) = f(x)\\) for all \\(x \\in \\mathbb{R}\\). The smallest such value of \\(p\\) is called the period of \\(f\\). In order to be able to speak meaningfully about rates of change, tangent line and planes, one needs to use the concept of a limit. Indeed, the concept of a limit is the cornerstone on which the development of calculus rests. Limits (part I) In the steady flow of a river, the smooth passage of time and the majestic formation of clouds, we perceive continuity of motion. There are no sharp changes and no jumps in the movement. Through the idea of limits, calculus provides the means to study continuity rigorously. Indeed, in order to be able to speak meaningfully about rates of change, tangent line and planes, one needs to use the concept of a limit, and as such, the concept of a limit is the cornerstone on which the development of calculus rests. Definition 1.3 (limits – part I) Let \\(x_{0} \\in \\mathbb{R}\\), let \\(I \\subseteq \\mathbb{R}\\) be an open interval containing \\(x_{0}\\) and let \\(f\\) be a real valued function defined on \\(I\\), except possibly at \\(x_{0}\\). We say that \\(L\\) is the limit of \\(f\\) as \\(x\\) approaches \\(x_{0}\\) if for every \\(\\epsilon &gt; 0\\) there exists a \\(\\delta &gt; 0\\) such that, for all \\(x \\in I\\) satisfying \\(\\lvert x - x_{0} \\rvert &lt; \\delta\\), we have that \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to x_{0}} f(x) = L. \\end{align*}\\] One can also speak about the limit as \\(x\\) tends to positive and negative infinity. Definition 1.4 (limits – part II) A real valued function \\(f\\) defined on the half‑line \\(\\{ x \\, \\colon \\, x \\geq k \\}\\), for some \\(k \\in \\mathbb{R}\\), has a limit \\(L\\) at infinity, if for every \\(\\epsilon &gt; 0\\) there exists a real number \\(N &gt; 0\\) such that, for all \\(x &gt; N\\), we have that \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to \\infty} f(x) = L. \\end{align*}\\] Similarly, we say that a real valued function \\(f\\) defined on the half‑line \\(\\{ x \\, \\colon x \\leq k \\}\\), for some \\(k \\in \\mathbb{R}\\), has a limit \\(L\\) at negative infinity, if for every \\(\\epsilon &gt; 0\\) there exists a real number \\(N &lt; 0\\) so that, for all \\(x &lt; N\\), we have \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to -\\infty} f(x) = L. \\end{align*}\\] Let \\(L\\), \\(M\\), \\(k\\) and \\(x_{0}\\) denote four real numbers, and let \\(I \\subseteq \\mathbb{R}\\) denote an open interval containing \\(x_{0}\\). If \\(f\\) and \\(g\\) are two real valued functions defined on \\(I\\), except possibly at \\(x_{0}\\) itself, such that \\[\\begin{align*} \\lim_{x \\to x_{0}} f(x) = L \\quad \\text{and} \\quad \\lim_{x \\to x_{0}} g(x) = M, \\end{align*}\\] then we have the following: \\(\\displaystyle \\lim_{x \\to x_{0}} f(x) \\pm g(x) = L \\pm M\\), \\(\\displaystyle \\lim_{x \\to x_{0}} k f(x) = k L\\), and \\(\\displaystyle \\lim_{x \\to x_{0}} f(x) g(x) = L M\\). If in addition, \\(L\\) is positive, \\(M\\) is non-zero, and \\(n\\) is a positive real number, then \\(\\displaystyle \\lim_{x \\to x_{0}} \\frac{f(x)}{g(x)} = \\frac{L}{M}\\), and \\(\\displaystyle \\lim_{x \\to x_{0}} (f(x))^{n} = L ^{n}.\\) The above equalities also hold when we replace \\(x_{0}\\) by positive infinity and when \\(x_{0}\\) is replaced by negative infinity. Further, if \\(f(x) \\leq g(x)\\) for all \\(x\\) in some non-empty open interval about a point \\(x_{0}\\), except possibly at \\(x_{0}\\) itself, and the limits of \\(f\\) and \\(g\\) both exist as \\(x\\) approaches \\(x_{0}\\), and are denoted by \\(L\\) and \\(M\\) respectively, then \\(L \\leq M\\). The concept of a limit can be extended to that of a one‑sided limit, where one considers the limit as \\(x\\) approaches a number \\(c\\) from the left‑hand side only, or the right‑hand side only. Definition 1.5 (one-sided limits) Let \\(x_{0} \\in \\mathbb{R}\\), \\(I \\subseteq \\mathbb{R}\\) be an interval containing \\(x_{0}\\) and let \\(f\\) be a real valued function defined on \\(I\\), except possibly at \\(x_{0}\\). We say that \\(L\\) is the right‑limit of \\(f\\) as \\(x\\) approaches \\(x_{0}\\) if for every \\(\\epsilon &gt; 0\\) there exists a \\(\\delta &gt; 0\\) such that, for all \\(x \\in I\\) satisfying \\(x_{0} &lt; x &lt; x_{0} + \\delta\\), we have that \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to x_{0}^{+}} f(x) = L. \\end{align*}\\] Similarly, we say that \\(L\\) is the left‑hand limit of \\(f\\) as \\(x\\) approaches \\(x_{0}\\) if for every \\(\\epsilon &gt; 0\\) there exists a \\(\\delta &gt; 0\\) such that, for all \\(x\\) satisfying \\(x_{0} -\\delta &lt; x &lt; x_{0}\\) in the domain of \\(f\\), we have that \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to x_{0}^{-}} f(x) = L. \\end{align*}\\] Observe that if the limit of a function exists, then both the left‑hand and right‑hand limits exist. However, the converse is not true. Continuity (part I) Informally, any function \\(f\\) whose graph can be sketched over its domain in one continuous motion without lifting ones pencil, is an example of a continuous function. To define continuity formally we use the notion of a limit. Definition 1.6 (continuity – part I) Let \\(I\\) denote a non-empty interval and let \\(f \\, \\colon \\, I \\to \\mathbb{R}\\). If \\(x_{0}\\) is an interior point of \\(I\\), then \\(f\\) is continuous at \\(x_{0}\\) if \\[\\begin{align*} \\lim_{x \\to x_{0}} f(x) = f(x_{0}).\\qquad \\end{align*}\\] If \\(a\\) is a left boundary point of \\(I\\) and \\(a \\in I\\), then \\(f\\) is continuous at \\(a\\) if \\[\\begin{align*} \\lim_{x \\to x_{0}^{+}} f(x) = f(x_{0}).\\qquad \\end{align*}\\] If \\(b\\) is a right boundary point of \\(I\\) and \\(b \\in I\\), then \\(f\\) is continuous at \\(b\\) if \\[\\begin{align*} \\lim_{x \\to x_{0}^{-}} f(x) = f(x_{0}).\\qquad \\end{align*}\\] We say that \\(f\\) is continuous if it is continuous at \\(x\\) for all \\(x \\in I\\). On the other hand, if \\(f\\) is not continuous at a point \\(x_{0}\\), then \\(f\\) is said to be discontinuous and \\(x_{0}\\) is called a point of discontinuity. If they exist, then sums, products, quotients, powers and roots of continuous functions are again continuous. Further, if \\(f\\) is a continuous real valued function at \\(x_{0} \\in \\mathbb{R}\\) and \\(g\\) is a continuous real valued function at \\(f(x_{0}) \\in \\mathbb{R}\\), then the composite function \\(g \\circ f\\) is continuous at \\(x_{0}\\). Moreover, if \\(g\\) is a continuous real valued function at \\(b \\in \\mathbb{R}\\) and the limit as \\(x \\to x_{0}\\) of \\(f(x)\\) exists and is equal to \\(b\\), then \\[\\begin{align*} \\lim_{x \\to x_{0}} g (f(x)) = g(b) = g\\left(\\lim_{x \\to x_{0}} f(x)\\right). \\end{align*}\\] An extremely powerful and useful result concerning continuous functions is the intermediate value theorem. Theorem 1.2 (intermediate value theorem) If \\(f\\) is a continuous real valued function with domain \\([a, b]\\) and \\(y_{0}\\) lies between \\(f(a)\\) and \\(f(b)\\), then there exists \\(c \\in [a, b]\\) with \\(f(c) = y_{0}\\). "],["differentiationfoundations.html", "1.4 Differentiation", " 1.4 Differentiation Derivatives and their generalisations appear in many fields of mathematics, such as complex analysis, functional analysis, differential geometry, measure theory, and abstract algebra. They have applications in all quantitative disciplines. For example, in physics, the derivative of the displacement of a moving body with respect to time is the velocity of the body, and the derivative of velocity with respect to time is acceleration; momentum and force are related via a derivative and from this relation comes Newton’s second law of motion. In chemistry, the rate of a chemical reaction is also determined via a derivative; and in operations research, derivatives determine the most efficient ways to transport materials and design factory operations. Definition 1.7 (derivative) Let \\(f\\) denote a real valued function with domain a non‑degenerate interval \\(D \\subseteq \\mathbb{R}\\). The derivative of \\(f\\) at a point \\(x_{0}\\) in the interior of \\(D\\) is defined by \\[\\begin{align*} f&#39;(x_{0}) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\lim_{h \\to 0} \\frac{f(x_{0} + h) - f(x_{0})}{h} = \\lim_{z \\to x_{0}} \\frac{f(z) - f(x_{0})}{z - x_{0}} \\end{align*}\\] provided that the limit exist; if \\(x_{0} \\in D\\) but is not an interior point, then we define the derivative of \\(f\\) at \\(x_{0}\\) as above, replacing the limit by the appropriate one‑sided limit, provided that it exists. It is also common to use the notation \\[\\begin{align*} \\frac{\\mathrm{d}f}{\\mathrm{d}x}(x_{0}) \\quad \\text{or} \\quad \\frac{\\mathrm{d}}{\\mathrm{d}x} f(x_{0}) \\end{align*}\\] for the derivative of \\(f\\) at \\(x_{0}\\), provided that the derivative at \\(x_{0}\\) exists. If the derivative of \\(f\\) exists at every point in \\(D\\), then we say that \\(f\\) is differentiable. If \\(f\\) is a differentiable function, then its derivative \\(f&#39;\\) is also a function. If \\(f&#39;\\) is also differentiable, then we can take the derivative of \\(f&#39;\\) with respect to \\(x\\) to obtain a new function \\(f&#39;&#39; \\,{\\colon}\\mathrel{\\mkern-5mu}=(f&#39;)&#39;\\). The function \\(f&#39;&#39;\\) is called the second derivative of \\(f\\) with respect to \\(x\\) and is written in several way: \\[\\begin{align*} f&#39;&#39; = \\frac{\\mathrm{d}^{2}f}{\\mathrm{d}x^{2}} = \\frac{\\mathrm{d}^{2}}{\\mathrm{d}x^{2}} f = \\frac{\\mathrm{d}}{\\mathrm{d}x} \\left(\\frac{\\mathrm{d}}{\\mathrm{d}x}f \\right). \\end{align*}\\] If \\(f&#39;&#39;\\) is also differentiable, its derivative \\(f&#39;&#39;&#39; \\,{\\colon}\\mathrel{\\mkern-5mu}=(f&#39;&#39;)&#39;\\) is called the third derivative of \\(f\\) with respect to \\(x\\). The name continues as you would imagine, with \\[\\begin{align*} f^{(n)} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\mathrm{d}}{\\mathrm{d}x} f^{(n-1)} \\end{align*}\\] denoting the \\(n\\)-th derivative of \\(f\\) with respect to \\(x\\). If for all \\(n \\in \\mathbb{N}\\), the \\(n\\)-th derivative of \\(f\\) exists, then we say that \\(f\\) is smooth. A common question which arises in calculus is, if \\(f\\) is a given function, then does there exist a function \\(F\\) such that \\(F&#39; = f\\)? When such a function \\(F\\) exists, we call it an anti‑derivative of a \\(f\\). The collection of all anti‑derivatives of a function \\(f\\) is called the indefinite integral of \\(f\\) with respect to \\(x\\), and is denoted by \\[\\begin{align*} \\int f(x) \\, \\mathrm{d}x. \\end{align*}\\] The function \\(f\\) is the integrand of the integral, and \\(x\\) is the variable of integration. In fact, if \\(F\\) and \\(G\\) are anti‑derivatives of \\(f\\), then there exists a constant \\(c \\in \\mathbb{R}\\) such that \\(G(x) = F(x) + c\\), for all \\(x\\) in the domain of \\(f\\). Such a constant is often referred to as a constant of integration. Let us now list some techniques of differentiation. Theorem 1.3 (properties and techniques of differentiation) Let \\(f\\) and \\(g\\) denote real valued differentiable functions and let \\(a\\) and \\(b \\in \\mathbb{R}\\). Linearity \\(\\displaystyle \\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} (a f(x) + b g(x)) = a f&#39;(x) + b g&#39;(x)\\) Product rule \\(\\displaystyle \\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} f(x) g (x) = f&#39;(x) g(x) + f(x) g&#39;(x)\\) Quotient rule: Provided that \\(g(x) \\neq 0\\) \\(\\displaystyle \\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{f(x)}{g(x)} = \\frac{f&#39;(x) g(x) - f(x) g&#39;(x)}{g^{2}(x)}\\) Chain rule: Provided that \\(\\operatorname{Ran}(g) \\subseteq \\operatorname{Dom}(f)\\) \\(\\displaystyle \\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} f \\circ g (x) = f&#39;(g(x)) g&#39;(x)\\) Inverse function rule: Provided that \\(f\\) is bijective and \\(f&#39;(x) \\neq 0\\) for all \\(x \\in \\mathrm{Dom}(f)\\) \\(\\displaystyle \\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} f^{-1}(x) = \\frac{1}{f&#39;(f^{-1}(x))}\\) Two further techniques for finding derivatives are implicit differentiation and logarithmic differentiation; in fact as we will shortly see the latter is an application of the former. With this in mind, let us give a brief overview of implicit differentiation followed by a short description of logarithmic differentiation. Most functions which one sees in calculus express \\(y\\) explicitly in terms of a single variable \\(x\\), namely they are of the form \\(y = f(x)\\). However, often we are presented which situations which give implicit relations between the variables \\(x\\) and \\(y\\), for instance, \\[\\begin{align*} x^{3}y + x^{2}y^{2} + 3 = y + x \\quad \\text{or} \\quad y^{4} +3y - 4x^{3} = 5x + 1. \\end{align*}\\] In some cases we may be able to solve such an equation for \\(y\\) as an explicit function (or even several functions) of \\(x\\). When this is not possible we may able to find the derivative of \\(y\\) with respect to \\(x\\) by the method of implicit differentiation, where we differentiate each term of the equation with respect to \\(x\\). In using implicit differentiation, it is often necessary to consider terms of the form \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}x} x^{2}y^{2}, \\quad \\frac{\\mathrm{d}}{\\mathrm{d}x} y^{4}, \\quad \\text{or} \\quad \\frac{\\mathrm{d}}{\\mathrm{d}x} x^{m}y^{n}, \\end{align*}\\] for some \\(m\\) and \\(n \\in \\mathbb{N}\\). Since we are viewing \\(y\\) as a differentiable function of \\(x\\), using the product and the chain rule, we obtain that \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}x} x^{m}y^{n} = x^{m} \\frac{\\mathrm{d}}{\\mathrm{d}x} (y^{n}) + y^{n} \\frac{\\mathrm{d}}{\\mathrm{d}x} x^{m} = n x^{m} y^{n-1} y&#39; + m x^{m-1} y^{n}. \\end{align*}\\] The general approach to finding the derivative of \\(y\\) with respect to \\(x\\), when \\(x\\) and \\(y\\) are given by a implicit expression, is as follows: Differentiate both sides of the expression relating \\(x\\) and \\(y\\) implicitly, treating y as a differentiable function of \\(x\\); Solve the resulting equation for \\(y&#39; = \\mathrm{d}y/\\mathrm{d}x\\). Note, it may not always be possible to solve explicitly for \\(y&#39;\\), in which case we will have an expression relating \\(x\\), \\(y&#39;\\) and maybe even \\(y\\). With this brief overview of implicit differentiation, let us turn our attention to our final technique, namely logarithmic differentiation. This is an application of implicit differentiation and applies to our standard setting when \\(y\\) is explicitly given in terms of a single variable \\(x\\), namely when there exists a function \\(f\\) such that \\(y = f(x)\\). In logarithmic differentiation one first takes logarithms before differentiating. This enables us to use the laws of logarithms to simplify positive functions involving complicated products, quotients or powers. Suppose that \\(f\\) is such a function defined on an open domain. To apply logarithmic differentiation we set \\(y = f(x)\\) and proceed as follows: Take natural logarithms and simplify to obtain \\[\\begin{align*} \\ln(y) = \\ln(f(x)). \\end{align*}\\] Differentiate implicitly with respect to \\(x\\), \\[\\begin{align*} \\frac{1}{y} \\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\frac{\\mathrm{d}}{\\mathrm{d}x} \\ln(f(x)). \\end{align*}\\] Multiply by \\(y = f(x)\\) to obtain the derivative of \\(f\\) with respect to \\(x\\), \\[\\begin{align*} f&#39;(x) = \\frac{\\mathrm{d}y}{\\mathrm{d}x} = f(x) \\frac{\\mathrm{d}}{\\mathrm{d}x} \\ln(f(x)). \\end{align*}\\] Before we conclude this section with a list of derivatives of common functions we recall three useful results. Theorem 1.4 (differentiability implies continuity) Every differentiable function is continuous. Theorem 1.5 (mean value theorem) Let \\(a\\) and \\(b\\) denote two real numbers with \\(a &lt; b\\). Suppose that \\(f\\) is a well‑defined function that is continuous at every point in the closed interval \\([a, b]\\) and differentiable at every point of its interior \\((a, b)\\). Then there exists a real number \\(c \\in (a, b)\\) such that \\[\\begin{align*} \\frac{f(b) - f(a)}{b-a} = f&#39;(c). \\end{align*}\\] Theorem 1.6 (L'Hôpital's rule) Let \\(f\\) and \\(g\\) denote two functions which are differentiable on a non-empty open interval about a given point \\(a\\). If either \\[\\begin{align*} \\lim_{x \\to a} f(x) = \\lim_{x \\to a} g(x) = 0 \\quad \\text{or} \\quad \\lim_{x \\to a}f(x) = \\pm \\infty \\;\\, \\text{and} \\;\\, \\displaystyle \\lim_{x \\to a}g(x) = \\pm \\infty, \\end{align*}\\] then we have that \\[\\begin{align*} \\lim_{x \\to a} \\frac{f(x)}{g(x)} = \\lim_{x \\to a} \\frac{f&#39;(x)}{g&#39;(x)}. \\end{align*}\\] Derivatives of common functions We conclude this section with a list of derivatives of some common and familiar functions. Polynomials: For \\(n \\in \\mathbb{N_{0}}\\) and \\(a_{0}\\), \\(a_{2}\\), …, and \\(a_{n} \\in \\mathbb{R}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} (a_{0} + a_{1} x + a_{2} x^{2} + \\dots + a_{n }x^{n}) = a_{1} + 2 a_{2} x + \\dots + n a_{n}x^{n-1}\\) Trigonometric functions \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\sin(x) = \\cos(x)\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\cos(x) = -\\sin(x)\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\tan(x) = \\sec^{2}(x)\\) Inverse trigonometric functions \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\arcsin(x) = \\frac{1}{\\sqrt{1 - x^{2}}}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\arccos(x) = \\frac{-1}{\\sqrt{1 - x^{2}}}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\arctan(x) = \\frac{1}{1 + x^{2}}\\) Exponential and logarithm \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathrm{e}^{x} = \\mathrm{e}^{x}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\ln(x) = \\frac{1}{x}\\) Hyperbolic functions \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\sinh(x) = \\cosh(x)\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\cosh(x) = \\sinh(x)\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\tanh(x) = \\operatorname{sech}^{2}(x)\\) Inverse hyperbolic functions \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\operatorname{arcsinh}(x) = \\frac{1}{\\sqrt{1 + x^{2}}}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\operatorname{arccosh}(x) = \\frac{1}{\\sqrt{x^{2} - 1}}\\) \\(\\displaystyle \\qquad\\qquad \\frac{\\mathrm{d}}{\\mathrm{d}x} \\operatorname{arctanh}(x) = \\frac{1}{1 - x^{2}}\\) "],["critical_points_foundations.html", "1.5 Critical points", " 1.5 Critical points Hydro systems, solar panels and wind turbines symbolise world efforts to build energy sources that maximise the generation of electricity, while keeping pollution and costs low. In many other real world situations, there are similar challenges to optimise systems while satisfying certain constraints. Here derivatives help to solve such constraint optimisation problems. As a first step to developing such a theory, in the calculus of functions of a single variable, we examine how to determine extremal values of a function. Definition 1.8 (local and global extreme) Let \\(I\\) be a non-empty interval, half-line or \\(\\mathbb{R}\\) and let \\(f \\, \\colon \\, I \\to \\mathbb{R}\\). A point \\(c \\in I\\) is said to be a local maximum if \\(f(x) \\leq f(c)\\) for all points \\(x\\) in an open neighbourhood of \\(c\\); a local minimum if \\(f(x) \\geq f(c)\\) for all points \\(x\\) in an open neighbourhood of \\(c\\); a global (or absolute) maximum if \\(f(x) \\leq f(c)\\) for all \\(x \\in I\\); a global (or absolute) minimum if \\(f(x)\\ge f(c)\\) for all \\(x \\in I\\); a local or global extreme if it is a local or global maximum or minimum. Existence of global extreme of continuous functions whose domain is closed is given by the extreme value theorem. Definition 1.9 (extreme value theorem) If \\(f\\) is a continuous function whose domain is closed attains both an absolute maximum and an absolute minimum. Local and global extreme fall under a larger class of points called critical points. In addition to local and global extreme, the class of critical points include singular points and saddle points. We say that \\(c\\) is a singular point of \\(f\\), if the derivative of \\(f\\) at \\(c\\) is undefined; and if \\(f\\) is differentiable, then \\(c\\) is called a saddle point of \\(f\\) if \\(f&#39;(c) = 0\\) and \\(c\\) is neither a local maximum nor a local minimum. Our next results not only allows us show existence of extreme, but to also determine their position. Theorem 1.7 (second derivative test for local extreme) Suppose that \\(f\\) is twice differentiable on a non-degenerate interval, and let \\(c \\in I\\). If \\(f&#39;(c) = 0\\) and \\(f&#39;&#39;(c) &lt; 0\\), then \\(f\\) has a local maximum at \\(c\\). If \\(f&#39;(c) = 0\\) and \\(f&#39;&#39;(c) &gt; 0\\), then \\(f\\) has a local minimum at \\(c\\). If \\(f&#39;(c) = 0\\) and \\(f&#39;&#39;(c) = 0\\), then the test fails. Indeed, at \\(c\\) the function \\(f\\) may have a local minimum, a local maximum, or be a saddle point. "],["integrationfoundations.html", "1.6 Integration", " 1.6 Integration The Riemann integral was introduced by the German mathematician Georg Friedrich Bernhard Riemann (1826–1866) who also posed some of the most famous open problems in mathematics. He introduced the notion of integration in his Habilitationsschrift which was published in 1868 in Abhandlungen der Königlichen Gesellschaft der Wissenschaften zu Göttingen (Proceedings of the Royal Philosophical Society at Göttingen), under the title Über die Darstellbarkeit einer Function durch eine trigonometrische Reihe (On the representability of a function by a trigonometric series; that is, when can a function be represented by a trigonometric series). Given a non-degenerate interval \\(I\\) with left boundary point \\(a\\) and right boundary point \\(b\\) we call a collection of points \\(P = \\{ x_{0}, x_{1}, \\dots, x_{n} \\}\\) a partition of \\(I\\) if \\[\\begin{align*} a = x_{0} &lt; x_{1} &lt; x_{2} &lt; \\dots &lt; x_{n-1} &lt; x_{n} = b. \\end{align*}\\] In the case that \\(I\\) is degenerate but non-empty, namely the single point \\(a=b\\), then we only have one partition of \\(I\\), namely \\(P = \\{ a \\}\\). The partition \\(P\\) divides, or partitions, the closure of \\(I\\) into \\(n\\) sub-intervals \\[\\begin{align*} I_{1} = [x_{0}, x_{1}), \\; I_{2} = [x_{1}, x_{2}), \\dots, I_{n-1} = [x_{n-2}, x_{n-1}), \\; I_{n} = [x_{n-1}, x_{n}], \\end{align*}\\] with length \\(\\Delta_{1}\\), \\(\\Delta_{2}\\), …, \\(\\Delta_{n-1}\\), \\(\\Delta_{n}\\) respectively. We define the norm of \\(P\\), denoted by \\(\\lvert P \\rvert\\), to be the supreme of the set \\(\\{\\Delta_{1}, \\Delta_{2}, \\dots, \\Delta_{n} \\}\\). Let \\(f\\) be an arbitrary bounded function defined on a non-empty interval \\(I\\) and let \\(P = \\{ x_{0}, x_{1}, \\dots, x_{n} \\}\\) be a partition of \\(I\\). For each natural number \\(k \\leq n\\), let \\(c_{k}\\) denote an arbitrary chosen point in the interval \\(I_{k}\\). The sum \\[\\begin{align*} S_{p} = S_{p}(f) = \\sum_{k = 1}^{n} f(c_{k}) \\Delta x_{k} \\end{align*}\\] is called a Riemann sum for \\(f\\) over \\(I\\) with respect to the partition \\(P\\). Note, there are many Riemann sum for \\(f\\) over \\(I\\) depending on the partition \\(P\\) we choose and the choices of the points \\(c_{k}\\). Definition 1.10 (definite intergral) Let \\(f\\) be an arbitrary bounded function defined on a non-empty interval \\(I\\). We say that a real number \\(J\\) is the value of the definite integral of \\(f\\) over \\(I\\) if given an \\(\\epsilon &gt; 0\\) there is a corresponding \\(\\delta &gt; 0\\) such that for every partition \\(P\\) of \\(I\\) with \\(\\lvert P \\rvert &lt; \\delta\\) and any Riemann sum \\(S_{p}\\), we have that \\(\\lvert S_{p} - J \\rvert &lt; \\epsilon\\). Letting \\(I\\) denote a non-empty interval with left boundary point \\(a\\) and right boundary point \\(b\\), if the definite integral of \\(f\\) over \\(I\\) exists, then we commonly denote it by \\[\\begin{align*} \\int_{a}^{b} f(x) \\, \\mathrm{d}x, \\end{align*}\\] and by convention, we set \\[\\begin{align*} \\int_{b}^{a} f(x) \\, \\mathrm{d}x = - \\int_{a}^{b} f(x) \\, \\mathrm{d}x. \\end{align*}\\] In computing values of definite integrals, one commonly uses the following algebraic properties, where \\(f\\) and \\(g \\,\\colon \\, I \\to \\mathbb{R}\\) denote two integrable functions over a non-empty interval \\(I\\) with left boundary point \\(a\\) and right boundary point \\(b\\). If \\(k\\) and \\(l \\in \\mathbb{R}\\) denote two fixed constants, then \\(\\displaystyle \\qquad \\int_{a}^{b} k f(x) + l g(x) \\, \\mathrm{d}x = k \\int_{a}^{b} f(x) \\, \\mathrm{d}x + l \\int_{a}^{b} f(x) \\, \\mathrm{d}x\\). If \\(f\\) has a maximum value \\(\\max(f)\\) and a minimum value \\(\\min(f)\\), then \\(\\displaystyle \\qquad (b-a) \\min(f) \\leq \\int_{a}^{b} f(x) \\, \\mathrm{d}x \\leq (b- a) \\max(f)\\). If \\(f(x) \\geq g(x)\\) for all \\(x \\in I\\), then \\(\\displaystyle \\qquad \\int_{a}^{b} f(x) \\, \\mathrm{d}x \\geq \\int_{a}^{b} g(x) \\, \\mathrm{d}x\\). One of the most foundational results in calculus is the intimate link between integration and differentiation. Definition 1.11 (fundamental theorem of calculus) If \\(f\\) is a continuous real valued function with domain \\([a, b]\\), for some \\(a\\) and \\(b \\in \\mathbb{R}\\) with \\(a &lt; b\\), then the function \\(F\\) defined by \\[\\begin{align*} F(x) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\int_{a}^{x} f(t) \\, \\mathrm{d}t, \\end{align*}\\] for all \\(x \\in [a, b]\\), is differentiable and \\[\\begin{align*} F&#39;(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x} \\int_{a}^{x} f(t) \\, \\mathrm{d}t = f(x). \\end{align*}\\] Conversely, if \\(f\\) is a continuous function on \\([a, b]\\) and \\(F\\) is any anti‑derivative of \\(f\\) on \\((a, b)\\), then \\[\\begin{align*} \\int_{a}^{b} f(x) \\, \\mathrm{d}x = F(b) - F(a). \\end{align*}\\] Calculating integrals from first principals is often lengthy and challenging, and so we often use the above results with knowledge about integrals of common functions (see below) together with a variety of integration techniques, such as integration by substitution, integration by parts and integration by partial fractions. Integration by substitution If \\(u = g(x)\\) is a differentiable function, and if \\(f\\) is continuous on the range of \\(g\\), then \\[\\begin{align*} \\int f(g(x)) g&#39;(x) \\, \\mathrm{d}x = \\int f(u) \\, \\mathrm{d}u. \\end{align*}\\] Integration by parts If \\(f\\) and \\(g\\) are two differentiable functions, then \\[\\begin{align*} \\int f(x) g&#39;(x) \\, \\mathrm{d}x = f(x)g(x) - \\int f&#39;(x) g(x) \\, \\mathrm{d}x \\end{align*}\\] Integration by partial fractions Recall that a rational function is a function of the form \\(q(x) = f(x)/g(x)\\), where \\(f(x)\\) and \\(g(x)\\) are polynomials. If the degree of \\(f(x)\\) is less than the degree of \\(g(x)\\), then one can write \\(q(x)\\) in the following way, \\[\\begin{align*} \\frac{f(x)}{g(x)} = F_{1}(x) + F_{2}(x) + \\dots + F_{r}(x). \\end{align*}\\] Here, each term \\(F_{k}(x)\\) has one of the following forms, \\[\\begin{align*} \\frac{A}{(ax+b)^{n}} \\qquad \\text{or} \\qquad \\frac{Ax + B}{(ax^{2} + bx + c)^{n}}, \\end{align*}\\] for \\(a\\), \\(b\\), \\(c\\), \\(A\\) and \\(B \\in \\mathbb{R}\\) and \\(n\\) a non‑negative integer, and where \\(ax^{2} + bx + c\\) is irreducible in the sense that this quadratic polynomial has no real zeros (that is \\(b^{2} - 4ac &lt; 0\\)). The sum \\(F_{1}(x) + F_{2}(x) + \\dots + F_{r}(x)\\) is called the partial fraction decomposition of \\(q(x)\\), and each \\(F_{k}(x)\\) is called a partial fraction. Rewriting a rational function as a partial fraction decomposition allows one to evaluate the integral of a rational function \\(q(x) = f(x)/g(x)\\) as follows. \\[\\begin{align*} \\int q(x) \\, \\mathrm{d}x = \\int \\frac{f(x)}{g(x)} \\, \\mathrm{d}x = \\int F_{1}(x) \\, \\mathrm{d}x + \\int F_{2}(x) \\, \\mathrm{d}x + \\dots + \\int F_{r}(x) \\, \\mathrm{d}x \\end{align*}\\] Having discussed some of the algebraic and analytic properties of integration let us highlight some geometric aspects. If \\(f\\) is a non‑negative and integrable function whose domain is a non-empty interval with left boundary point \\(a\\) and right boundary point \\(b\\), then the area \\(A\\) between the graph of \\(f\\), the \\(x\\)-axis and the lines \\(\\{ (a, y) \\, \\colon \\, y \\in \\mathbb{R} \\}\\) and \\(\\{ (b, y) \\, \\colon \\, y \\in \\mathbb{R} \\}\\), namely \\(y = a\\) and \\(y = b\\), is the integral of \\(f\\) over \\(I\\): \\[\\begin{align*} A = \\int_{a}^{b} f(x) \\, \\mathrm{d}x. \\end{align*}\\] Another, geometric interpretation of integration is as an average value. Specifically, the average value \\(\\operatorname{av}(f)\\) of \\(f\\) over its domain is given by \\[\\begin{align*} \\operatorname{av}(f) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{1}{b-a} \\int_{a}^{b} f(x) \\, \\mathrm{d}x. \\end{align*}\\] In the above two geometric interpretations of integration, one may remove the condition that \\(f\\) is non‑negative, in which case we replace area, by net area, where regions above the \\(x\\)-axis have a positive contribution and regions below the \\(x\\)-axis have a negative contribution to area. Integrals of common functions We conclude this section with a list of integrals of some common and familiar functions; please note, for ease of notation the constant of integration has been omitted. Polynomials: For \\(n \\in \\mathbb{N_{0}}\\) and \\(a_{0}\\), \\(a_{2}\\), …, and \\(a_{n} \\in \\mathbb{R}\\) \\(\\displaystyle \\qquad\\qquad \\int a_{0} + a_{1} x + a_{2} x^{2} + \\dots + a_{n }x^{n} \\, \\mathrm{d}x = a_{0}x + \\frac{a_{1} x^{2}}{2} x + \\dots + \\frac{a_{n}x^{n+1}}{n+1}\\) Trigonometric functions \\(\\displaystyle \\qquad\\qquad \\int \\sin(x) \\, \\mathrm{d}x = -\\cos(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\cos(x) \\, \\mathrm{d}x = \\sin(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\tan(x) \\, \\mathrm{d}x = \\ln(\\lvert \\cos(x) \\rvert)\\) Inverse trigonometric functions \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{\\sqrt{1 - x^{2}}} \\, \\mathrm{d}x = \\arcsin(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\frac{-1}{\\sqrt{1 - x^{2}}} \\, \\mathrm{d}x = \\arccos(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{1 + x^{2}} \\, \\mathrm{d}x = \\arctan(x)\\) Exponential and logarithm \\(\\displaystyle \\qquad\\qquad \\int \\mathrm{e}^{x} \\, \\mathrm{d}x = \\mathrm{e}^{x}\\) \\(\\displaystyle \\qquad\\qquad \\int \\ln(x) \\, \\mathrm{d}x = x \\ln(x) - x\\) \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{x} \\, \\mathrm{d}x = \\ln(x)\\) Hyperbolic functions \\(\\displaystyle \\qquad\\qquad \\int \\sinh(x) \\, \\mathrm{d}x = \\cosh(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\cosh(x) \\, \\mathrm{d}x = \\sinh(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\tanh(x) \\, \\mathrm{d}x = \\ln(\\lvert \\cosh(x) \\rvert)\\) Inverse hyperbolic functions \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{\\sqrt{1 + x^{2}}} \\, \\mathrm{d}x = \\operatorname{arcsinh}(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{\\sqrt{x^{2} - 1}} \\, \\mathrm{d}x = \\operatorname{arccosh}(x)\\) \\(\\displaystyle \\qquad\\qquad \\int \\frac{1}{1 - x^{2}} \\, \\mathrm{d}x = \\operatorname{arctanh}(x)\\) "],["parametriccurvesfoundations.html", "1.7 Parametric curves", " 1.7 Parametric curves Nature is filled with curves that fascinate the minds of artists and the curiosity of scientists, for instance, the outline of the moon, the delicate folds in the petal of a flower, the sinuous curves of the Nordic fjords and the graceful silhouette of a bird in flight. A common way to represent such curves is via the use of parametric equations. If \\(f\\) is a continuous function, the graph of \\(f\\), is often called a plane curve. However, this definition is restrictive because it excludes many useful curves. The following definition provides a more suitable definition. Definition 1.12 (plane curve) A plane curve is a collection \\(C\\) of ordered pairs \\((f(t), g(t))\\), where \\(f\\) and \\(g\\) are continuous functions on a non-empty interval \\(I\\), and \\(t \\in I\\). The graph of the a plane curve \\(C\\), as defined in Definition 1.12, consists of all points \\(P(t) = (f(t), g(t))\\) in the \\(x\\)-\\(y\\) plane. It is common for the terms curve and graph of a curve to be used interchangeably. The points \\(P(a)\\) and \\(P(b) \\in C\\) are often called the end points of \\(C\\). Three examples of plane curves are sketched in Figure 1.2, where \\(I\\) is the closed interval \\([a, b]\\), for some given \\(a\\) and \\(b \\in \\mathbb{R}\\), with \\(a &lt; b\\). In Figure 1.2(a) we have that \\(P(a) \\neq P(b)\\), and note that the given curve intersects itself, that there exist \\(s\\) and \\(t \\in [a, b]\\) such that \\(P(s) = P(t)\\). If we have that \\(P(a) = P(b)\\) as we have in Figures 1.2(b) and  1.2(c), then \\(C\\) is called closed; if in addition to being closed, \\(C\\) being closed, if \\(C\\) does not intersect itself in anywhere other than \\(P(a) = P(b)\\), then it is said to be a simple closed curve. FIGURE 1.2: Examples of plane curve. Show/hide image source code %%Image (a) generated using \\LaTeX package tikz.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % puts the x axis in the middle axis y line=middle, % puts the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\tikzset{-&gt;-/.style={decoration={ markings, mark=at position 0.1 with {\\arrow{&gt;}}, mark=at position 0.3 with {\\arrow{&gt;}}, mark=at position 0.45 with {\\arrow{&gt;}}, mark=at position 0.55 with {\\arrow{&gt;}}, mark=at position 0.7 with {\\arrow{&gt;}}, mark=at position 0.9 with {\\arrow{&gt;}}}, postaction={decorate} } } \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-10,ymax=10, % grid=both, % adds gridlines ] \\addplot [-&gt;-, thick, domain=-2.25:2.25, samples=50, color=Cerulean] ({0.5*(x^3-3*x)},{3*x^2-9}); \\addplot[mark=*, color=Cerulean] coordinates {(2.32031,6.1875)}; \\addplot[mark=*, color=Cerulean] coordinates {(-2.32031,6.1875)}; \\addplot[mark=*, color=Cerulean] coordinates {(1,-6)}; \\end{axis} \\node at (0.9, 4.625) {${\\color{Cerulean}P(a)}$}; \\node at (5.95, 4.625) {${\\color{Cerulean}P(b)}$}; \\node at (4.75, 1.125) {${\\color{Cerulean}P(t)}$}; \\node[right] at (0, -0.75) {(a) Example of a plane curve.}; \\end{tikzpicture} \\end{preview} \\end{document} %%Image (b) generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % puts the x a xis in the middle axis y line=middle, % puts the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\tikzset{-&gt;-/.style={decoration={ markings, mark=at position 0.05 with {\\arrow{&gt;}}, mark=at position 0.2 with {\\arrow{&gt;}}, mark=at position 0.35 with {\\arrow{&gt;}}, mark=at position 0.475 with {\\arrow{&gt;}}, mark=at position 0.525 with {\\arrow{&gt;}}, mark=at position 0.65 with {\\arrow{&gt;}}, mark=at position 0.8 with {\\arrow{&gt;}}, mark=at position 0.95 with {\\arrow{&gt;}}, }, postaction={decorate} } } \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4, % grid=both, % adds gridlines ] \\addplot [-&gt;-, thick, domain=0:360, samples=500, color=Cerulean, variable=\\t] ({2*sin(t)}, {2*cos(3*t)}); \\addplot[mark=*, color=Cerulean] coordinates {(1.75,2)}; \\addplot[mark=*, color=Cerulean] coordinates {(-1.9125,1.5)}; \\end{axis} \\node at (4.9125, 4.55) {${\\color{Cerulean}P(a)=P(b)}$}; \\node at (1.25, 3.95) {${\\color{Cerulean}P(t)}$}; \\node[right] at (0, -0.75) {(b) Example of a closed plane curve.}; \\end{tikzpicture} \\end{preview} \\end{document} %%Image (c) generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % puts the x a xis in the middle axis y line=middle, % puts the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\tikzset{-&gt;-/.style={decoration={ markings, mark=at position 0.15 with {\\arrow{&gt;}}, mark=at position 0.3 with {\\arrow{&gt;}}, mark=at position 0.475 with {\\arrow{&gt;}}, mark=at position 0.6 with {\\arrow{&gt;}}, mark=at position 0.7 with {\\arrow{&gt;}}, mark=at position 0.9 with {\\arrow{&gt;}}}, postaction={decorate} } } \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4, % grid=both, % adds gridlines ] \\addplot [-&gt;-, thick, domain=0:360, samples=500, color=Cerulean, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot[mark=*, color=Cerulean] coordinates {(2.67441,1.05887)}; \\addplot[mark=*, color=Cerulean] coordinates {(-2.26261,1.75506)}; \\end{axis} \\node at (5.725, 3.95) {${\\color{Cerulean}P(a)=P(b)}$}; \\node at (0.95, 4.125) {${\\color{Cerulean}P(t)}$}; \\node[right] at (0, -0.75) {(c) Example of a simple closed plane curve.}; \\end{tikzpicture} \\end{preview} \\end{document} Letting \\(C\\) be a plane curve, as defined in Definition 1.12. The equations, \\[\\begin{align*} x = f(t) \\quad \\text{and} \\quad y = g(t), \\end{align*}\\] for \\(t \\in I\\), are parametric equations for \\(C\\) with parameter \\(t\\). When describing a curve \\(C\\)in this way, we say that \\(C\\) is a parametrised curve, and the parametric equations are a parametrisation for \\(C\\). In all three of our examples given in Figure 1.2, we have highlighted, by use of arrows, the direction in which \\(C\\) is traced‑out by \\(P\\) as \\(t\\) increases from \\(a\\) to \\(b\\). The orientation of a parametrised curve \\(C\\) is the direction determined by increasing the value of the parameter. Note, the orientation is a property of the parametrisation and not the plane curve. Indeed, a plane curve may have several different parametrisations. A plane curve \\(C\\) is called smooth, if it has a parametrisation \\[\\begin{align*} x = f(t) \\quad \\text{and} \\quad y = g(t), \\end{align*}\\] for \\(t \\in I\\), with \\(f\\) and \\(g\\) smooth and not simultaneously zero, except possibly at the end points of the domain \\(I\\) of the parameter \\(t\\). More generally, if the domain \\(I\\) can be partitioned into closed subintervals with \\(C\\) smooth on each subinterval, then we say that \\(C\\) is piecewise smooth. Note, a smooth plane curve has no corners or cusps, but a piecewise smooth plane curves may contain a finite number of corners or cusps. "],["sequencesseriesfoundations.html", "1.8 Sequences and series", " 1.8 Sequences and series Sequences Sequences are fundamental to the study of infinite series and many applications of mathematics. A sequence is an enumerated collection of objects in which repetitions are allowed and where order is important. Like a set, it contains members (also called elements, or terms). We will often denote a sequence of by \\[\\begin{align*} (a_{1}, a_{2}, a_{3}, \\dots ) \\quad \\text{or} \\quad (a_{n})_{n = 1}^{\\infty}. \\end{align*}\\] An important property of a sequence is if it converges or diverges. Definition 1.13 (convergent and divergent sequences) A sequence \\(( a_{n} )_{n = 1}^{\\infty}\\) or real numbers is said to converge to \\(L \\in \\mathbb{R}\\) if for every positive number \\(\\epsilon\\) there exists a corresponding integer \\(M\\) such that \\(\\lvert a_{n} - L \\rvert &lt; \\epsilon\\) for all \\(n \\geq M\\). If no such number \\(L\\) exists, then we say that the sequence \\(( a_{n} )_{n = 1}^{\\infty}\\) is divergent. If the infinite sequence \\(( a_{n} )_{n = 1}^{\\infty}\\) converges to \\(L\\), then we call \\(L\\) the limit of the sequence and write \\(\\lim_{n \\to \\infty} a_{n} = L\\). One important fact to remember is that if an infinite sequence is convergent, the value of its limit is unique. Further, sums, differences and products of convergent sequences are again convergent sequences. Formally, if \\((a_{n})_{n = 1}^{\\infty}\\) and \\((b_{n})_{n = 1}^{\\infty}\\) denote two convergent sequences with respective limits \\(\\alpha\\) and \\(\\beta\\), then \\(\\displaystyle \\lim_{n \\to \\infty} (a_{n} + b_{n}) = \\left( \\lim_{n \\to \\infty} a_{n} \\right) + \\left( \\lim_{n \\to \\infty} b_{n} \\right) = \\alpha + \\beta\\), \\(\\displaystyle \\lim_{n \\to \\infty} (a_{n} - b_{n}) = \\left( \\lim_{n \\to \\infty} a_{n} \\right) - \\left( \\lim_{n \\to \\infty} b_{n} \\right) = \\alpha - \\beta\\), \\(\\displaystyle \\lim_{n \\to \\infty} a_{n} b_{n} = \\left( \\lim_{n \\to \\infty} a_{n} \\right) \\left( \\lim_{n \\to \\infty} b_{n} \\right) = \\alpha \\beta\\). Examples of convergent sequences include \\[\\begin{align*} (1/n)_{n=1}^{\\infty}, \\quad (\\sin(1/n))_{n=1}^{\\infty} \\quad \\text{and} \\quad (1- \\pi/n)^{n}, \\end{align*}\\] and examples of divergent sequences include \\[\\begin{align*} ((-1)^{n})_{n=1}^{\\infty}, \\quad (\\cos(n\\pi))_{n=1}^{\\infty} \\quad \\text{and} \\quad (n^{1/2})_{n=1}^{\\infty}. \\end{align*}\\] Although all three of the above sequences diverge, the last one diverges for different reasons to the first two, and in fact belongs to a class of sequences which diverge to infinity. Definition 1.14 (diverging to infinity) A sequence \\((a_{n})_{n = 1}^{\\infty}\\) diverges to infinity if for every real number \\(M\\), there is an integer \\(K\\) such that \\(a_{n} &gt; M\\) for all \\(n \\geq K\\). If this condition holds, then we write \\(\\lim_{n \\to \\infty} a_{n} = \\infty\\). Similarly, a sequence \\((a_{n})_{n = N}^{\\infty}\\) diverges to negative infinity if for every real number \\(M\\), there is an integer \\(K\\) such that \\(a_{n} &lt; M\\) for all \\(n \\geq K\\). If this condition holds, then we write \\(\\lim_{n \\to \\infty} a_{n} = -\\infty\\). Two other types of sequences which play an important role in calculus are bounded and monotonic sequences. Note a sequence can be bounded but not convergent, monotonic but not convergent, convergent but not monotonic. However, a convergent sequence is always bounded. Definition 1.15 (bounded and monotonic sequences) Let \\((a_{n})_{n = 1}^{\\infty}\\) denote a sequence of real numbers. If there exists a real number \\(M\\) such that \\(a_{n} \\leq M\\) for all integers \\(n \\geq N\\), then \\((a_{n})_{n = 1}^{\\infty}\\) is said to be bounded from above and \\(M\\) is called an upper bound of \\((a_{n})_{n = 1}^{\\infty}\\). If \\(M\\) is an upper bound for \\((a_{n})_{n = 1}^{\\infty}\\), but no number less than \\(M\\) is an upper bound for \\((a_{n})_{n = 1}^{\\infty}\\), then \\(M\\) is called the least upper bound of \\((a_{n})_{n = 1}^{\\infty}\\). If there exists a real number \\(m\\) such that \\(a_{n} \\geq m\\) for all integers \\(n \\geq N\\), then \\((a_{n})_{n = 1}^{\\infty}\\) is said to be bounded from below and \\(m\\) is called a lower bound of \\((a_{n})_{n = 1}^{\\infty}\\). If \\(m\\) is a lower bound, but no number greater than \\(m\\) is a lower bound of \\((a_{n})_{n = 1}^{\\infty}\\), then \\(m\\) is called the greatest lower bound of \\((a_{n})_{n = 1}^{\\infty}\\). If \\((a_{n})_{n = 1}^{\\infty}\\) is bounded from above and bounded from below, then \\((a_{n})_{n = 1}^{\\infty}\\) is said to be bounded. If a sequence is not bounded, then it called unbounded. If \\(a_{n} \\geq a_{n + 1}\\) for all \\(n \\in \\mathbb{N}\\) beyond some index \\(M \\in \\mathbb{N}\\), then \\((a_{n})_{n = 1}^{\\infty}\\) is called eventually non‑increasing. If \\(a_{n} \\leq a_{n + 1}\\) for all \\(n \\in \\mathbb{N}\\) beyond some index \\(M \\in \\mathbb{N}\\), then \\((a_{n})_{n = 1}^{\\infty}\\) is called eventually non‑decreasing. If \\((a_{n})_{n = 1}^{\\infty}\\) is eventually non‑increasing or eventually non‑decreasing, then \\(A\\) is called eventually monotonic. Three useful results to determine when a sequence is convergent are the sandwich theorem, the bounded monotonic sequence theorem and the continuous function theorem. Theorem 1.8 (sandwich theorem) Let \\((a_{n})_{n = 1}^{\\infty}\\), \\((b_{n})_{n = 1}^{\\infty}\\), and \\(( c_{n} )_{n = 1}^{\\infty}\\) denote three sequences of real numbers. If \\(a_{n} \\leq b_{n} \\leq c_{n}\\) for all \\(n \\in \\mathbb{N}\\) beyond some index \\(M \\in \\mathbb{N}\\), and if \\(\\lim_{n \\to \\infty} a_{n} = \\lim_{n \\to \\infty} c_{n} = L\\), for some \\(L \\in \\mathbb{R}\\), then \\(\\lim_{n \\to \\infty} b_{n} = L\\). Theorem 1.9 (bounded monotonic sequence theorem) If a sequence is either eventually non‑increasing and bounded from below, or eventually non‑decreasing and bounded from above, then the sequence is convergent. Theorem 1.10 (continuous function theorem) If \\((a_{n})_{n = 1}^{\\infty}\\) denotes a convergent sequence of real numbers with limit \\(L\\) and if \\(f\\) is a continuous function defined on a non-empty open interval containing \\(L\\) and the set \\(\\{ a_{n} \\, \\colon \\, n \\in \\mathbb{N}\\}\\), then \\((f(a_{n}))_{n = 1}^{\\infty}\\) is a convergent sequence with limit \\(f(L)\\). Series A series is the sum of a sequence \\((a_{n})_{n=1}^{\\infty}\\) of real numbers: \\[\\begin{align*} \\sum_{n = 1}^{\\infty} a_{n} = a_{1} + a_{2} + a_{3} + \\dots \\end{align*}\\] For \\(n \\in \\mathbb{N}\\), the value \\(a_{n}\\) is called the \\(n\\)-th term of the series, and the sequence \\((s_{n})_{n = N}^{\\infty}\\), determined by \\(s_{n} = a_{1} + a_{2} + \\dots + a_{n}\\) for \\(n \\in \\mathbb{N}\\), is called the sequence of partial sums with \\(s_{n}\\) often referred to as the \\(n\\)-th partial sum. If the sequence \\((s_{n})_{n = N}^{\\infty}\\) of partial sums converges to a limit \\(L\\), then we write \\[\\begin{align*} \\sum_{n = 1}^{\\infty} a_{n} = L, \\end{align*}\\] and say that the series converges with sum is equal to \\(L\\). On the other hand, if the sequence of partial sums \\((s_{n})_{n = N}^{\\infty}\\) diverges, then we say that the series diverges. If \\(\\sum_{n = 1}^{\\infty} a_{n}\\) and \\(\\sum_{n = N}^{\\infty} b_{n}\\) are two convergent series with sums \\(\\alpha\\) and \\(\\beta\\), respectively, then the infinite series \\[\\begin{align} \\sum_{n = 1}^{\\infty} (a_{n} + b_{n}) \\tag{1.1} \\end{align}\\] converges with sum equal to \\(\\alpha + \\beta\\). On the other hand, if one of our initial two series was divergent and the other was convergent, then the series given in (1.1) would diverge. Here, we have defined a series to be indexed over the natural numbers, however, a series may be index over any totally ordered countable set. There are several other useful tests to determine if a series is convergent or divergent, for instance, the \\(n\\)-th term test, the integral test, the comparison and limit comparison test, the ratio and root test and Leibniz’s test. Below we give a brief discussion of each of these tests. \\(n\\)-th term test If \\(( a_{n} )_{n = 1}^{\\infty}\\) denotes a sequence of real numbers and if \\(\\lim_{n \\to \\infty} a_{n}\\) fails to exists or is different from zero, then \\(\\sum_{n = 1}^{\\infty} a_{n}\\) is a divergent series. Integral test If \\(( a_{n} )_{n = 1}^{\\infty}\\) denote a sequence of real numbers such that there exists a continuous eventually non‑increasing non‑negative function \\(f \\, \\colon \\, [1, \\infty) \\to \\mathbb{R}\\) with \\(f(n) = a_{n}\\) for all \\(n \\in \\mathbb{N}\\), then either \\(\\sum_{n = N}^{\\infty} a_{n}\\) and \\(\\int_{M}^{\\infty} f(x) \\, \\mathrm{d}x\\) both converge or both diverge. Comparison test Let \\(( a_{n} )_{n = 1}^{\\infty}\\) and \\((b_{n})_{n=1}^{\\infty}\\) denote two sequences of non‑negative real numbers with \\(a_{n} \\leq b_{n}\\) for all \\(n \\in \\mathbb{N}\\). If \\(\\sum_{n = 1}^{\\infty} a_{n}\\) diverges, then \\(\\sum_{n = 1}^{\\infty} b_{n}\\) diverge, and if \\(\\sum_{n = 1}^{\\infty} b_{n}\\) converges, then \\(\\sum_{n = N}^{\\infty} a_{n}\\) converge. Limit comparison test Let \\((a_{n})_{n = 1}^{\\infty}\\) and \\((b_{n})_{n = N}^{\\infty}\\) denote two sequences of positive real numbers. If \\(\\lim_{n \\to \\infty} a_{n}/b_{n}\\) exists and is non‑zero, then either \\(\\sum_{n = N}^{\\infty} a_{n}\\) and \\(\\sum_{n = N}^{\\infty} b_{n}\\) both converge or both diverge. Ratio test Let \\(( a_{n} )_{n = 1}^{\\infty}\\) denote a sequence of positive real numbers with \\(\\lim_{n \\to \\infty} a_{n+1}/a_{n} = p\\), for some \\(p \\in \\mathbb{R}\\). If \\(p &lt; 1\\), then the series \\(\\sum_{n = 1}^{\\infty} a_{n}\\) converges, and if \\(p &gt; 1\\) or if \\(p = \\infty\\), then the series \\(\\sum_{n = 1}^{\\infty} a_{n}\\) diverges. Root test Let \\(( a_{n} )_{n = 1}^{\\infty}\\) denote a sequence of non‑negative real numbers with \\(\\lim_{n \\to \\infty} \\sqrt[n]{a_{n}} = p\\), for some \\(p \\in \\mathbb{R}\\). If \\(p &lt; 1\\), then the series \\(\\sum_{n = 1}^{\\infty} a_{n}\\) converges, and if \\(p &gt; 1\\) or if \\(p = \\infty\\), then the series \\(\\sum_{n = 1}^{\\infty} a_{n}\\) diverges. Leibniz’s testThe series \\(\\sum_{n = N}^{\\infty} (-1)^{n} u_{n}\\) converges if \\((u_{n})_{n = N}^{\\infty}\\) is bounded below by zero and eventually non‑increasing and \\(\\lim_{n \\to \\infty} u_{n} = 0\\). The series to which Leibniz’s test applies is often referred to as an alternating series. A stronger notion of convergence for such series is that of absolutely convergent. A series \\(\\sum_{n = 1}^{\\infty} a_{n}\\) is said to be absolutely convergent if the series \\(\\sum_{n = 1}^{\\infty} \\lvert a_{n} \\rvert\\) is convergent. As the name suggests, if a series is absolutely convergent then it is convergent. However, the converse is not true. Indeed, we call a series which converges but does not converge absolutely conditionally convergent. Let us conclude this section with a collection of well‑known series. A geometric series is a series of the form \\(\\sum_{n = 0}^{\\infty} a r^{n}\\), where \\(a\\) and \\(r\\) are fixed real numbers. The series converges if and only if the absolute value of the ratio \\(r\\) is strictly less than \\(1\\), in which case the sum of the series is \\(a/1-r\\). This is sometime referred to as the geometric series identity. A \\(p\\)-series is a series of the form \\(\\sum_{n = 0}^{\\infty} n^{-p}\\), where \\(p\\) is a fixed real numbers. The series converges if and only if \\(p \\in (0, 1)\\). If \\(p=1\\), then the series \\(\\sum_{n = 0}^{\\infty} n\\) is also known as the harmonic series. A power series is a series of the form \\(\\sum_{n = 0}^{\\infty} c_{n} (x - a)^{n}\\), where \\(x\\) is a variable, \\(a\\) is a constant, and \\((c_{n})_{n = 1}^{\\infty}\\) is a sequence of real numbers. By convention, if \\(x = a\\), then we set \\((x-a)^0 = 1\\). The radius of convergence of a power series is the non‑negative real number \\(R\\) such that for \\(x\\) with \\(\\lvert x - a \\rvert &lt; R\\) the series converges, and for all \\(x\\) with \\(\\lvert x - a \\rvert &gt; R\\) the series diverges. A trigonometric series is a series of the form \\(\\sum_{n = 0}^{\\infty} a_{n} \\cos(nx) +b_{n} \\sin(nx)\\), where \\(x\\) is a variable, and\\((a_{n})_{n = 0}^{\\infty}\\) and \\((b_{n})_{n=0}^{\\infty}\\) are sequences of real numbers. "],["taylorandfourierseriesfoundations.html", "1.9 Taylor and Fourier series", " 1.9 Taylor and Fourier series Taylor series (part I) A Taylor series is a representation of a function as a power series whose terms are derived from the values of the function’s derivatives at an initial point – referred to as the series centre. The concept of a Taylor series was developed by James Gregory and formally introduced by Brook Taylor in 1715. If the Taylor series is centred at zero, then the series is also sometimes referred to a Maclaurin series, named after Colin Maclaurin, who made extensive use of this special case of Taylor series to characterise maxima, minima, and points of inflection for infinitely differentiable functions. If \\(f\\) is a function that can be approximated by using a finite number of terms of its Taylor series, then Taylor’s theorem gives quantitative estimates on the error of the approximation. The polynomial formed by taking some initial terms of the Taylor series of \\(f\\) is called a Taylor polynomial of \\(f\\). Note, a function may not be equal to its Taylor series, even if its Taylor series converges at every point. An example of such a function is \\(g \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by, \\[\\begin{align*} g(x) = \\begin{cases} \\mathrm{e}^{-1/x} &amp; \\text{if} \\; x &gt; 0,\\\\[0.5em] 0 &amp; \\text{otherwise}, \\end{cases} \\end{align*}\\] since \\(g^{(n)}(0) = 0\\), for all \\(n \\in \\mathbb{N}\\), and so the Taylor series generated by \\(f\\) centred at zero, sums to zero, independent of \\(x\\). On the other hand, if a function is equal to its Taylor series, then it called an analytic function. Definition 1.16 (Taylor series) Suppose that \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is infinitely differentiable on a non-empty open interval \\(I\\) and let \\(a \\in I\\). The Taylor series generated by \\(f\\) and centered at \\(a\\) is the power series \\[\\begin{align*} f(a)+\\sum_{n=1}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^{n}. \\end{align*}\\] For \\(n \\in \\mathbb{N}\\) the Taylor polynomial of order \\(n\\) generated by \\(f\\) and centered at \\(a\\) is the polynomial \\[\\begin{align*} P_{n}(x) = f(a) + f^{(1)}(a)(x - a) + \\frac{f^{(2)}(a)}{2!}(x - a)^{2} + \\dots + \\frac{f^{(n)}(a)}{n!}(x - a)^{n}. \\end{align*}\\] Theorem 1.11 (Taylor’s remainder theorem) Assuming the setting of Definition 1.16, for a fixed \\(n \\in \\mathbb{N}\\), we have that \\(f(x) = P_{n}(x) + R_{n}(x)\\), where \\[\\begin{align*} R_{n}(x) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{f^{(n+1)}(c)}{(n+1)!} (x - a)^{n+1}, \\end{align*}\\] for some real number \\(c\\) between \\(a\\) and \\(x\\). If \\(\\lim_{n \\to \\infty} \\lvert R_{n}(x) \\rvert = 0\\), for all \\(x \\in I\\), then the Taylor series generated by \\(f\\) and centered at \\(a\\) converges to \\(f\\) on \\(I\\) and, for all \\(x \\in I\\), \\[\\begin{align*} f(x) = f(a) + \\sum_{k = 1}^{\\infty} \\frac{f^{(k)}(a)}{k!} (x - a)^{k}. \\end{align*}\\] Note, if the Taylor series generated by a function \\(f\\) converges to \\(f\\), then any power series expansion of \\(f\\) has the same coefficients as the Taylor series of \\(f\\). Fourier series A function \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is said to be periodic with period \\(p\\) if \\(f(x+p) = f(x)\\) for all \\(x \\in \\mathbb{R}\\), and \\(p\\) is the minimal positive real number for which this is satisfied. Without loss of generality, here we consider functions with period \\(2\\pi\\), since we can always revert back to period \\(p\\) by studying \\(f(x)=g(xp/2\\pi)\\), where \\(g\\) is a function with period \\(2\\pi\\). Further, if \\(f \\, \\colon \\, (0, p) \\to \\mathbb{R}\\) is an arbitrary function, then \\(f\\) can be extended to a periodic function \\(F \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) by defining \\[\\begin{align*} F(x)= \\begin{cases} f(x) &amp;\\text{if $x\\in(0, p)$,}\\\\[0.25em] f(x-kp) &amp;\\text{if $x\\in(kp,(k+1)p)$, for some $k\\in\\mathbb{Z}$,}\\\\[0.25em] c &amp;\\text{if $x=kp$, for some $k\\in\\mathbb{Z}$,} \\end{cases} \\end{align*}\\] where \\(c \\in \\mathbb{R}\\) is a fixed constant. Expressing a function \\(f\\) as a power series is often useful and even vital in helping us analyse its properties. However, polynomials are not periodic and if the function we want to analyse is periodic (for instance if it represents a heart beat, brain waves, nerve signals, or signals from pulsars) it might be more useful to be able to split up \\(f\\) into simpler periodic functions associated to certain wavelengths, and as such study a trigonometric series expansion of \\(f\\). To this end suppose that \\(f\\) is a bounded, \\(2 \\pi\\)-periodic, piecewise continuous function and that \\[\\begin{align*} f(x) = \\frac{a_{0}}{2} + \\sum_{k = 1}^{\\infty} a_{k} \\cos(kx) +b_{k} \\sin(kx), \\end{align*}\\] where \\((a_{k})_{k = 0}^{\\infty}\\) and \\((b_{k})_{k=1}^{\\infty}\\) are two sequences of real numbers. In this case, how should \\(a_{k}\\) and \\(b_{k}\\) be chosen? In order to determine these coefficients, observe that, for \\(n\\) a non-negative integer, \\[\\begin{align*} \\int_{-\\pi}^{\\pi} \\! f(x)\\cos(nx) \\, \\mathrm{d}x &amp;= \\int_{-\\pi}^{\\pi} \\left( \\frac{a_0}{2} + \\sum_{k = 1}^{\\infty} a_{k} \\cos(kx) +b_{k}\\sin(kx) \\right) \\cos(nx) \\, \\mathrm{d}x\\\\[0.25em] &amp;= \\int_{-\\pi}^{\\pi} \\frac{a_0}{2} \\cos(nx) \\, \\mathrm{d}x + \\sum_{k = 1}^{\\infty} \\int_{-\\pi}^{\\pi} a_{k} \\cos(kx) \\cos(nx) \\, \\mathrm{d}x + \\int_{-\\pi}^{\\pi} b_{k} \\sin(kx) \\cos(nx) \\, \\mathrm{d}x = \\pi a_n, \\end{align*}\\] and for \\(n\\) a natural number, \\[\\begin{align*} \\int_{-\\pi}^{\\pi} f(x)\\sin(nx) \\, \\mathrm{d}x &amp;= \\int_{-\\pi}^{\\pi} \\left( \\frac{a_0}{2} + \\sum_{k = 1}^{\\infty} a_{k} \\cos(kx) +b_{k}\\sin(kx) \\right) \\sin(nx) \\, \\mathrm{d}x\\\\[0.25em] &amp;= \\int_{-\\pi}^{\\pi} \\frac{a_0}{2} \\sin(nx) \\, \\mathrm{d}x + \\sum_{k = 1}^{\\infty} \\int_{-\\pi}^{\\pi} a_{k} \\cos(kx) \\sin(nx) \\, \\mathrm{d}x + \\int_{-\\pi}^{\\pi} b_{k} \\sin(kx) \\sin(nx) \\, \\mathrm{d}x = \\pi b_n. \\end{align*}\\] This leads us to the following definition. Definition 1.17 (Fourier series) Suppose that \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is a bounded, \\(2\\pi\\)-periodic, piecewise continuous function. The Fourier series of \\(f\\) is the trigonometric series \\[\\begin{align*} \\frac{a_0}{2} + \\sum_{k = 1}^{\\infty} a_{k} \\cos(kx) + b_{n}\\sin(kx), \\end{align*}\\] where \\(\\displaystyle a_{0} = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x) \\, \\mathrm{d}x\\) and, for \\(k \\in \\mathbb{N}\\), \\[\\begin{align*} a_{k} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac {1}{\\pi} \\int_{-\\pi}^{\\pi} f(x) \\cos(kx) \\, \\mathrm{d}x \\quad \\text{and}\\quad b_{k} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x) \\sin(kx) \\, \\mathrm{d}x. \\end{align*}\\] The coefficients \\(a_{k}\\) are called the \\(k\\)-th cosine Fourier coefficients of \\(f\\), and the coefficients \\(b_{k}\\) are called the \\(k\\)-th sine Fourier coefficients of \\(f\\). The Fourier series of a bounded, \\(2 \\pi\\)-periodic, piecewise continuous function \\(f\\) may not converge to \\(f\\), for instance the Fourier series of the \\(2\\pi\\)-periodic Heaviside step function \\[\\begin{align*} h(x) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\begin{cases} \\hphantom{-}1 &amp; \\text{if} \\; x \\in [2n\\pi, (2n+1)\\pi) \\; \\text{for some} \\; n \\in \\mathbb{Z},\\\\[0.25em] -1 &amp; \\text{if} \\; x \\in [(2n-1)\\pi, 2n\\pi) \\; \\text{for some} \\; n \\in \\mathbb{Z}, \\end{cases} \\end{align*}\\] does not converge to \\(h\\). On the other hand, if \\(f\\) is equal to it’s Fourier series, then we necessarily have that \\[\\begin{align*} \\int_{-\\pi}^{\\pi} f(x) \\cos(nx) \\, \\mathrm{d}x = a_{n} \\pi \\quad \\text{and} \\quad \\int_{-\\pi}^{\\pi} f(x) \\sin(nx) \\, \\mathrm{d}x = b_{n} \\pi. \\end{align*}\\] In other words, if the Fourier series converges of a bounded, \\(2 \\pi\\)-periodic, piecewise continuous function \\(f\\) converges to \\(f\\), then any trigonometric series expansion of \\(f\\) has the same coefficients as the Fourier series of \\(f\\). With the above at hand, it is natural to ask the question when does the Fourier series of a bounded, \\(2 \\pi\\)-periodic, piecewise continuous function \\(f\\) converge \\(f\\)? An answer to this question is given in Dini’s theorem. Theorem 1.12 (Dini's theorem) If \\(f \\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is a bounded, \\(2 \\pi\\)-periodic, piecewise smooth function, then the Fourier series of \\(f\\) is convergent at all \\(x \\in \\mathbb{R}\\) and \\[\\begin{align*} \\frac{a_{0}}{2} + \\sum_{k = 1}^{\\infty} a_{k} \\cos(kx) + b_{k} \\sin(kx) = \\begin{cases} f(x) &amp; \\text{if} \\; f \\; \\text{is continuous at} \\; x,\\\\[0.25em] \\left( f(x^{-}) + f(x^{+}) \\right)/2 &amp; \\text{if} \\; f \\; \\text{is discontinuous at} \\; x. \\end{cases} \\end{align*}\\] In particular, if \\(f\\) is continuous at \\(x\\), then its Fourier series at \\(x\\) converges to \\(f(x)\\). "],["practiceproblemschapterone.html", "Practice problems - Chapter 1", " Practice problems - Chapter 1 Exercise 1.1 Find and classify the stationary points of the following functions. The function \\(f \\, \\colon \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x) = x^{3} - 3x^{2} + 2x\\) The function \\(g \\colon \\mathbb{R} \\to \\mathbb{R}\\) given by \\(g(x) = 5x^{3} - 3x^{5}\\) The function \\(h \\colon \\mathbb{R} \\to \\mathbb{R}\\) given by \\(h(x) = (x^2 + x - 1)/(x^{2} + 1)\\) Show/hide solution Solution (part a). If \\(x\\) is a stationary point of \\(f\\), then \\(f&#39;(x) = 0\\), which in this case is when \\(3x^{2} - 6x + 2 = 0\\). Solutions to this equation are \\(x = 1 - 1/\\sqrt{3}\\) and \\(x = 1 + 1/\\sqrt{3}\\). By the second derivative test, since \\(f&#39;&#39;(x) = 6x - 6\\) is negative at \\(x = 1 - 1/\\sqrt{3}\\), we have a local maximum at \\(x = 1 - 1/\\sqrt{3}\\), and since \\(f&#39;&#39;(x)\\) is positive at \\(x=1+1/\\sqrt3\\), we have a local minimum at \\(x=1+1/\\sqrt3\\). Since \\(f\\) is a polynomial, it is continuous, and since \\[\\begin{align*} \\lim_{x \\to \\infty} f(x) = \\infty \\quad \\text{and} \\quad \\lim_{x \\to -\\infty} f(x) = -\\infty, \\end{align*}\\] we have that neither \\(x = 1 - 1/\\sqrt{3}\\) nor \\(x = 1 + 1/\\sqrt{3}\\) are global extrema. Solution (part b). If \\(x\\) is a stationary point, then \\(g&#39;(x) = 0\\), which in this case is when \\(15x^{2} - 15x^{4} = 0\\), or equivalently, if \\(x^{2}(1 - x^{2}) = 0\\). Solutions to this equation are \\(x= -1\\), \\(x = 0\\) and \\(x = 1\\). By the second derivative test, since \\(g&#39;&#39;(x) = 30x - 60x^{3}\\), at \\(x = -1\\), we have \\(g&#39;&#39;(x) = 30 &gt; 0\\), and so \\(x = -1\\) is a local minimum; at \\(x=1\\), we have \\(g&#39;&#39;(x) = -30 &lt; 0\\), and so \\(x = 1\\) is a local maximum; at \\(x=0\\) we have \\(g&#39;&#39;(x) = 0\\), and so the second derivative test is inconclusive. Let us examine this latter case more closely. Observe that \\[\\begin{align*} \\lim_{\\epsilon \\to 0} \\frac{g(\\epsilon)}{5\\epsilon^{3}} = \\lim_{\\epsilon \\to 0} \\frac{5\\epsilon^{3} - 3\\epsilon^{5}}{5\\epsilon^{3}} = 1. \\end{align*}\\] Therefore, if \\(\\epsilon\\) is arbitrarily small and positive, then \\(g(\\epsilon) &gt; 0\\) since \\(5\\epsilon^{3} &gt; 0\\), and so \\(g(\\epsilon) &gt; 0 = g(0)\\). Similarly, if \\(\\epsilon\\) is arbitrarily small and negative, then \\(g(\\epsilon) &lt; 0\\) since \\(5\\epsilon^{3} &lt; 0\\), and so \\(g(\\epsilon) &lt; 0 = g(0)\\). This implies that \\(x=0\\) is a saddle point. Since, \\(g\\) is a polynomial, it is continuous, and since \\[\\begin{align*} \\lim_{x \\to \\infty} g(x) = -\\infty \\quad \\text{and} \\quad \\lim_{x \\to -\\infty} g(x) = \\infty, \\end{align*}\\] neither \\(x = -1\\), \\(x = 0\\) nor \\(x = 1\\) are global extrema. Solution (part c). If \\(x\\) is a stationary points, then \\(h&#39;(x) = 0\\). By the quotient rule, \\[\\begin{align*} h&#39;(x) = \\frac{(2x+1)(x^{2}+1) - (x^{2} + x - 1)(2x)}{(x^{2} + 1)^{2}}=\\frac{-x^{2} + 4x + 1}{(x^{2} + 1)^{2}} \\end{align*}\\] Thus, \\(x\\) is a stationary point if \\(-x^{2} + 4x + 1 = 0\\). Solutions to this equation are \\(x = 2 - \\sqrt{5}\\) and \\(x = 2 + \\sqrt{5}\\). Observing that the graph of \\(y = -x^{2} + 4x + 1\\) is a parabola, a quick sketch shows that \\(x = 2 - \\sqrt{5}\\) is a local minimum and \\(x = 2 + \\sqrt{5}\\) is a local maximum, see Figures 1.3. Note you could use the second derivative test here but \\(h&#39;&#39;\\) is not easy to work with. FIGURE 1.3: Sketch of the graph of \\(y = -x^{2}+4*x+1\\). Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % put the x a xis in the middle axis y line=middle, % put the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis xtick = {-2,2,4}, ytick = {-6,-3,3,6} %add tickmarks }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\begin{axis}[ xmin=-2.25,xmax=6, ymin=-8,ymax=8, % grid=both, % adds gridlines ] \\addplot [thick, domain=-1.5:5.5, samples=500, color=Cerulean, variable=\\t] ({t}, {-t*t + 4*t + 1}); \\end{axis} \\node at (4.75, 0.5) {${\\color{Cerulean}y = -x^2+4x+1}$}; \\end{tikzpicture} \\end{preview} \\end{document} Exercise 1.2 Determine the order four Taylor polynomials centered at zero and generated the following functions. The function \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x) =\\sin(2x)\\) The function \\(g \\, \\colon \\, (-1/2, 1/2) \\to \\mathbb{R}\\) given by \\(g(x)= 1/(1+2x)\\) The function \\(h \\, \\colon \\, (-2, 2) \\to \\mathbb{R}\\) given by \\(h(x) = 1/(2+x)\\) The function \\(k \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(k(x)=\\mathrm{e}^{2x}\\cos(x)\\) The function \\(q \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(q(x)= 2/(2-\\sin(x))\\) Exercise 1.3 Write down Taylor series centered at zero and generated by the following functions. The function \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=\\mathrm{e}^x\\) The function \\(g \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(g(x)=\\sin(x)\\) The function \\(h \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(h(x)=\\cos(x)\\) The function \\(k \\, \\colon \\, (-1, 1) \\to \\mathbb{R}\\) given by \\(k(x)=1/(1-x)\\) The function \\(r \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(r(x)=x^2+x+1\\) Show/hide solution Solution (part a). If \\(f \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is given by \\(f(x,y)=\\mathrm{e}^{x}\\), then the Taylor series generate by \\(f\\) centered at zero is \\[\\begin{align*} 1+x+\\frac{x^2}{2!}+\\dots+\\frac{x^n}{n!}+\\dots =\\sum_{n\\geq0}\\frac{x^{n}}{n!}. \\end{align*}\\] Solution (part b). If \\(g \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is given by \\(g(x)=\\sin(x)\\), then the Taylor series generate by \\(f\\) centered at zero is \\[\\begin{align*} x-\\frac{x^3}{3!}+\\frac{x^5}{5!}+\\dots+ (-1)^n\\frac{x^{2n+1}}{(2n+1)!} +\\dots =\\sum_{n\\geq0}\\frac{(-1)^nx^{2n+1}}{(2n+1)!} \\end{align*}\\] Solution (part c). If \\(h \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) is given by \\(h(x)=\\cos(x)\\), then the Taylor series generate by \\(f\\) centered at zero is \\[\\begin{align*} 1-\\frac{x^2}{2!}+\\frac{x^4}{4!}+\\dots+(-1)^n\\frac{x^{2n}}{(2n)!}+\\dots =\\sum_{n\\geq0}\\frac{(-1)^nx^{2n}}{(2n)!} \\end{align*}\\] Solution (part d). If \\(k \\, \\colon \\, (-1, 1) \\to \\mathbb{R}\\) is given by \\(k(x) = 1/(1-x)\\), then the Taylor series generate by \\(k\\) centered at zero is \\[\\begin{align*} 1+ x+x^2+\\dots+x^n+\\dots =\\sum_{n\\geq0} x^n \\end{align*}\\] Solution (part e). If \\(r \\, \\colon \\, (-1, 1) \\to \\mathbb{R}\\) is given by \\(r(x) = x^2+x+1\\), then the Taylor series generate by \\(r\\) centered at zero is \\(x^2+x+1\\). Exercise 1.4 Find the Taylor series generated by the following functions and centered at the given point \\(c\\). The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=\\mathrm{e}^x\\) and the point \\(c=-1\\) The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=\\mathrm{e}^x\\) and the point \\(c=-3\\) The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=x^2+x+1\\) and the point \\(c=-1\\) The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=x^3 + 3x + 2\\) and the point \\(c=3\\) The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=\\sin(x)\\) and the point \\(c=\\pi/2\\) The function \\(f\\,\\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) given by \\(f(x)=\\sin(x)\\) and the point \\(c=-\\pi\\) Exercise 1.5 Consider the following statement. Let \\(f \\colon \\mathbb{R} \\to \\mathbb{R}\\) be the \\(2\\pi\\)-periodic function, which for \\(x \\in [-\\pi, \\pi)\\) is given by \\[\\begin{align*} f(x) = \\begin{cases} \\hphantom{-}1 &amp; \\text{if} \\; x \\in [0, \\pi),\\\\ -1 &amp; \\text{if} \\; x \\in [-\\pi, 0). \\end{cases} \\end{align*}\\] The Fourier series of \\(f\\) converges pointwise to \\(f\\). Determine if the statement is true or false, giving a brief justification for your answer. Show/hide solution Solution. Since \\(f(x) \\in \\{-1, 1\\}\\), for all \\(x \\in \\mathbb{R}\\), we have that \\(-1 \\leq f(x) \\leq 1\\), for all \\(x \\in \\mathbb{R}\\), and thus \\(f\\) is a bounded function. Further, by definition \\(f\\) is a \\(2\\pi\\)-periodic function, and since \\(f\\) is piecewise constant, and since a piecewise constant implies piecewise smooth, \\(f\\) is piecewise smooth. Therefore, the hypotheses of Dini’s Theorem are satisfied. Thus, the Fourier series of \\(f\\) at \\(x = 0\\) converges to \\[\\begin{align*} \\frac{f(0^{+}) + f(0^{-})}{2} = \\frac{(\\lim_{x \\to 0^{+}} f(x)) + (\\lim_{x \\to 0^{-}} f(x))}{2} = \\frac{(\\lim_{x \\to 0^{+}} 1) + (\\lim_{x \\to 0^{-}} -1)}{2} = \\frac{1+ -1}{2} = 0. \\end{align*}\\] As \\(f(0) = 1 \\neq 0\\), the Fourier series of \\(f\\) does not converge pointwise to \\(f\\), and hence the statement is false. "],["functions-of-several-variables.html", "Chapter 2 Functions of several variables", " Chapter 2 Functions of several variables Many quantities can be regarded as depending on more than one variable and thus to be functions of several variables. For example, the volume of circular cylinder of radius \\(r\\) and height \\(h\\) is given by \\(V = \\pi r^{2} h\\); in this case we say that \\(V\\) is a function of the two variables \\(r\\) and \\(h\\). If we choose to denote this function by \\(f\\), then we would write \\(V = f(r, h)\\) where \\(f \\, \\colon \\, \\{ (r, h) \\in \\mathbb{R}^{2} \\,\\colon \\, r &gt; 0 \\; \\text{and } \\; h&gt;0 \\} \\to \\mathbb{R}\\) is defined by \\(f(r, h) = \\pi r^{2}h\\) for \\(r &gt; 0\\) and \\(h &gt; 0\\). Definition 2.1 (function of several variables) Let \\(n \\geq 2\\) denote a natural number. A function \\(f\\) whose domain is a non-empty subset of \\(\\mathbb{R}^{n}\\) and whose codomain is a non-empty subset of \\(\\mathbb{R}\\) is called a function of several variables. Here, we will be mostly concerned with functions whose domain is a non-empty subset of \\(\\mathbb{R}^2\\) or \\(\\mathbb{R}^3\\). However, most of what we state will, in general, hold for \\(\\mathbb{R}^{n}\\), for \\(n \\geq 2\\) a natural number. With this in mind, we will often state results and definitions for one and not the other, noting they usually hold by the same proof; when this is not the case we will highlight it. Just as for functions of a single variable, a function of several variables is not defined until its domain and codomain are given. For example, the function \\(f \\colon [0,1]^{2} \\to \\mathbb{R}\\) defined by \\(f(x, y) = y \\sin(x)\\) is not the same as the function \\(g \\colon [-\\pi,\\pi]^{2} \\to \\mathbb{R}\\) defined by \\(g(x) = y \\sin(x)\\). Other examples of functions of several variables include: \\(\\displaystyle f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(\\displaystyle f(x, y) = x + 1\\); \\(\\displaystyle f \\, \\colon \\, \\{ (x, y) \\in \\mathbb{R}^{2} \\colon x^{2} \\geq y^{2} \\} \\to \\mathbb{R}\\) given by \\(f(x, y) = \\sqrt{x^{2} - y^{2}}\\); \\(\\displaystyle f \\, \\colon \\, \\{ (x, y) \\in \\mathbb{R}^{2} \\colon x^{2} + y^{2} \\leq 9\\} \\to \\mathbb{R}\\) given by \\(f(x, y) = \\sqrt{9 - x^{2} - y^{2}}\\). Note, with the first example \\(f \\, \\colon \\, (x, y) \\mapsto x + 1\\), the function \\(f\\) is independent of the second variable. Indeed, a function of several variables need to not depend on all variables; the analogue for functions of a single variable would be a constant function. Returning to our initial example of the volume of circular cylinder, we set \\(V = f(r, h)\\), where the domain of \\(f\\) is \\(\\{ (r, h) \\in \\mathbb{R}^{2} \\, \\colon \\, r &gt; 0 \\; \\text{and} \\; h &gt; 0 \\}\\) and the codomain is \\(\\mathbb{R}\\). The symbols \\(r\\) and \\(h\\) are referred to as independent variables, and \\(V\\) is the dependent variable. Two classes of functions of several variables, which provide a wealth of interesting examples are polynomial and rational functions. A function \\(f\\) of \\(n\\) variables, for some fixed \\(n \\in \\mathbb{N}\\), is polynomial if \\(f(x_{1}, x_{2}, \\dots, x_{n})\\) can be expressed as a sum of terms of the form \\[\\begin{align*} c x_{1}^{m_{1}} x_{2}^{m_{2}} \\dots x_{n}^{m_{n}}, \\end{align*}\\] for all \\((x_{1}, x_{2}, \\dots, x_{n})\\) belonging to the domain of \\(f\\), and where \\(c\\) is a real number and \\(m_{1}\\), \\(m_{2}\\), …, \\(m_{n}\\) are non-negative integers. The degree of the term \\(c x_{1}^{m_{1}} x_{2}^{m_{2}} \\dots x_{n}^{m_{n}}\\) is the sum \\(m_{1} + m_{2} + \\dots + m_{n}\\), and the degree of a polynomial is the maximum of the degrees of all its terms. A rational function of several variables is a quotient of two polynomial functions. For instance \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\[\\begin{align*} f(x, y) = x^{3}- 4 x y^2 + 5 x - 7, \\end{align*}\\] for all \\((x, y) \\in \\mathbb{R}^{2}\\), is a polynomial and \\(g \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\[\\begin{align*} g(x, y) = \\frac{x^{2}- y^{2}}{1+ x^{2} + y^{2}}, \\end{align*}\\] for all \\((x, y) \\in \\mathbb{R}^{2}\\), is a rational function. For functions of a single variable, having a graphical representation helps us understand and analyse the given function. For instance, we know that the graph of a quadric function \\(f \\, \\colon x \\to ax^{2} + bx + c\\) with domain and codomain \\(\\mathbb{R}\\), for some fixed \\(a\\), \\(b\\) and \\(c \\in \\mathbb{R}\\), is a parabola, yielding information about how \\(f\\) varies as \\(x\\) varies. The same is true for functions of several variables. Recall, the graph of a function \\(f\\) of a single variable is the set of points \\((x, y)\\) in \\(\\mathbb{R}^{2}\\) such that \\(x \\in \\operatorname{Dom}(f)\\) and \\(y = f(x)\\). Similarly, the graph of a function \\(f\\) of two variables is the set of points in \\((x, y, z)\\) in \\(\\mathbb{R}^{3}\\) such that \\((x, y) \\in \\operatorname{Dom}(f)\\) and \\(z = f(x, y)\\). Analogously, the graph of a function \\(f\\) of three variables is the set of points in \\((x, y, z, w)\\) in \\(\\mathbb{R}^{4}\\) such that \\((x, y, z) \\in \\operatorname{Dom}(f)\\) and \\(w = f(x, y, z)\\). One can continue in this way to define the graph of a function of \\(n\\) variables, where \\(n \\in \\mathbb{N}\\). See Figures 2.1 for an illustration of the graph of a function \\(f\\) of two variables. FIGURE 2.1: A of graph of a function \\(f\\) of two variables together with its domain. Show/hide image source code ## Interactive web application generated using r library plotly ## #Libraries library(plotly) # Point density pds &lt;- 80 # Define the function F &lt;- function(ax, by) {1.75 + 0.125*sin(1.5*ax)*sin(by)+1.5*exp(-ax^2)*sin(by)} #Function data set of points t &lt;- seq( 0, 4, length.out=pds) s &lt;- seq( 0, 2*pi, length.out=pds) stgrid &lt;-expand.grid(t=t,s=s) st &lt;-data.frame( a = 2*stgrid$t*cos(stgrid$s), b = stgrid$t*sin(stgrid$s), c = F(2*stgrid$t*cos(stgrid$s), stgrid$t*sin(stgrid$s)), d = 0) #Image annotation # Domain Note &lt;- c(&#39;Dom(f)&#39;) xpos &lt;- c(-7.5) ypos &lt;- c(-1) zpos &lt;- c(0) data &lt;- data.frame(Note, xpos, ypos, zpos) # Points Notepts &lt;- c(&#39;(a, b, 0)&#39;,&#39;(a, b, f(a,b))&#39;) xpts &lt;- c(-0.4, -0.4) ypts &lt;- c(1.3, 1.3) zpts &lt;- c(0, F(-0.4,1.3)) pts &lt;- data.frame(Notepts, xpts, ypts, zpts) #Initial view angle, axis labels and ticks scene = list( xaxis = list(range = c(-10,10), tickvals = c(-8,-6,-4,-2,0,2,4,6,8), title = &quot;x&quot;), yaxis = list(range = c(-5,5), tickvals = c(-4,-3,-2,-1,0,1,2,3,4), title = &quot;y&quot;), zaxis = list(range = c(-0.5,3.5), tickvals = c(-0,0.5,1,1.5,2,2.5,3), title = &quot;z&quot;), camera = list(eye = list(x = -1.1, y = 1.1, z = 0.5))) #Generating the figure fig &lt;- plot_ly() # Surface fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$c, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.6, showscale = FALSE, contour=list(show=TRUE, color=&quot;red&quot;)) # Initial view angle, axis labels, ticks and background fig &lt;- fig %&gt;% layout( scene = scene, hoverlabel = list(font=list(size=8)), paper_bgcolor = &quot;rgba(0,0,0,0)&quot;, plot_bgcolor = &quot;rgba(0,0,0,0)&quot;) # Domain fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$d, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.2, showscale = FALSE, contour=list(show=FALSE)) # Annotation fig &lt;- fig %&gt;% add_trace(data, x = ~xpos, y = ~ypos, z = ~zpos, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Note, textposition = &#39;right&#39;, textfont = list(color = &quot;lightseagreen&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;text+markers&#39;, marker = list(size=3, color = &quot;blue&quot;), text = ~Notepts, textposition = list(&#39;bottom left&#39;), textfont = list(color = &quot;blue&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Trace lines fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.4, line = list(color = &quot;blue&quot;, width = 2, dash = &#39;longdash&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # For positioning of annotation fig &lt;- fig %&gt;% layout() # Printing figure fig # Graphs of functions of several variables help us understand and visualise the action of the function on its domain. However, just as in the case for functions of a single variable, it can be challenging to sketch them. This is where we can use level curves and sections to gain insights into the complex structures that can occur. Below we give the definition of a level curve and section of a function of two variables, we note that one may analogously define level hyper‑surfaces and sections for functions of three or more variables. Definition 2.2 (level curves) Let \\(D\\) denote a non-empty subset of \\(\\mathbb{R}^{2}\\), let \\(f \\,\\colon\\, D \\to \\mathbb{R}\\) and fix \\(c \\in \\mathbb{R}\\). A level curve or contour of \\(f\\) at height \\(c\\) is the curve given by the set of points \\((x, y) \\in D\\) satisfying \\(f(x,y)=c\\), see Figures 2.2 for a graphical illustration. One important practical application of level curves is in the making of topographic maps, which conventionally gives a representation of the earth topography by means of contour lines (level curves). The marked contour lines connect contiguous points of the same altitude (isohypse). In other words, every point on the marked line of \\(100\\)m elevation is \\(100\\)m above mean sea level. Such maps have multiple uses, for instance in geographic planning or large‑scale architecture, earth sciences, mining, civil engineering, as well as hiking and orienteering. Other practical applications of level curves are in weather maps where on isothermal curves temperature is constant and where on isobars pressure is constant; or in economics in isocost and isoprofit curves. FIGURE 2.2: A of graph of a function \\(f\\) of two variables together with its domain and a level curve. Show/hide image source code ## Interactive web application generated using r library plotly ## # Libraries library(plotly) # Point density # Point density of surface pds^2 pds &lt;- 80 # Point density of level curve pdc &lt;-500 # Define the function F &lt;- function(ax, by) {1.75 + 0.125*sin(1.5*ax)*sin(by)+1.5*exp(-ax^2)*sin(by)} # Height of level curve h &lt;- 2.4 # Level curve function L &lt;- function(az) {asin((h-1.75)/(0.125*sin(1.5*az)+1.5*exp(-az^2)))} # Function data set of points t &lt;- seq( 0, 4, length.out=pds) s &lt;- seq( 0, 2*pi, length.out=pds) stgrid&lt;-expand.grid(t=t,s=s) st &lt;-data.frame( a = 2*stgrid$t*cos(stgrid$s), b = stgrid$t*sin(stgrid$s), c = F(2*stgrid$t*cos(stgrid$s), stgrid$t*sin(stgrid$s)), d = 0) # Level curve data set of points # Part a, due to arcsin u &lt;- seq( -0.8183669, 1.024535, length.out=pdc) lev1 &lt;-data.frame( levx = u, levy = L(u) ) lev1 &lt;- subset(lev1, !is.nan(lev1[[2]])) # Part b, due to arcsin v &lt;- seq( 1.024535, -0.8183669, length.out=pdc) lev2 &lt;-data.frame( levx = v, levy = pi-L(v)) lev2 &lt;- subset(lev2, !is.nan(lev2[[2]])) # Part a union Part b lev &lt;- rbind(lev1,lev2,head(lev1,n=1)) # Part c, due to arcsin w &lt;- seq( -0.6575,0.82625, length.out=ceiling(pdc/2)) lev3 &lt;-data.frame( levx = w, levy = -pi-L(w)) lev3 &lt;- subset(lev3, !is.nan(lev3[[2]])) # Image annotation Note &lt;- c(&#39;Dom(f)&#39;) xpos &lt;- c(-7.5) ypos &lt;- c(-1) zpos &lt;- c(0) data &lt;- data.frame(Note, xpos, ypos, zpos) # Initial view angle, axis labels and ticks scene = list( xaxis = list(range = c(-10,10), tickvals = c(-8,-6,-4,-2,0,2,4,6,8), title = &quot;x&quot;), yaxis = list(range = c(-5,5), tickvals = c(-4,-3,-2,-1,0,1,2,3,4), title = &quot;y&quot;), zaxis = list(range = c(-0.5,3.5), tickvals = c(-0,0.5,1,1.5,2,2.5,3), title = &quot;z&quot;), camera = list(eye = list(x = -1.1, y = 1.1, z = 0.5))) # Generating the figure fig &lt;- plot_ly() # Surface fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$c, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.6, showscale = FALSE, contour=list(show=FALSE)) # Initial view angle, axis labels, ticks and background fig &lt;- fig %&gt;% layout( scene = scene, hoverlabel = list(font=list(size=8)), paper_bgcolor = &quot;rgba(0,0,0,0)&quot;, plot_bgcolor = &quot;rgba(0,0,0,0)&quot;, legend = list(orientation = &quot;h&quot;, # show entries horizontally xanchor = &quot;center&quot;, # use centre of legend as anchor x = 0.5)) # Domain fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$d, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.2, showscale = FALSE, contour=list(show=FALSE)) # Annotation fig &lt;- fig %&gt;% add_trace(data, x = ~xpos, y = ~ypos, z = ~zpos, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Note, textposition = &#39;right&#39;, textfont = list(color = &quot;lightseagreen&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Level curve fig &lt;- fig %&gt;% add_trace(lev, x = ~lev$levx, y = ~lev$levy, z = ~h, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.75, line = list(width = 2, color=&quot;yellow&quot;), showlegend = FALSE) fig &lt;- fig %&gt;% add_trace(lev3, x = ~lev3$levx, y = ~lev3$levy, z = ~h, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.75, line = list(width = 2, color=&quot;yellow&quot;), showlegend = FALSE) fig &lt;- fig %&gt;% add_trace(lev, x = ~lev$levx, y = ~lev$levy, z = ~0, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;red&quot;), name = &#39;Level curve (height h=2.4)&#39;, showlegend = (TRUE)) fig &lt;- fig %&gt;% add_trace(lev3, x = ~lev3$levx, y = ~lev3$levy, z = ~0, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;red&quot;), showlegend = FALSE) # Trace lines fig &lt;- fig %&gt;% add_trace(lev, x = ~c(lev[1,]$levx, lev[1,]$levx), y = ~c(lev[1,]$levy, lev[1,]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev, x = ~c(lev[ceiling(2*pdc/4),]$levx, lev[ceiling(2*pdc/4),]$levx), y = ~c(lev[ceiling(2*pdc/4),]$levy, lev[ceiling(2*pdc/4),]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev, x = ~c(lev[ceiling(2*pdc/2),]$levx, lev[ceiling(2*pdc/2),]$levx), y = ~c(lev[ceiling(2*pdc/2),]$levy, lev[ceiling(2*pdc/2),]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev, x = ~c(lev[2*ceiling(3*pdc/4),]$levx, lev[ceiling(2*3*pdc/4),]$levx), y = ~c(lev[ceiling(2*3*pdc/4),]$levy, lev[ceiling(2*3*pdc/4),]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color=&quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev3, x = ~c(lev3[1,]$levx, lev3[1,]$levx), y = ~c(lev3[1,]$levy, lev3[1,]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev3, x = ~c(lev3[ceiling(pdc/4),]$levx, lev3[ceiling(pdc/4),]$levx), y = ~c(lev3[ceiling(pdc/2),]$levy, lev3[ceiling(pdc/4),]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(lev3, x = ~c(lev3[ceiling(pdc/2),]$levx, lev3[ceiling(pdc/2),]$levx), y = ~c(lev3[ceiling(pdc/2),]$levy, lev3[ceiling(pdc/2),]$levy), z = ~c(h,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # For positioning of annotation fig &lt;- fig %&gt;% layout() # Print figure fig # A level curve of a function of two variables, is a curve in the \\(x\\)-\\(y\\) plane. However, as is demonstrated in our example (Figures 2.2), they are not necessarily a graphs of functions of a single variable. This is in contract to sections, which dissect a the graph of a function of two variables by fixing either the first variable, or by fixing the second variable, see Figures 2.3 for a graphical illustration. Definition 2.3 (sections) Let \\(D\\) denote a non-empty subset of \\(\\mathbb{R}^{2}\\), let \\(f \\,\\colon\\, D \\to \\mathbb{R}\\), and fix \\(x_{0}\\) and \\(y_{0} \\in \\mathbb{R}\\) such that there exists a \\(y\\) and an \\(x \\in \\mathbb{R}\\) with \\((x_{0}, y)\\) and \\((x, y_{0}) \\in D\\). A vertical section of \\(f\\) at \\(x_{0}\\) in the direction of \\(y\\) is the graph of the function \\(y \\mapsto f(x_{0}, y)\\) with domain \\(\\{ w \\in \\mathbb{R} \\,\\colon\\, (x_{0}, w) \\in D\\}\\) and codomain \\(\\mathbb{R}^{3}\\); and a vertical section of \\(f\\) at \\(y_{0}\\) in the direction of \\(x\\) is the graph of the function \\(x \\mapsto f(x, y_{0})\\) with domain \\(\\{ w \\in \\mathbb{R} \\, \\colon \\, (w, y_{0}) \\in D\\}\\) and codomain \\(\\mathbb{R}^{3}\\). FIGURE 2.3: A of graph of a function \\(f\\) of two variables together with its domain, a section in the direction of \\(y\\) and a section in the direction of \\(x\\). Show/hide image source code ## Interactive web application generated using r library plotly ## # Libraries library(plotly) # Point density # Point density of surface pds^2 pds &lt;- 80 # Point density of level curve pdc &lt;-500 # Define the function F &lt;- function(ax, by) {1.75 + 0.125*sin(1.5*ax)*sin(by)+1.5*exp(-ax^2)*sin(by)} # Function data set of points t &lt;- seq( 0, 4, length.out=pds) s &lt;- seq( 0, 2*pi, length.out=pds) stgrid&lt;-expand.grid(t=t,s=s) st &lt;-data.frame( a = 2*stgrid$t*cos(stgrid$s), b = stgrid$t*sin(stgrid$s), c = F(2*stgrid$t*cos(stgrid$s), stgrid$t*sin(stgrid$s)), d = 0) # Section in y-direction data set of points tsecy &lt;- seq( -3.975, 3.975, length.out=pdc) ssecy &lt;- -0.8 ysec &lt;-data.frame( a = ssecy, b = tsecy, c = F(ssecy, tsecy), d = 0) # Section in x-direction data set of points tsecx &lt;- 1.5 ssecx &lt;- seq( -7.4, 7.4, length.out=pdc) xsec &lt;-data.frame( a = ssecx, b = tsecx, c = F(ssecx, tsecx), d = 0) # Image annotation Note &lt;- c(&#39;Dom(f)&#39;) xpos &lt;- c(-7.5) ypos &lt;- c(-1) zpos &lt;- c(0) data &lt;- data.frame(Note, xpos, ypos, zpos) # Initial view angle, axis labels and ticks scene = list( xaxis = list(range = c(-10,10), tickvals = c(-8,-6,-4,-2,0,2,4,6,8), title = &quot;x&quot;), yaxis = list(range = c(-5,5), tickvals = c(-4,-3,-2,-1,0,1,2,3,4), title = &quot;y&quot;), zaxis = list(range = c(-0.5,3.5), tickvals = c(-0,0.5,1,1.5,2,2.5,3), title = &quot;z&quot;), camera = list(eye = list(x = -1.1, y = 1.1, z = 0.5))) # Generating the figure fig &lt;- plot_ly() # Surface fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$c, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.6, showscale = FALSE, contour=list(show=TRUE, color=&quot;green&quot;)) # Initial view angle, axis labels, ticks and background fig &lt;- fig %&gt;% layout( scene = scene, hoverlabel = list(font=list(size=8)), paper_bgcolor = &quot;rgba(0,0,0,0)&quot;, plot_bgcolor = &quot;rgba(0,0,0,0)&quot;, legend = list(orientation = &quot;h&quot;, # show entries horizontally xanchor = &quot;center&quot;, # use centre of legend as anchor x = 0.5)) # Domain fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$d, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.2, showscale = FALSE, contour=list(show=TRUE, color=&quot;green&quot;)) # Annotation fig &lt;- fig %&gt;% add_trace(data, x = ~xpos, y = ~ypos, z = ~zpos, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Note, textposition = &#39;right&#39;, textfont = list(color = &quot;lightseagreen&quot;), showlegend = FALSE) # Section in y-direction fig &lt;- fig %&gt;% add_trace(ysec, x = ~ysec$a, y = ~ysec$b, z = ~ysec$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;red&quot;), showlegend = TRUE, name = &#39;Vertical section at x=-0.8 in the direction of y&#39;) fig &lt;- fig %&gt;% add_trace(ysec, x = ~ysec$a, y = ~ysec$b, z = ~ysec$d, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity = 0.6, line = list(width = 2, color=&quot;orange&quot;), showlegend = FALSE) # Section in x-direction fig &lt;- fig %&gt;% add_trace(xsec, x = ~xsec$a, y = ~xsec$b, z = ~xsec$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;brown&quot;), showlegend = TRUE, name = &#39;Vertical section at y=1.5 in the direction of x&#39;) fig &lt;- fig %&gt;% add_trace(xsec, x = ~xsec$a, y = ~xsec$b, z = ~xsec$d, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity = 0.35, line = list(width = 2, color=&quot;purple&quot;), showlegend = FALSE) # Trace lines section in the y-direction fig &lt;- fig %&gt;% add_trace(ysec, x = ~c(ssecy, ssecy), y = ~c(ysec[1,]$b, ysec[1,]$b), z = ~c(ysec[1,]$c, ysec[1,]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(ysec, x = ~c(ssecy, ssecy), y = ~c(ysec[ceiling(pdc/4),]$b, ysec[ceiling(pdc/4),]$b), z = ~c(ysec[ceiling(pdc/4),]$c, ysec[ceiling(pdc/4),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(ysec, x = ~c(ssecy, ssecy), y = ~c(ysec[ceiling(pdc/2),]$b, ysec[ceiling(pdc/2),]$b), z = ~c(ysec[ceiling(pdc/2),]$c, ysec[ceiling(pdc/2),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(ysec, x = ~c(ssecy, ssecy), y = ~c(ysec[ceiling(3*pdc/4),]$b, ysec[ceiling(3*pdc/4),]$b), z = ~c(ysec[ceiling(3*pdc/4),]$c, ysec[ceiling(3*pdc/4),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(ysec, x = ~c(ssecy, ssecy), y = ~c(ysec[ceiling(pdc),]$b, ysec[ceiling(pdc),]$b), z = ~c(ysec[ceiling(pdc),]$c, ysec[ceiling(pdc),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.6, line = list(color = &quot;orange&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Trace lines section in the x-direction fig &lt;- fig %&gt;% add_trace(xsec, x = ~c(xsec[1,]$a, xsec[1,]$a), y = ~c(tsecx, tsecx), z = ~c(xsec[1,]$c, xsec[1,]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.35, line = list(color = &quot;purple&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(xsec, x = ~c(xsec[ceiling(pdc/4),]$a, xsec[ceiling(pdc/4),]$a), y = ~c(tsecx, tsecx), z = ~c(xsec[ceiling(pdc/4),]$c, xsec[ceiling(pdc/4),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.35, line = list(color = &quot;purple&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(xsec, x = ~c(xsec[ceiling(pdc/2),]$a, xsec[ceiling(pdc/2),]$a), y = ~c(tsecx, tsecx), z = ~c(xsec[ceiling(pdc/2),]$c, xsec[ceiling(pdc/2),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.35, line = list(color = &quot;purple&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(xsec, x = ~c(xsec[ceiling(3*pdc/4),]$a, xsec[ceiling(3*pdc/4),]$a), y = ~c(tsecx, tsecx), z = ~c(xsec[ceiling(3*pdc/4),]$c, xsec[ceiling(3*pdc/4),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.35, line = list(color = &quot;purple&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(xsec, x = ~c(xsec[ceiling(pdc),]$a, xsec[ceiling(pdc),]$a), y = ~c(tsecx, tsecx), z = ~c(xsec[ceiling(pdc),]$c, xsec[ceiling(pdc),]$d), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.35, line = list(color = &quot;purple&quot;, width = 2, dash = &#39;longdashdot&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # For positioning of annotation fig &lt;- fig %&gt;% layout() # Print figure fig # As with functions of a single variable, the class of continuous functions of several variables is central in calculus. In the case of a function of a single variable, in order to determine if it is continuous, we used the concept of a limit, see Definitions 1.3–1.6. Limits and continuity of functions of several variables is focus of our next two sections. "],["limitsparttwoFSV.html", "2.1 Limits (part II)", " 2.1 Limits (part II) The rate of change of a function \\(f\\) of a single variable is a central topic in calculus, and reveals practical structural information of \\(f\\), and hence the scenario we our modelling with \\(f\\). Functions of several variables, allow us to model our physical world more accurately than functions of single variables, and thus it is natural build a theory which will allow us to determine rates of change of a function of several variables. As with functions of a single variable, limits allow us to build a robust theory to analyse and understand rates of change of functions of several variables. To this end, let \\(n \\in \\mathbb{N}\\) be fixed, and let \\(x = (x_{1}, x_{2}, \\dots, x_{n})\\) and \\(y = (y_{1}, y_{2}, \\dots, y_{n}) \\in \\mathbb{R}^{n}\\). The distance between \\(x\\) and \\(y\\), denoted by \\(\\lvert x - y \\rvert\\), is the length of the straight line segment in \\(\\mathbb{R}^{n}\\) connecting \\(x\\) and \\(y\\), equivalently \\[\\begin{align*} \\lvert x - y \\rvert = \\left( (x_{1} - y_{1})^{2} + (x_{2} - y_{2})^{2} + \\dots + (x_{n} - y_{n})^{2} \\right)^{1/2}. \\end{align*}\\] Geometrically, we think of \\(x \\pm y\\) as the point \\(( x_{1} \\pm y_{1}, x_{2} \\pm y_{2}, \\dots, x_{n} \\pm y_{n} )\\), and as such, if \\(y = (0, 0, \\dots, 0)\\) is the origin, then we abbreviate \\(\\lvert x - y \\rvert\\) to \\(\\lvert x \\rvert\\). Further, we note that \\[\\begin{align} \\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\quad \\text{and} \\quad \\lvert x - y \\rvert \\geq \\max \\{ \\lvert x \\rvert - \\lvert y \\rvert, \\lvert y \\rvert - \\lvert x \\rvert \\}. \\tag{2.1} \\end{align}\\] The first of these inequalities, is referred to as a triangle inequality. Show/hide proof of (2.1) Proof. The first inequality is a direct application of the law of cosines, and the second inequality is an application of the first inequality to \\((x-y) + y\\). Given an \\(x \\in \\mathbb{R}^{n}\\) and a non-negative real number \\(r\\), the set of points whose distance is exactly \\(r\\) away from \\(x\\) is called the \\((n-1)\\)-dimensional sphere of radius \\(r\\) centred at \\(x\\). In the case that \\(x = (0, 0, \\dots, 0)\\) is the origin in \\(\\mathbb{R}^{n}\\) and \\(r = 1\\), we denote the \\((n-1)\\)-dimensional sphere of radius one centred at the origin by \\(\\mathbb{S}^{n-1}\\); note \\(\\mathbb{S}^{n-1}\\) is a subset of \\(\\mathbb{R}^{n}\\). In particular, \\[\\begin{align*} \\mathbb{S}^{1} = \\{ (y_{1}, y_{2}) \\in \\mathbb{R}^{2} \\, \\colon \\, \\lvert (y_{1}, y_{2}) \\rvert = 1 \\} \\end{align*}\\] is the unit circle in \\(\\mathbb{R}^{2}\\) and \\[\\begin{align*} \\mathbb{S}^{2} = \\{ (y_{1}, y_{2}, y_{3}) \\in \\mathbb{R}^{3} \\, \\colon \\, \\lvert (y_{1}, y_{2}, y_{3}) \\rvert = 1 \\} \\end{align*}\\] is the unit sphere in \\(\\mathbb{R}^{3}\\). The set of point in \\(\\mathbb{R}^{n}\\) enclosed by but not on an \\((n-1)\\)-dimensional sphere of radius \\(r\\) centred at a given \\(x \\in \\mathbb{R}^{n}\\), is called the open \\(n\\)-dimensional ball of radius \\(r\\) centred at \\(x\\) and is denoted by \\(\\mathbb{B}^{n}(x, r)\\); the set of point in \\(\\mathbb{R}^{n}\\) on or enclosed by an \\((n-1)\\)-dimensional sphere of radius \\(r\\) centred at a given \\(x \\in \\mathbb{R}^{n}\\), is referred to as the closed \\(n\\)-dimensional ball of radius \\(r\\) centred at \\(x\\) and is denoted by \\(\\overline{\\mathbb{B}^{n}}(x, r)\\). Namely, \\[\\begin{align*} \\mathbb{B}^{n}(x, r) = \\{ y \\in \\mathbb{R}^{n} \\, \\colon \\, \\lvert x - y \\rvert &lt; r \\} \\quad \\text{and} \\quad \\overline{\\mathbb{B}^{n}}(x, r) = \\{ y \\in \\mathbb{R}^{n} \\, \\colon \\, \\lvert x - y \\rvert \\leq r \\}. \\end{align*}\\] This leads us to the concept of the closure of a set. Given a subset \\(D\\) of \\(\\mathbb{R}^{n}\\) we define its closure, denoted by \\(\\overline{D}\\), to be the set of points \\(x\\) such that for all \\(\\epsilon &gt; 0\\), there exists a \\(y \\in D\\) with \\(\\lvert x - y \\rvert &lt; \\epsilon\\). We say that \\(x\\) is an interior point of a subset \\(D\\) of \\(\\mathbb{R}^{n}\\), for some fixed \\(n \\in \\mathbb{N}\\), if there exists an \\(\\epsilon &gt; 0\\), such that \\(B(x, \\epsilon) \\subseteq D\\), see Figures 2.4(b) for an illustration. A point \\(x\\) is called a boundary point of \\(D\\) if \\(x \\in \\overline{D}\\) and is not an interior point of \\(\\overline{D}\\), see Figures 2.4(b) for an illustration. FIGURE 2.4: Examples of an interior point and a boundary point of the shaded region D. Show/hide image source code %%Image (a) generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % put the x a xis in the middle axis y line=middle, % put the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4] \\addplot [ thick, domain=0:360, samples=500, color=Cerulean, fill=Cerulean, fill opacity=0.2, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot [thick, domain=0:360, samples=500, color=Cerulean, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot [dashed, domain=35:325, samples=500, color=Red, variable=\\t] ({0.475+0.425*cos(t)}, {0.3+0.5*sin(t)}); \\addplot[mark=*, color=Red] coordinates {(0.475,0.3)}; \\end{axis} \\node at (4.35, 3.075) {${\\color{Red}(a, b)}$}; \\node at (1.2, 4.125) {${\\color{Cerulean}D}$}; \\node[right] at (0, -0.75) {(a) Example of an interior point.}; \\end{tikzpicture} \\end{preview} \\end{document} %%Image (b) generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % put the x a xis in the middle axis y line=middle, % put the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4] \\addplot [ thick, domain=0:360, samples=500, color=Cerulean, fill=Cerulean, fill opacity=0.2, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot [thick, domain=0:360, samples=500, color=Cerulean, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot [dashed, domain=35:325, samples=500, color=Red, variable=\\t] ({2.67441+0.425*cos(t)}, {1.05887+0.5*sin(t)}); \\addplot[mark=*, color=Red] coordinates {(2.67441,1.05887)}; \\end{axis} \\node at (6.2, 3.6) {${\\color{Red}(a, b)}$}; \\node at (1.2, 4.125) {${\\color{Cerulean}D}$}; \\node[right] at (0, -0.75) {(b) Example of a boudary point.}; \\end{tikzpicture} \\end{preview} \\end{document} Definition 2.4 (limits — part III) Let \\(n \\in \\mathbb{N}\\), let \\(D\\) be a non-empty subset of \\(\\mathbb{R}^{n}\\), let \\(f \\, \\colon \\, D \\to \\mathbb{R}\\), and let \\(w \\in \\overline{D}\\). We say that \\(L\\) is the limit of \\(f\\) as \\(x\\) approaches \\(w\\) if for every \\(\\epsilon &gt; 0\\) there exists a \\(\\delta &gt; 0\\) such that for all \\(x \\in D\\) satisfying \\(0 &lt; \\lvert x - w \\rvert &lt; \\delta\\) we have that \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\), and write \\[\\begin{align*} \\lim_{x \\to w} f(x) = L. \\end{align*}\\] In the above definition it is important to note that \\(w\\) may not lie in the domain of \\(f\\), and even if \\(w\\) does belong to the domain of \\(f\\), it may be the case that \\(f(w) \\neq L\\). We also note that equivalent formulations of the conditions \\(0 &lt; \\lvert x - w \\rvert &lt; \\delta\\) and \\(\\lvert f(x) - L \\rvert &lt; \\epsilon\\) are \\(x \\in \\mathbb{B}^{n}(w, \\delta) \\setminus \\{w\\}\\) and \\(f(x) \\in \\mathbb{B}^{n}(L, \\epsilon) = (L - \\epsilon, L+\\epsilon)\\), respectively, see Figures 2.5 for a graphical illustration. FIGURE 2.5: Illustration of the limit as \\(x\\) approaches \\(w\\) of a function \\(f\\) of two variables. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % put the x a xis in the middle axis y line=middle, % put the y axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4, % grid=both, % adds gridlines ] \\addplot [ thick, domain=0:360, samples=500, color=Cerulean, fill=Cerulean, fill opacity=0.2, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\addplot [ thick, domain=0:360, samples=500, color=Cerulean, variable=\\t] ({(2-sin(3*t)*cos(9*t))*cos(t)}, {(2-sin(3*t)*cos(9*t))*sin(t)}); \\end{axis} \\draw[thick, -&gt;] (9,0) -- (9,5.7); \\draw[thick] (8.875,2.85) -- (9.125,2.85); \\draw[thick] (8.875,4.25) -- (9.125,4.25); \\draw[thick, color=Cerulean] (8.875,4) -- (9.125,4); \\node at (9.35, 4.25) {$L$}; \\node at (9.64, 4.75) {$\\color{Red}L+\\epsilon$}; \\node at (9.64, 3.75) {$\\color{Red}L-\\epsilon$}; \\node at (8.4, 4) {$\\color{Cerulean}f(x)$}; \\node at (9.35, 2.85) {$0$}; \\node at (9.175, 5.48) {$z$}; \\node at (10,2.85) {}; % Determines edge of image \\node at (0.9, 3.7) {${\\color{Cerulean}\\operatorname{Dom}(f)}$}; \\draw[thick, dashed, color=Red, fill=Red, fill opacity=0.25] (4.6,3.125) circle (6pt); \\draw[thick, dashed, color=Red] (4.6,3.125) circle (6pt); \\draw[Red] (4.6,3.125) -- (4.4,3.1); \\draw[Red] (5,3.3) to[out=200,in=70] (4.5,3.15); \\draw[thick, color=black, fill=black] (4.6,3.125) circle (0.7pt); \\draw[thick, color=Cerulean, fill=Cerulean] (4.55,3.025) circle (0.7pt); \\draw[Cerulean] (4.25,2.7) to[out=20,in=200] (4.5,3.025); \\node at (4.1, 2.7) {${\\color{Cerulean}x}$}; \\node at (5.1, 3.3) {${\\color{Red}\\delta}$}; \\node at (4.2, 3.125) {$w$}; \\draw[draw=none, rounded corners=2.5pt, color=Cerulean, fill=Cerulean, fill opacity=0.125] (8.875,3.75) rectangle ++(0.25,1); \\draw[draw=none, rounded corners=2.5pt, color=Red, fill=Red, fill opacity=0.25] (8.875,3.75) rectangle ++(0.25,1); \\draw[thick, Red] (8.875,3.8) arc (225:315:0.175); \\draw[thick, Red] (9.125,4.7) arc (45:135:0.175); \\draw[-&gt;, color=Cerulean] (4.6,3.025) to[out=-5,in=200] (8,4); \\end{tikzpicture} \\end{preview} \\end{document} Just as in the case of functions of a single variable, if \\(f \\, \\colon \\, D \\to \\mathbb{R}\\) is a function of several variables and if the limit of \\(f\\) as \\(x\\) approaches \\(w \\in \\overline{D}\\) exists, then it is unique. Further, letting \\(L\\), \\(M\\), and \\(k\\) denote three real numbers, and letting \\(D\\) denote a non‑empty subset of \\(\\mathbb{R}^{n}\\), for some \\(n \\in \\mathbb{N}\\), if \\(f\\) and \\(g \\, \\colon \\, D \\to \\mathbb{R}\\) and \\(w \\in \\overline{D}\\) are such that \\[\\begin{align*} \\lim_{x \\to w} f(x) = L \\quad \\text{and} \\quad \\lim_{x \\to w} g(x) = M, \\end{align*}\\] then we have the following: \\(\\displaystyle \\lim_{x \\to w} f(x) \\pm g(x) = L \\pm M\\), \\(\\displaystyle \\lim_{x \\to w} k f(x) = k L\\), and \\(\\displaystyle \\lim_{x \\to w} f(x) g(x) = L M\\). If in addition, \\(L\\) is positive, \\(M\\) is non‑zero and \\(m\\) is a positive real numbers, then \\(\\displaystyle \\lim_{x \\to w} \\frac{f(x)}{g(x)} = \\frac{L}{M}\\), and \\(\\displaystyle \\lim_{x \\to w} (f(x))^{m} = L ^{m}\\). The proofs of these results follows analogously to those for functions of a single variable. For a function \\(g \\, \\colon \\mathbb{R} \\to \\mathbb{R}\\) of a single variable with a jump discontinuity at \\(x = a\\), for some \\(a \\in \\mathbb{R}\\), one proves that the limit of \\(g(x)\\) as \\(x\\) approaches \\(a\\) does not exist by showing that the one sided limits \\[\\begin{align*} \\lim_{x \\to a^{+}} g(x) \\quad \\text{and} \\quad \\lim_{x \\to a^{-}} g(x), \\end{align*}\\] are not equal. Indeed, when considering these one‑sided limits, we may regard points on the \\(x\\)-axis with coordinate \\(x\\) as approaching a given point with coordinate \\(a\\) either from the left, or from the right. The analogous situation for functions of several variables is much more complex, since in \\(\\mathbb{R}^{n}\\), for \\(n \\geq 2\\) a natural number, there are an infinite number of different curves, or paths, along which we can approach a given point \\(w \\in \\mathbb{R}^{n}\\), see Figures 2.6. However, if the limit in Definition 2.4 exists, then a function of several variables \\(f\\) must have limit \\(L\\) as \\(x\\) approaches \\(w\\), no matter how we approach \\(w\\). FIGURE 2.6: Examples of paths approaching a point in the plane. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usepackage{pgfplots} \\pgfplotsset{every axis/.append style={ axis x line=middle, % put the x-axis in the middle axis y line=middle, % put the y-axis in the middle axis line style={thick,-&gt;,color=black}, % arrows on the axis xlabel={$x$}, % default put x on x-axis ylabel={$y$}, % default put y on y-axis ticks=none, }} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% \\begin{tikzpicture} \\begin{axis}[ xmin=-4,xmax=4, ymin=-4,ymax=4,] \\end{axis} \\draw[thick, color=Cerulean, fill=Cerulean] (5.6,3.6) circle (1pt); \\draw[-&gt;, color=Blue] (2.6,3.025) to[out=-20,in=160] (5.5,3.6); \\draw[-&gt;, color=Green] (3,5) -- (5.5,3.7); \\draw[-&gt;, color=Gray] (2,2) -- (5.5,3.5); \\draw[-&gt;, color=Red] (5.7, 5.5) -- (5.5, 5.3) -- (5.7, 5.1) -- (5.5,4.9) -- (5.7,4.7) -- (5.5,4.5) -- (5.7,4.3) -- (5.5, 4.1) -- (5.7, 3.9) -- (5.6,3.7); \\draw[-&gt;, color=Brown] (6.5,4) to[out=120,in=15] (5.7,3.7); \\draw [Orange, -&gt;] plot [smooth, tension=2] coordinates {(5.5,1.2) (5.9,1.4) (5.5,1.6) (5.9,1.8) (5.5,2) (5.9,2.2) (5.5,2.4) (5.9,2.6) (5.5,2.8) (5.9,3) (5.5,3.2) (5.9,3.4) (5.7,3.6)}; \\end{tikzpicture} \\end{preview} \\end{document} "],["continuityparttwoFSV.html", "2.2 Continuity (part II)", " 2.2 Continuity (part II) The definition of continuity of a function of several variables is analogous to that for functions of a single variable given in Definition 1.6. Definition 2.5 (continuity — part II) A function \\(f\\) of several variables is continuous at \\(w \\in \\mathrm{Dom}(f)\\) if \\[\\begin{align*} \\lim_{x \\to w} f(x) = f(w). \\end{align*}\\] If \\(f\\) is continuous at every point in its domain, then \\(f\\) is said to be continuous. We observe that if \\(f\\) is a continuous function of \\(n\\) variables, then a small change in \\(x = (x_{1}, x_{2}, \\dots, x_{n}) \\in \\mathrm{Dom}(f)\\) results in a small change in \\(f(x)\\). In terms of the graph of \\(f\\), if \\(x= (x_{1}, x_{2}, \\dots, x_{n})\\) and \\(y= (y_{1}, y_{2}, \\dots, y_{n})\\) are two points in the domain of \\(f\\), which are sufficiently close to each other, then the points \\((x_{1}, x_{2}, \\dots, x_{n}, f(x_{1}, x_{2}, \\dots, x_{n}))\\) and \\((y_{1}, y_{2}, \\dots, y_{n}, f(y_{1}, y_{2}, \\dots, y_{n}))\\) are also close. Thus, there are no jumps or vertical hyperplanes in the graph of a continuous function of several variables. Just as in the case of functions of a single variable, sums, products and quotients of continuous functions are continuous, provided no zero denominators occur for the case of quotients. In particular, polynomials and rational functions (except at points where the denominator is zero) are continuous. If one builds a function of several variables, from continuous functions of a single variable, through taking sums, products and quotients, except in the case of quotients at points where the denominator is zero, then the resulting function is continuous. For instance if \\(g\\) and \\(h \\, \\colon \\mathbb{R} \\to \\mathbb{R}\\) are continuous functions, then \\((x, y) \\mapsto g(x)\\pm h(y)\\), \\((x, y) \\mapsto g(x) h(y)\\) and \\((x, y) \\mapsto g(x) / h(y)\\) all determine continuous functions, except in the last case, at points where the denominator is zero. Another useful result on continuity, which carries over from the case of functions of a single variable to functions of several variables, concerns the composition of continuous functions. Namely, letting \\(f\\) denote a continuous functions of \\(n\\) variables, for some fixed \\(n \\in \\mathbb{N}\\), and letting \\(g\\) denote a function of a single variable, if \\(f\\) is continuous at \\(x = (x_{1}, x_{2}, \\dots, x_{n})\\) and \\(g\\) is continuous at \\(f(x)\\), then \\(g \\circ f\\) is continuous at \\(x\\), where \\(g \\circ f(x) = g(f(x))\\). "],["practiceproblemschaptertwo.html", "Practice problems – Chapter 2", " Practice problems – Chapter 2 Exercise 2.1 Prove that a vertical section is the graph of a function, but that a level curve need not be. Show/hide solution Solution. Let \\(n \\geq 2\\) be a natural number, \\(m \\in \\{ 1, 2, \\dots, n \\}\\) and suppose that \\(D\\) is a non-empty subset of \\(\\mathbb{R}^{n}\\). If \\(f \\, \\colon \\, D \\to \\mathbb{R}\\) is a function of \\(n\\) variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), and if \\(k \\in \\mathbb{R}\\) is such that there exist, \\(x_{1}\\), …, \\(x_{m-1}\\), \\(x_{m+1}\\), …, \\(x_{n} \\in \\mathbb{R}\\) with \\((x_{1}, \\dots, x_{m-1}, k, x_{m-1}, \\dots, x_{n}) \\in D\\), then \\(f(x_{1}, \\dots, x_{m-1}, k, x_{m-1}, \\dots, x_{n})\\) is a unique value, for each \\((x_{1}, \\dots, x_{m-1}, x_{m-1}, \\dots, x_{n}) \\in \\mathbb{R}^{n-1}\\) with \\((x_{1}, \\dots, x_{m-1}, k, x_{m-1}, \\dots, x_{n}) \\in D\\). Hence, the map \\[\\begin{align*} (x_{1}, \\dots, x_{m-1}, x_{m-1}, \\dots, x_{n}) \\mapsto f(x_{1}, \\dots, x_{m-1}, k, x_{m-1}, \\dots, x_{n}), \\end{align*}\\] with domain \\[\\begin{align*} \\{ (x_{1}, \\dots, x_{m-1}, x_{m-1}, \\dots, x_{n}) \\in \\mathbb{R}^{n} \\, \\colon \\, (x_{1}, \\dots, x_{m-1}, k, x_{m-1}, \\dots, x_{n}) \\in D\\}, \\end{align*}\\] defines a real valued function whose graph is a vertical section. On the other hand, a level curve of a function of two variables need not be the graph of a function of a single variable. Take for instance \\(f \\, \\colon \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\(f(x, y) = x^2+y^2\\). The level curve of \\(f\\) at height one is the circle in the \\(x\\)-\\(y\\) plane centered at the origin of radius one, which is not the graph of a function of a single variable. Since if it were the graph of a function of a single variable, it would not pass the horizontal line test, that is, it would not be well defined. Exercise 2.2 Sketch some vertical sections and level curves of the following functions. The function \\(f \\colon \\mathbb{R}^2 \\to \\mathbb{R}\\) given by \\(f(x,y)=x^2-y^2\\) The function \\(f \\colon \\mathbb{R}^2 \\to \\mathbb{R}\\) given by \\(f(x,y)=\\sin(x)\\) The function \\(f \\colon \\mathbb{R} \\times \\mathbb{R}^{+} \\to \\mathbb{R}\\) given by \\(f(x,y)=x/y\\) Exercise 2.3 Let \\(a\\) and \\(b\\) denote two real numbers with \\(a &lt; b\\). Show that the closure of the open interval \\(I = (a, b)\\) is the closed interval \\([a, b]\\) and describe the interior and boundary points of \\(I\\). Show/hide solution Solution. Let \\(x \\in \\mathbb{R}\\) be such that \\(x \\not\\in [a, b]\\). Letting \\(r = \\min \\{ \\lvert a -x \\rvert, \\lvert x - b \\rvert \\}\\), we observe that \\(\\mathbb{B}^{1}(x, r) \\cap (a, b) = \\emptyset\\), and thus \\(x\\) does not belong to the closure of \\((a, b)\\). On the other hand if \\(x \\in (a, b)\\), since \\(x\\), \\((x + \\max\\{a, x-r \\})/2\\), and \\((x + \\min\\{b, x+r \\})/2\\) all belong to \\(\\mathbb{B}^{1}(x, r) \\cap (a, b)\\), for all positive \\(r \\in \\mathbb{R}\\), it follows that \\(x\\) belong to the closure of \\((a, b)\\). Let us now consider the points \\(a\\) and \\(b\\). Since \\(a \\neq b\\), for all \\(r \\in \\mathbb{R}\\) positive, \\(\\mathbb{B}^{1}(a, r) \\cap (a, b) = (a, \\min \\{ a+r, b \\} )\\) and \\(\\mathbb{B}^{1}(b, r) \\cap (a, b) = (\\max \\{ a, b-r \\} )\\) are non-empty, and so both \\(a\\) and \\(b\\) belong to the closure of \\((a, b)\\). Thus, we have shown that the closure of the open interval \\((a, b)\\) is the closed interval \\([a, b]\\). The interior of of the open interval \\((a, b)\\) is itself, since for all \\(x \\in (a, b)\\), letting \\(r = \\min\\{ x - a, b -x \\}\\), we have that \\(\\mathbb{B}^{1}(x, r) \\subseteq (a, b)\\). As \\([a, b]\\) is the closure of \\((a, b)\\), and since \\([a, b] \\setminus (a, b) = \\{a, b\\}\\), it follows that the boundary of the open interval \\((a, b)\\) is the set \\(\\{a, b\\}\\). Exercise 2.4 For all positive real numbers \\(a\\) and \\(b\\) with \\(a &lt; b\\), show that the closure of the Cartesian product \\((a, b) \\times (a, b)\\) is the Cartesian product \\([a, b] \\times [a, b]\\) and describe the interior and boundary points of \\((a, b) \\times (a, b)\\). Exercise 2.5 Let \\(n \\in \\mathbb{N}\\) and let \\(D\\) denote a non-empty subset of \\(\\mathbb{R}^{n}\\), prove that the closure of \\(\\overline{D}\\) is itself. Show/hide solution Solution. If \\(x \\in \\overline{D}\\), then \\(x\\) belongs to the closure of \\(\\overline{D}\\), since \\(x \\in \\mathbb{B}^{n}(x, r) \\cap \\overline{D}\\) for all positive \\(r \\in \\mathbb{R}\\). Therefore, the closure of \\(\\overline{D}\\) contains \\(\\overline{D}\\). Suppose, by way of contradiction, that the closure of \\(\\overline{D}\\) contained an \\(x \\not\\in \\overline{D}\\). Then for all positive \\(r \\in \\mathbb{R}\\) there exists a point \\(y \\in \\overline{D}\\) such that \\(y \\in \\mathbb{B}^{n}(x, r) \\cap \\overline{D}\\). Since \\(\\mathbb{B}^{n}(x, r)\\) is open, there exists a positive \\(r&#39; \\in \\mathbb{R}\\) such that \\(\\mathbb{B}^{n}(y, r&#39;) \\subseteq \\mathbb{B}^{n}(x, r)\\). Additionally, since \\(y\\) belongs to the closure of \\(D\\), there exists a \\(z \\in \\mathbb{B}^{n}(y, r&#39;) \\cap D\\). This implies that to each positive \\(r \\in \\mathbb{R}\\), there exists a \\(z \\in \\mathbb{B}^{n}(x, r) \\cap D\\). However, this would mean that \\(x\\) belongs to the closure of \\(D\\), contradicting our hypothesis. "],["partialderivatives.html", "Chapter 3 Partial derivatives", " Chapter 3 Partial derivatives Derivatives are one of the most fundamental concepts in calculus. In this chapter we investigate how differentiation can be defined for functions of several variables. For a function \\(g\\) of a single variable, we defined the derivative \\(g&#39;(x)\\) of \\(g\\) at a point \\(x \\in \\mathrm{Dom}(g)\\) as \\[\\begin{align*} g&#39;(x) = \\lim_{h \\to 0} \\frac{g(x + h) - g(x)}{h}, \\end{align*}\\] provided that the limit exists. The resulting value informs us of the rate of change of \\(g\\) as we approach \\(x\\). For instance, if \\(g&#39;(x) &gt; 0\\), then \\(g\\) is increasing in a small neighbourhood of \\(x\\), if \\(g&#39;(x) &lt; 0\\), then \\(g\\) is decreasing in a small neighbourhood of \\(x\\), and if \\(g&#39;(x) = 0\\), then we know that \\(x\\) is either a local maximum, a local minimum or a saddle point of \\(g\\). For a function of several variables, we have seen that one can define limits and continuity in an analogously fashion to how we defined them for functions of a single variable. However, as we have seen in Figures 2.6, unlike in \\(\\mathbb{R}\\), where we can approach a point from one of two directions, namely either from the left or from the right, there are infinitely many paths (or ways) by which we can approach a point in \\(\\mathbb{R}^{n}\\), for \\(n \\geq 2\\) a natural number. This makes defining the derivative of a function of several variables more challenging than for functions of a single variable. In order to build a meaningful and rigorous definition of what it means for a function of several variables to be differentiable, we begin with defining partial derivatives. That is, where we fix all but a single variable of a function \\(f\\) of several variables, and examine how \\(f\\) changes as we vary that one variable. This motivates the notion of a directional derivative, from which we can define what it means for a function of several variables to be differentiable. "],["pd.html", "3.1 Partial derivatives", " 3.1 Partial derivatives Partial differentiation is concerned with extending the concept of differentiation of a functions of a single variable to functions of several variables. Here differentiation is carried out one variable at a time. The relationship, or lack thereof, between the derivatives with respect to different variables makes the analysis of such functions much more complicated and subtle than that of a function of a single variable. Let us suppose that \\(f\\) is a function of two variables and that \\((x_{0}, y_{0})\\) is a point in the interior of the domain of \\(f\\). The vertical plane determined by the set of points \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, y = y_{0} \\}\\) will intersect the graph of \\(f\\) in a curve determined by \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, y = y_{0} \\; \\text{and} \\; z = f(x, y_{0}) \\}\\). This curve is the graph of the function \\(z \\, \\colon \\, x \\mapsto f(x, y_{0})\\), see Figures 3.1. We define the partial derivative of \\(f\\) at \\((x_{0}, y_{0})\\) with respect to its first variable \\(x\\) as the ordinary derivative of the function \\(x \\mapsto f(x, y_{0})\\) with respect to \\(x\\) at the point \\(x = x_{0}\\). The definition of the partial derivative of \\(f\\) with respect to its second variable \\(y\\) at the point \\((x_{0}, y_{0})\\) is defined similarly, except we hold \\(x\\) fixed at \\(x_{0}\\) and take the ordinary derivative of \\(y \\mapsto f(x_{0}, y)\\) with respect to \\(y\\) at \\(y_{0}\\). This idea is generalised and formalised for functions of several variables in the following definition. FIGURE 3.1: Illustrution of a curve at the intersection of the vertical plane \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, y = y_{0} \\}\\) and the graph of a function \\(f\\) of two variables, together with the tangent line to the function \\(z = f(x, y_{0})\\) at \\(x = x_{0}\\). Show/hide image source code # Libraries library(plotly) library(Deriv) # Point density # Point density of surface pds^2 pds &lt;- 80 # Point density of level curve pdc &lt;-500 # Point density of plane plds &lt;-150 # Define the function F &lt;- function(ax, by) {1.75 + 0.125*sin(1.5*ax)*sin(by)+1.5*exp(-ax^2)*sin(by)} # Function data set of points t &lt;- seq( 0, 4, length.out=pds) s &lt;- seq( 0, 2*pi, length.out=pds) stgrid&lt;-expand.grid(t=t,s=s) st &lt;-data.frame( a = 2*stgrid$t*cos(stgrid$s), b = stgrid$t*sin(stgrid$s), c = F(2*stgrid$t*cos(stgrid$s), stgrid$t*sin(stgrid$s)), d = 0) # Section in x-direction data set of points tsecx &lt;- 1.5 ssecx &lt;- seq( -7.4, 7.4, length.out=pdc) xsec &lt;-data.frame( a = ssecx, b = tsecx, c = F(ssecx, tsecx), d = 0) # Plane y = 1.5 xt &lt;- seq( -10, 10, length.out=plds) zt &lt;- seq( -0.25, 3.25, length.out=plds) planegrid&lt;-expand.grid(t=xt,s=zt) planest &lt;-data.frame( a = planegrid$t, b = tsecx, c = planegrid$s) # Tangent line to section xm &lt;- -4.4 m &lt;- Deriv(F,&quot;ax&quot;)(xm,tsecx) G &lt;- function(ax) {m*(ax-xm)+F(xm,tsecx)} lvar &lt;- seq( -7.4, -1.5, length.out=pdc) tanl &lt;-data.frame( a = lvar, b = tsecx, c = G(lvar)) # Points xpts &lt;- c(xm, xm) ypts &lt;- c(tsecx,tsecx) zpts &lt;- c(0, G(xm)) pts &lt;- data.frame(xpts, ypts, zpts) # Image annotation Note &lt;- c(&#39;Dom(f)&#39;) xpos &lt;- c(-7.5) ypos &lt;- c(-1) zpos &lt;- c(0) data &lt;- data.frame(Note, xpos, ypos, zpos) # Notept1 &lt;- c(&#39;(x&lt;sub&gt;0&lt;/sub&gt;, y&lt;sub&gt;0&lt;/sub&gt;, 0)&#39;) xptsN1 &lt;- c(xm) yptsN1 &lt;- c(tsecx) zptsN1 &lt;- c(0) data1 &lt;- data.frame(Notept1, xptsN1, yptsN1, zptsN1) # Notept2 &lt;- c(&#39;(x&lt;sub&gt;0&lt;/sub&gt;, y&lt;sub&gt;0&lt;/sub&gt;, f(x&lt;sub&gt;0&lt;/sub&gt;, y&lt;sub&gt;0&lt;/sub&gt;))&#39;) xptsN2 &lt;- c(xm) yptsN2 &lt;- c(tsecx) zptsN2 &lt;- c(G(xm)) data2 &lt;- data.frame(Notept2, xptsN2, yptsN2, zptsN2) # Initial view angle, axis labels and ticks scene = list( xaxis = list(range = c(-10,10), tickvals = c(-8,-6,-4,-2,0,2,4,6,8), title = &quot;x&quot;), yaxis = list(range = c(-5,5), tickvals = c(-4,-3,-2,-1,0,1,2,3,4), title = &quot;y&quot;), zaxis = list(range = c(-0.5,3.5), tickvals = c(-0,0.5,1,1.5,2,2.5,3), title = &quot;z&quot;), camera = list(eye = list(x = -1.1, y = 1.1, z = 0.5))) # Generating the figure fig &lt;- plot_ly() # Surface fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$c, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.6, showscale = FALSE, contour=list(show=TRUE, color=&quot;green&quot;)) # Initial view angle, axis labels, ticks and background fig &lt;- fig %&gt;% layout( scene = scene, hoverlabel = list(font=list(size=8)), paper_bgcolor = &quot;rgba(0,0,0,0)&quot;, plot_bgcolor = &quot;rgba(0,0,0,0)&quot;, legend = list(orientation = &quot;h&quot;, # show entries horizontally xanchor = &quot;center&quot;, # use centre of legend as anchor x = 0.5)) # Plane y = 1.5 fig &lt;- fig %&gt;% add_trace(planest, x = ~planest$a, y = ~planest$b, z = ~planest$c, type = &#39;scatter3d&#39;, mode = &#39;markers&#39;, marker = list(size=1, color = &quot;red&quot;), opacity=0.1, showlegend = FALSE, hoverinfo=&quot;none&quot;) # Domain fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$d, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.25, showscale = FALSE, contour=list(show=FALSE), hoverinfo=&quot;none&quot;) # Annotation fig &lt;- fig %&gt;% add_trace(data, x = ~xpos, y = ~ypos, z = ~zpos, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Note, textposition = &#39;right&#39;, textfont = list(color = c(&quot;lightseagreen&quot;)), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(data1, x = ~xptsN1, y = ~yptsN1, z = ~zptsN1, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Notept1, textposition = &#39;middle right&#39;, textfont = list(color = c(&quot;blue&quot;)), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% add_trace(data2, x = ~xptsN2, y = ~yptsN2, z = ~zptsN2, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = ~Notept2, textposition = &#39;middle left&#39;, textfont = list(color = c(&quot;blue&quot;)), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Section in x-direction fig &lt;- fig %&gt;% add_trace(xsec, x = ~xsec$a, y = ~xsec$b, z = ~xsec$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity = 0.8, line = list(width = 2, color=&quot;red&quot;), showlegend = TRUE, name = &#39;Graph of z = f(x, y&lt;sub&gt;0&lt;/sub&gt;), with y&lt;sub&gt;0&lt;/sub&gt;=1.5&#39;) # # Tangent line to section fig &lt;- fig %&gt;% add_trace(tanl, x = ~tanl$a, y = ~tanl$b, z = ~tanl$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity = 0.8, line = list(width = 2, color=&quot;blue&quot;), showlegend = TRUE, name = &#39;Tangent line to the graph of z = f(x, y&lt;sub&gt;0&lt;/sub&gt;), with y&lt;sub&gt;0&lt;/sub&gt;=1.5&#39;) # Points fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;markers&#39;, marker = list(size=4, color = &quot;blue&quot;), hoverinfo = &quot;none&quot;, showlegend = FALSE) # Trace lines fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.4, line = list(color = &quot;blue&quot;, width = 2, dash = &#39;longdash&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # For positioning of annotation fig &lt;- fig %&gt;% layout() # Print figure fig # Definition 3.1 (partial derivatives) Let \\(n \\geq 2\\) denote a natural number, let \\(D \\subseteq \\mathbb{R}^{n}\\) have non‑empty interior, and let \\(w = (w_{1}, w_{2}, \\dots, w_{n})\\) be an interior point of \\(D\\). If \\(f \\, \\colon \\, D \\to \\mathbb{R}\\) is a function of the independent variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), then the partial derivative of \\(f\\) with respect to \\(x_{j}\\) at \\(w\\) is defined to be \\[\\begin{align} \\frac{\\partial}{\\partial x_{j}} f (w) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\lim_{h \\to 0} \\frac{f(w_{1}, \\dots, w_{j-1}, w_{j} + h, w_{j+1}, \\dots, w_n) - f(w_{1}, \\dots, w_{j-1}, w_{j}, w_{j+1} \\dots, w_n)}{h} \\tag{3.1} \\end{align}\\] provided this limit exists. Observe that in Definition 3.1, as \\(w_{1}\\), \\(w_{2}\\), …, \\(w_{n}\\) are fixed and \\(h\\) is the only variable, we can use the notion of limits of functions of a single variable, and avoid the more complex version given in Definition 2.4. In fact, we can find partial derivatives of functions of several variables, by using our knowledge of derivatives of functions of a single variable. Letting \\(f\\) and \\(w\\) be as in Definition 3.1 and fixing \\(j \\in \\{1, 2, \\dots, n\\}\\), to find the partial derivative of \\(f\\) with respect to \\(x_{j}\\) at \\(w\\), we let \\(x_{i} = w_{i}\\) for all \\(i \\in \\{ 1, 2, \\dots, n\\}\\) with \\(i \\neq j\\) and define a function \\(g\\) of a single variable by \\(g(x) = f(w_{1}, w_{2}, \\dots, w_{j-1}, x, w_{j+1}, \\dots, w_{n})\\), in which case, \\[\\begin{align*} g&#39;(w_{j}) = \\frac{\\partial}{\\partial x_{j}} f (w). \\end{align*}\\] Thus, to find the partial derivative of \\(f\\) with respect to \\(x_{j}\\), we regard \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{j-1}\\), \\(x_{j+1}\\), …, \\(x_{n}\\) as constants and differentiate the function \\(f\\) with respect to \\(x_{j}\\). As in our previous paragraph, suppose that \\(f\\) and \\(D\\) are as in Definition 3.1, then provided that the partial derivative of \\(f\\) with respect to \\(x_{j}\\), for some \\(j \\in \\{1, 2, \\dots, n\\}\\), exists at every point in the interior of \\(D\\), it is again a function of several variable on the interior of \\(D\\), which we denote by \\[\\begin{align*} \\frac{\\partial f}{\\partial x_{j}}, \\quad \\frac{\\partial}{\\partial x_{j}} f, \\quad \\text{or} \\quad \\frac{\\partial}{\\partial x_{j}} (f). \\end{align*}\\] Other notations that we may sometimes use will include \\(f_{x_{j}}\\), \\(f_{j}\\), \\(D_{j} f\\) and \\(D_{j} (f)\\). Exercise 3.1 Let \\(f \\, \\colon \\mathbb{R}^{2} \\to \\mathbb{R}\\) be defined by \\[\\begin{align*} f(x, y) = x^2y^3 - 2x y^2 + 3y, \\end{align*}\\] for all \\((x, y) \\in \\mathbb{R}^{2}\\). Determine the functions \\(f_{x}\\) and \\(f_{y} \\, \\colon \\mathbb{R}^{2} \\to \\mathbb{R}\\), and find the values of \\(f_{x}(3, 2)\\) and \\(f_{y}(3, 2)\\). Show/hide solution Solution. Regarding \\(y\\) as a constant and differentiating with respect to \\(x\\), yields \\[\\begin{align*} f_{x}(x, y) = 2x y^3 - 2y^2, \\end{align*}\\] and regarding \\(x\\) as a constant and differentiating with respect to \\(y\\), yields \\[\\begin{align*} f_{y}(x, y) = 3 x^{2}y^2 - 4 x y + 3. \\end{align*}\\] Substituting \\(x = 3\\) and \\(y = 2\\) into \\(f_{x}(x, y)\\) and \\(f_{y}(x, y)\\) gives \\[\\begin{align*} f_{x}(3, 2) = 2 \\cdot 3 \\cdot 2^3 - 2 \\cdot 2^2 = 40 \\quad \\text{and} \\quad f_{y}(3, 2) = 3 \\cdot 3^{2} \\cdot 2^2 - 4 \\cdot 3 \\cdot 2 + 3 = 87. \\end{align*}\\] Differentiation rules similar to those for functions of a single variable are also true for partial derivatives of functions of several variables. For example the sum, product and quotient rules all transfer over. Indeed, if \\(f\\) and \\(g\\) are functions of the independent variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), for some fixed natural number \\(n \\geq 2\\), and if \\(f_{x_{j}}\\) and \\(g_{x_{j}}\\) exist and share a common domain, then \\[\\begin{align*} \\frac{\\partial}{\\partial x_{j}}(f + g) = \\frac{\\partial f}{\\partial x_{j}} + \\frac{\\partial g}{\\partial x_{j}} \\quad \\text{and} \\quad \\frac{\\partial}{\\partial x_{j}} (f g) = f \\frac{\\partial g}{\\partial x_{j}} + g \\frac{\\partial f}{\\partial x_{j}}, \\end{align*}\\] and, provide \\(g\\) is non-zero in its domain, \\[\\begin{align*} \\frac{\\partial}{\\partial x_{j}} \\left(\\frac{f}{g}\\right) = \\frac{g f_{x_{j}} - f g_{x_{j}}}{g^{2}}. \\end{align*}\\] However, partial derivatives of compositions of functions of several variables, namely a chain rule, becomes more complicated as we will see in our next section. Since the partial derivative of a function of several variables is again a function of several variables we can take further partial derivatives, if they exist. Letting \\(f\\) be as in Definition 3.1, the pure second order partial derivatives of \\(f\\) are of the form \\[\\begin{align*} \\frac{\\partial^2 f}{\\partial x_{j}^{2}} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\partial}{\\partial x_{j}} \\frac{\\partial f}{\\partial x_{j}} \\end{align*}\\] where \\(j \\in \\{ 1, 2, \\dots, n\\}\\); other notations that we may sometimes use include \\(f_{x_{j}x_{j}}\\), \\(f_{jj}\\), \\(D_{jj} f\\) and \\(D_{jj} (f)\\). The mixed second order partial derivatives of \\(f\\) are of the form \\[\\begin{align*} \\frac{\\partial^2 f}{\\partial x_{i} \\partial x_{j}} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\partial}{\\partial x_{i}} \\frac{\\partial f}{\\partial x_{j}}, \\end{align*}\\] where \\(i\\) and \\(j \\in \\{ 1, 2, \\dots, n\\}\\) with \\(i \\neq j\\); other notations that we may sometimes use include \\(f_{x_{j}x_{i}}\\), \\(f_{ji}\\), \\(D_{ji} f\\) and \\(D_{ji} (f)\\); take careful note of the order of the subscript. We can carry on with this notation, for example, a fifth order partial derivative, provided it exists, would have the form \\[\\begin{align*} \\frac{\\partial^{5}f}{\\partial x_{i} \\partial x_{j} \\partial x_{k}^2 \\partial x_{j}} \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\partial}{\\partial x_{i}} \\frac{\\partial}{\\partial x_{j}} \\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\frac{\\partial f}{\\partial x_{j}}, \\end{align*}\\] where \\(i\\), \\(j\\) and \\(k \\in \\{ 1, 2, \\dots, n\\}\\); other notations that we may sometimes use include \\(f_{x_{j}x_{k}x_{k}x_{j}x_{i}}\\) and \\(f_{jkkji}\\); again take careful note of the order of the subscript. The order in which we carry out partial derivatives is important, for instance, if \\(f\\) is a function of two variables \\(x\\) and \\(y\\), it is not necessarily the case that \\(f_{x y}\\) and \\(f_{y x}\\) are equal. The following result, named after the French mathematician Alexis Claude Clairaut, gives a condition for when equality holds. Theorem 3.1 (Clairaut's theorem) Suppose that two mixed \\(n\\)-th ordered partial derivatives of a function \\(f\\) involve the same differentiations, but in different orders. If those partial derivatives are continuous at a point \\(p\\), and if \\(f\\) and all partial derivatives of \\(f\\) of order less than \\(n\\) are continuous in a neighbourhood of \\(p\\), then the two mixed \\(n\\)-th ordered partial derivatives of \\(f\\) at \\(p\\) are equal. In terms of a function \\(f\\) of two variables \\(x\\) and \\(y\\), Clairaut’s theorem states that if \\(f\\), \\(f_{x}\\), \\(f_{y}\\), \\(f_{xy}\\) and \\(f_{yx}\\) are continuous on an open region \\(R\\), then \\(f_{xy} = f_{yx}\\) throughout \\(R\\). The hypotheses of Clairaut’s theorem are satisfied for most functions encountered in calculus and its applications. However, there exists functions which do not satisfy the hypotheses of Clairaut’s theorem, for instance consider the function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\[\\begin{align*} f(x, y) = \\begin{cases} 0 &amp; \\text{if} \\; (x,y) = (0, 0),\\\\[0.5em] \\displaystyle \\frac{xy(x^2 - y^2)}{x^2 + y^2} &amp; \\text{otherwise.} \\end{cases} \\end{align*}\\] Here, all of the second order mixed partial derivatives of \\(f\\) exist, but they are not equal. To show that all second order mixed partial derivatives of \\(f\\) exist at \\((a,b) \\neq (0, 0)\\) one can appeal to the techniques noted above, in particular, when computing the partial derivative of \\(f\\), \\(f_{x}\\) or \\(f_{y}\\) with respect to \\(x\\) to view \\(y\\) as a constant, and when computing the partial derivative of \\(f\\), \\(f_{x}\\) or \\(f_{y}\\) with respect to \\(y\\) to view \\(x\\) as a constant. However, this is not possible when computing the partial derivatives of \\(f\\) at the origin. Here, one needs to prove this from first principles using Definition 3.1. Question Does the converse of Clairaut’s theorem hold? Show/hide solution Solution. The converse of Clairaut’s theorem is false. Consider \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\[\\begin{align*} f(x, y) = \\begin{cases} 0 &amp; \\text{if either} \\; x = 0 \\; \\text{or} \\; y = 0,\\\\[0.5em] x^{2} y^{2} \\sin(1/x)\\sin(1/y) &amp; \\text{otherwise.}\\end{cases} \\end{align*}\\] Here, we have that all second order mixed partial derivatives of \\(f\\) exist and are equal. However, they are not continuous. To show the existence of the second order mixed partial derivatives of \\(f\\) at a point \\((a, b)\\) where \\(a \\neq 0\\) and \\(b \\neq 0\\), we appeal to the techniques noted above, in particular, when computing the partial derivative of \\(f\\), \\(f_{x}\\) or \\(f_{y}\\) with respect to \\(x\\) to view \\(y\\) as a constant, and when computing the partial derivative of \\(f\\), \\(f_{x}\\) or \\(f_{y}\\) with respect to \\(y\\) to view \\(x\\) as a constant. However, this is not possible when computing the partial derivatives of \\(f\\), \\(f_{x}\\) or \\(f_{y}\\) at \\((a, b)\\) with either \\(a = 0\\) or \\(b = 0\\). Here, one needs to prove this from first principles using Definition 3.1. We conclude this section with a very nice link between the continuity of first order partial derivatives of a function \\(f\\) and the continuity of \\(f\\) itself. Theorem 3.2 (continuity and continuity of partial derivaties) If \\(f\\) is a function of \\(n\\) independent variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), for some given natural number \\(n \\geq 2\\), and if \\(f_{x_{j}}\\) is continuous on a open region \\(R\\), for all \\(j \\in \\{ 1, 2, \\dots, n \\}\\), then f is continuous on \\(R\\). Unlike in the setting of functions of a single variable, in Theorem 3.2 the mere existence of \\(f_{x_{j}}\\), for all \\(j \\in \\{ 1, 2, \\dots, n \\}\\) is not enough to guarantee that \\(f\\) is continuous. This can be shown by means of a counterexample. Exercise 3.2 Let \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) be defined by \\[\\begin{align*} f(x, y) = \\begin{cases} \\displaystyle \\frac{xy}{x^2 + y^2} &amp; \\text{if} \\; (x,y) \\neq (0, 0),\\\\[0.5em] 0 &amp; \\text{otherwise.} \\end{cases} \\end{align*}\\] Prove that \\(f_{x}(0, 0)\\) and \\(f_{y}(0, 0)\\) exist, but that \\(f\\) is not continuous at \\((0,0)\\). Show/hide solution Solution. By Definition 3.1 we have that \\[\\begin{align*} f_{x}(0, 0) = \\lim_{h \\to 0} \\frac{f(0+h,0) - f(0,0)}{h} = \\lim_{h \\to 0} \\frac{h\\cdot 0 /(h^{2}+0^2) - 0}{h} = \\lim_{h \\to 0} \\frac{0}{h} = \\lim_{h \\to 0} 0 = 0, \\end{align*}\\] similarly we have that \\[\\begin{align*} f_{y}(0, 0) = \\lim_{h \\to 0} \\frac{f(0,0+h) - f(0,0)}{h} = \\lim_{h \\to 0} \\frac{0\\cdot h /(0^{2}+h^2) - 0}{h} = \\lim_{h \\to 0} \\frac{0}{h} = \\lim_{h \\to 0} 0 = 0. \\end{align*}\\] Therefore, \\(f_{x}(0, 0)\\) and \\(f_{y}(0, 0)\\) exist. To show that \\(f\\) is not continuous at \\((0, 0)\\), let \\(\\epsilon \\in (0, 1/2)\\) be given and let \\(\\delta\\) denote a positive real number. The point \\((x, y) = (\\delta/2, \\delta/2) \\in \\mathbb{B}^{2}((0, 0),\\delta)\\) and \\[\\begin{align*} f(\\delta/2, \\delta/2) = \\frac{(\\delta/2)(\\delta/2)}{(\\delta/2)^{2}+ (\\delta/2)^{2}} = \\frac{1}{2} &gt; \\epsilon, \\end{align*}\\] yielding that \\(f\\) is not continuous at \\((0, 0)\\). "],["thechainrule.html", "3.2 The chain rule", " 3.2 The chain rule The chain rule for functions of a single variable is a formula that gives the derivative of the composition \\(u \\circ v\\) of \\(u\\) with \\(v\\), where both \\(u\\) and \\(v\\) are differentiable functions of a single variable \\(x\\), and \\(\\mathrm{Ran}(v) \\subseteq \\mathrm{Dom}(u)\\), namely \\[\\begin{align} \\frac{\\mathrm{d}}{\\mathrm{d}x} u \\circ v (x) = \\frac{\\mathrm{d}}{\\mathrm{d}x} u(v(x)) = u&#39;(v(x)) v&#39;(x). \\tag{3.2} \\end{align}\\] Here, we extend (3.2) to functions of several variables. In this setting, the chain rule has several forms, and the form will depend on how many variables are involved. Let us consider the following situation. Suppose that \\(f\\) is a function of two variables \\(u\\) and \\(v\\), that the domain of \\(f\\) is a non-empty open region \\(R \\subseteq \\mathbb{R}^{2}\\), and that \\(\\partial f / \\partial u\\) and \\(\\partial f / \\partial v\\) are continuous. Let us also assume that \\(u\\) and \\(v\\) are differentiable functions of a single variable \\(t\\), that \\(u\\) and \\(v\\) are defined on an open set \\(D \\subseteq \\mathbb{R}\\), and that \\(\\{ (u(t), v(t)) \\in \\mathbb{R}^{2} \\, \\colon \\, t \\in D \\}\\) is contained in the interior of \\(R\\). In this case, we have the following chain rule throughout \\(D\\). \\[\\begin{align} \\frac{\\mathrm{d}f}{\\mathrm{d} t} = \\frac{\\partial f}{\\partial u} \\frac{\\mathrm{d}u}{\\mathrm{d}t} + \\frac{\\partial f}{\\partial v} \\frac{\\mathrm{d}v}{\\mathrm{d}t} \\tag{3.3} \\end{align}\\] The tree diagram in Figure 3.2 is a device for remembering the chain rule of (3.3). We first draw branches from \\(f\\) to \\(u\\) and \\(v\\), to indicate that \\(f\\) is a function of \\(u\\) and \\(v\\). Since \\(u\\) and \\(v\\) are a functions of \\(t\\), next we draw branches from \\(u\\) to \\(t\\) and from \\(v\\) to \\(t\\). In this diagram we have also highlighted the various partial derivatives that are involved for the given variables. FIGURE 3.2: Tree diagram for (3.3), where \\(u\\) and \\(v\\) are intermediate variables and \\(t\\) is an independent variable. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=3.5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=2cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$v$} child { node[label=right:{$\\color{Cerulean}t$}] {} edge from parent [Cerulean] node[above] {} node[below=0.25em,black] {$\\frac{\\partial v}{\\partial t}$} } edge from parent [Red] node[above] {} node[below=0.75em, left=0.25em, black] {$\\frac{\\partial f}{\\partial v}$} } child { node[Red] {$u$} child { node[label=right:{$\\color{Cerulean}t$}] {} edge from parent [Cerulean] node[above] {} node[above=0.25em,black] {$\\frac{\\partial u}{\\partial t}$} } edge from parent [Red] node[above=0.75em, left=0.25em, black] {$\\frac{\\partial f}{\\partial u}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} To find the derivative of \\(f\\) with respect to \\(t\\) by means of the diagram we consider all pairs of branches that lead from \\(f\\) to \\(t\\). Here there are two possibilities: \\[\\begin{align*} f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial u} \\quad} u \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} u}{\\mathrm{d} t} \\quad} t \\qquad \\text{and} \\qquad f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial v} \\quad} v \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} v}{\\mathrm{d} t} \\quad} t \\end{align*}\\] Next, we add the products of the corresponding pairs of partial derivatives to obtain (3.3). Exercise 3.3 Let \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) be defined by \\(f(x, y) = \\mathrm{e}^{xy}\\) and suppose that \\(x\\) and \\(y \\, \\colon \\, \\mathbb{R} \\to \\mathbb{R}\\) are defined by \\(x(t) =t^2\\) and \\(y(t) = t^3\\). Using the chain rule given in (3.3), find the derivative of \\(f\\) with respect to \\(t\\). Show/hide solution Solution. To apply the chain rule given in (3.3), we first compute the partial derivative of \\(f\\) with respect to \\(x\\) and with respect to \\(y\\), and the derivatives of \\(x\\) and \\(y\\) with respect to \\(t\\): \\[\\begin{align*} \\frac{\\partial}{\\partial x} f(x, y) = y \\mathrm{e}^{xy} \\qquad \\frac{\\partial}{\\partial y} f(x, y) = x\\mathrm{e}^{xy} \\qquad \\frac{\\mathrm{d}}{\\mathrm{d} t} x(t) = 2 t \\qquad \\frac{\\mathrm{d}}{\\mathrm{d} t} y(t) = 3 t^{2} \\end{align*}\\] Applying the chain rule given in (3.3), yields \\[\\begin{align*} \\frac{\\mathrm{d} }{\\mathrm{d} t} f(x(t),y(t)) &amp;= \\frac{\\partial}{\\partial x} f(x, y) \\frac{\\mathrm{d}}{\\mathrm{d}t} x(t) + \\frac{\\partial}{\\partial y} f(x, y) \\frac{\\mathrm{d}}{\\mathrm{d}t} y(t)\\\\[0.5em] &amp;= (y \\mathrm{e}^{xy})(2 t) + (x\\mathrm{e}^{xy})(3 t^{2})\\\\[0.5em] &amp;= (t^{3} \\mathrm{e}^{t^{2}t^{3}})(2 t) + (t^{2}\\mathrm{e}^{t^{2}t^{3}})(3 t^{2})\\\\[0.5em] &amp;= 2t^{4} \\mathrm{e}^{t^{5}} + 3t^{4} \\mathrm{e}^{t^{5}} = 5t^{4} \\mathrm{e}^{t^{5}}. \\end{align*}\\] Note, after applying the chain rule we substituted for \\(x\\) and \\(y\\), thereby expressing the derivative of \\(f\\) with respect to \\(t\\) as a function of \\(t\\). This is done to emphasise the fact that \\(f\\) is a composite function of the variable \\(t\\). The proof of the equality stated in (3.3) follows in three steps. Note, here, we implicitly assume that \\((u, v)\\) is in the interior of the domain of \\(f\\). First, is to show that \\[\\begin{align} \\frac{\\partial}{\\partial v} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t} v(t) = \\lim_{h \\to 0} \\frac{f(u(t), v(t+h)) - f(u(t), v(t))}{h}. \\tag{3.4} \\end{align}\\] Show/hide proof of (3.4) Proof. For \\(k \\in \\mathbb{R}\\) with \\((u, v + k)\\) in the interior of \\(\\mathrm{Dom}(f)\\), set \\[\\begin{align*} E(k) = \\begin{cases} 0 &amp; \\text{if} \\; k = 0,\\\\[0.5em] \\displaystyle \\frac{f(u, v + k) - f(u, v)}{k} - \\frac{\\partial}{\\partial v} f(u, v) &amp; \\text{otherwise}. \\end{cases} \\end{align*}\\] By definition, \\(\\lim_{k \\to 0} E(k) = 0\\), meaning that \\(E\\) is continuous at zero, and \\[\\begin{align*} f(u, v + k) - f(u, v) = \\left( \\frac{\\partial}{\\partial v} f(u, v) + E(k) \\right) k. \\end{align*}\\] Setting \\(k = k_{h} = v(t + h) - v(t)\\), for \\(h \\in \\mathbb{R}\\) with \\(t + h \\in \\mathrm{Dom}(v)\\), we obtain that \\[\\begin{align*} f(u(t), v(t + h)) - f(u(t), v(t)) = \\left( \\frac{\\partial}{\\partial v} f(u, v) + E(k_{h}) \\right) (v(t + h) - v(t)). \\end{align*}\\] Since \\(v\\) is differentiable, it is continuous, and so \\(\\lim_{h \\to 0} k_{h} = \\lim_{h \\to 0} v(t + h) - v(t) = 0\\). This in tandem with the fact that \\(E\\) is continuous at zero, yields \\(\\lim_{h \\to 0} E(k_{h}) = 0\\). Combining the above with Definition 1.7, we have the following chain of equalities. \\[\\begin{align*} \\lim_{h \\to 0} \\frac{f(u(t), v(t+h)) - f(u(t), v(t))}{h} &amp;= \\lim_{h \\to 0} \\left( \\frac{\\partial}{\\partial v} f(u, v) + E(k_{h}) \\right) \\frac{v(t + h) - v(t)}{h}\\\\[0.5em] &amp;= \\left( \\frac{\\partial}{\\partial v} f(u, v) + \\lim_{h \\to 0} E(k_{h}) \\right) \\lim_{h \\to 0} \\frac{v(t + h) - v(t)}{h}\\\\[0.5em] &amp;= \\left( \\frac{\\partial}{\\partial v} f(u, v) + 0 \\right) \\frac{\\mathrm{d}}{\\mathrm{d}t} v(t) = \\frac{\\partial}{\\partial v} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t} v(t) \\end{align*}\\] Second, is to prove that \\[\\begin{align} \\frac{\\partial}{\\partial u} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t}u(t) =\\lim_{h \\to 0} \\frac{f(u(t+h), v(t+h)) - f(u(t), v(t+h))}{h}. \\tag{3.5} \\end{align}\\] Show/hide proof of (3.5) For \\(l\\) and \\(k \\in \\mathbb{R}\\) with \\((u + l, v + k)\\) and \\((u, v+k)\\) in the interior of \\(\\mathrm{Dom}(f)\\), set \\[\\begin{align*} F(k, l) = \\begin{cases} 0 &amp; \\text{if} \\; l = 0,\\\\[0.5em] \\displaystyle \\frac{f(u + l,v + k) - f(u, v + k)}{l} - \\frac{\\partial}{\\partial u}f(u, v+k) &amp; \\text{otherwise}. \\end{cases} \\end{align*}\\] Since \\(f\\) has continuous first order partial derivatives, \\(F\\) is continuous at \\((0, 0)\\), and \\[\\begin{align*} f(u + l, v + k) - f(u, v + k) = \\left( \\frac{\\partial}{\\partial u} f(u, v+k) + F(k, l) \\right) l. \\end{align*}\\] Setting \\(k = k_{h} = v(t + h) - v(t)\\) and \\(l = l_{h} = u(t + h) - u(t)\\), for \\(h \\in \\mathbb{R}\\) with \\(t + h \\in \\mathrm{Dom}(v) \\cap \\mathrm{Dom}(u)\\), we obtain that \\[\\begin{align*} f(u(t + h), v(t + h)) - f(u(t), v(t + h)) = \\left( \\frac{\\partial}{\\partial u} f(u(t), v(t + h)) + F(k_{h}, l_{h}) \\right) (u(t + h) - u(t)). \\end{align*}\\] Since \\(u\\) and \\(v\\) are differentiable, they are continuous, and so \\(\\lim_{h \\to 0} l_{h} = \\lim_{h \\to 0} u(t + h) - u(t) = 0\\) and \\(\\lim_{h \\to 0} k_{h} = \\lim_{h \\to 0} v(t + h) - v(t) = 0\\). This in tandem with the fact that \\(F\\) is continuous at \\((0, 0)\\) implies \\(\\lim_{h \\to 0} F(k_{h}, l_{h}) = 0\\). Combining the above with Definition 1.7 and the hypothesis that \\(f\\) has continuous partial derivatives, we have the following chain of equalities. \\[\\begin{align*} &amp;\\lim_{h \\to 0} \\frac{f(u(t + h), v(t+h)) - f(u(t), v(t + h))}{h}\\\\ &amp;= \\lim_{h \\to 0} \\left( \\frac{\\partial}{\\partial u} f(u(t), v(t+h)) + F(k_{h}, l_{h}) \\right) \\frac{u(t + h) - u(t)}{h}\\\\[0.5em] &amp;= \\left( \\lim_{h \\to 0} \\frac{\\partial}{\\partial u} f(u(t), v(t+h)) + \\lim_{h \\to 0} F(k_{h}, l_{h}) \\right) \\lim_{h \\to 0} \\frac{u(t + h) - u(t)}{h}\\\\[0.5em] &amp;= \\left( \\frac{\\partial}{\\partial u} f(u(t), v(t)) + 0 \\right) \\frac{\\mathrm{d}}{\\mathrm{d}t} u(t)\\\\ &amp;= \\frac{\\partial}{\\partial u} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t} u(t) \\end{align*}\\] Third, is to combine the first and second steps with Definition 1.7 and the observation that \\(t \\mapsto f(u(t),v(t))\\) is a function of a single variable, to obtain the following chain of equalities. \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}t} f(u(t), v(t)) &amp;= \\lim_{h \\to 0} \\frac{f(u(t+h), v(t+h)) - f(u(t), v(t))}{h}\\\\[0.5em] &amp;= \\lim_{h \\to 0} \\frac{f(u(t+h), v(t+h)) - f(u(t), v(t+h)) + f(u(t), v(t+h)) - f(u(t), v(t))}{h}\\\\[0.5em] &amp;= \\lim_{h \\to 0} \\frac{f(u(t+h), v(t+h)) - f(u(t), v(t+h))}{h} + \\lim_{h \\to 0} \\frac{f(u(t), v(t+h)) - f(u(t), v(t))}{h}\\\\[0.5em] &amp;= \\frac{\\partial}{\\partial u} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t}u(t) + \\frac{\\partial}{\\partial v} f(u, v) \\frac{\\mathrm{d}}{\\mathrm{d}t}v(t). \\end{align*}\\] This yields the required result. In (3.3) we saw how one can formulate a chain rule for the composite function \\(t \\mapsto f(u(t),v(t))\\), where \\(f\\) is a function of two variables \\(u\\) and \\(v\\), which are in turn functions of a single variable \\(t\\). Similar augments to our proof of (3.3) can be used to construct a chain rule for composite functions of any number of variables, and tree diagrams similar Figure 3.2 can be used to help formulate these rules. As an illustration let us consider the following two cases. Case 1 Suppose that \\(f\\) is a function in the variables \\(u\\) and \\(v\\), and that \\(u\\) and \\(v\\) are in turn functions of the variables \\(x\\), \\(y\\) and \\(z\\), as indicated in Figure 3.3. Assuming that all relevant partial derivatives exist and are continuous, to find \\(\\partial f/ \\partial x\\), we take the pairs of products of the partial derivatives that lead from \\(f\\) to \\(x\\) and add: \\[\\begin{align} \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial f}{\\partial v} \\frac{\\partial v}{\\partial x}. \\tag{3.6} \\end{align}\\] Similarly, to find \\(\\partial f/ \\partial y\\), assuming that all relevant partial derivatives exist and are continuous, we take the pairs of products of the partial derivatives that lead from \\(f\\) to \\(y\\) and add: \\[\\begin{align} \\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial f}{\\partial v} \\frac{\\partial v}{\\partial y}. \\tag{3.7} \\end{align}\\] Likewise, to find \\(\\partial f/ \\partial z\\), assuming that all relevant partial derivatives exist and are continuous, we take the pairs of products of the partial derivatives that lead from \\(f\\) to \\(z\\) and add: \\[\\begin{align} \\frac{\\partial f}{\\partial z} = \\frac{\\partial f}{\\partial u} \\frac{\\partial u}{\\partial z} + \\frac{\\partial f}{\\partial z} \\frac{\\partial v}{\\partial z}. \\tag{3.8} \\end{align}\\] Note, here our composite function \\((x,y,z) \\mapsto f(u(x,y,z), v(x, y, z))\\) is a function of several variables, and so unlike in (3.3) where we took the derivative with respect to \\(t\\), here, we take partial derivatives. FIGURE 3.3: Tree diagram for (3.6)–(3.8), where \\(u\\) and \\(v\\) are intermediate variables, and \\(x\\), \\(y\\) and \\(z\\) are independent variable. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=1.5cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$v$} child { node[label=right:{$\\color{Cerulean}z$}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial v}{\\partial z}$} } child { node[label=right:{$\\color{Cerulean}y$}] {} edge from parent [Cerulean] node[above=0.875em,right=0.1em,black] {$\\frac{\\partial v}{\\partial y}$} node[below] {} } child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial v}{\\partial x}$} node[below] {} } edge from parent [Red] node[above] {} node[below=0.5em, left=0.25em, black] {$\\frac{\\partial f}{\\partial v}$} } child { node[Red] {$u$} child { node[label=right:{{$\\color{Cerulean}z$}}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial u}{\\partial z}$} } child { node[label=right:{$\\color{Cerulean}y$}] {} edge from parent [Cerulean] node[above=0.875em,right=0.1em,black] {$\\frac{\\partial u}{\\partial y}$} node[below] {} } child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial u}{\\partial x}$} node[below] {} } edge from parent [Red] node[above=0.5em, left= 0.25em, black] {$\\frac{\\partial f}{\\partial u}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} Case 2 Suppose that \\(g\\) is a function in the variables \\(u\\), \\(v\\) and \\(r\\), and that \\(u\\), \\(v\\) and \\(r\\) are each functions of \\(x\\) and \\(y\\), as indicated in Figure 3.4. Assuming that all relevant partial derivatives exist and are continuous, to find \\(\\partial g/ \\partial x\\), we take the pairs of products of the partial derivatives that lead from \\(g\\) to \\(x\\) and add: \\[\\begin{align} \\frac{\\partial g}{\\partial x} = \\frac{\\partial g}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial g}{\\partial v} \\frac{\\partial v}{\\partial x} + \\frac{\\partial g}{\\partial r} \\frac{\\partial r}{\\partial x}. \\tag{3.9} \\end{align}\\] Similarly, assuming that all relevant partial derivatives exist and are continuous, to find \\(\\partial g/ \\partial y\\), we take the pairs of products of the partial derivatives that lead from \\(g\\) to \\(y\\) and add: \\[\\begin{align} \\frac{\\partial g}{\\partial y} = \\frac{\\partial g}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial g}{\\partial v} \\frac{\\partial v}{\\partial y} + \\frac{\\partial g}{\\partial r} \\frac{\\partial r}{\\partial y}. \\tag{3.10} \\end{align}\\] As in our previous case, here our composite function \\((x,y) \\mapsto g(u(x,y), v(x, y), r(x, y))\\) is a function of several variables, and so unlike in (3.3) where we took the derivative with respect to \\(t\\), here, we take partial derivatives. FIGURE 3.4: Tree diagram for (3.9) and (3.10), where \\(u\\), \\(v\\) and \\(r\\) are intermediate variables, and \\(x\\) and \\(y\\) are independent variable. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=3.5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=2cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$r$} child { node[label=right:{$\\color{Cerulean}y$}] {} edge from parent [Cerulean] node[above] {} node[below=0.25em,black] {$\\frac{\\partial r}{\\partial y}$} } child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above=0.25em,black] {$\\frac{\\partial r}{\\partial x}$} node[below] {} } edge from parent [Red] node[above] {} node[below=0.5em, left=0.25em, black] {$\\frac{\\partial f}{\\partial r}$} } child { node[Red] {$v$} child { node[label=right:{$\\color{Cerulean}y$}] {} edge from parent [Cerulean] node[above] {} node[below=0.25em,black] {$\\frac{\\partial v}{\\partial y}$} } child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above=0.25em,black] {$\\frac{\\partial v}{\\partial x}$} node[below] {} } edge from parent [Red] node[above, black] {$\\frac{\\partial f}{\\partial v}$} node[below] {} } child { node[Red] {$u$} child { node[label=right:{{$\\color{Cerulean}y$}}] {} edge from parent [Cerulean] node[above] {} node[below=0.25em, black] {$\\frac{\\partial v}{\\partial x}$} } child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above=0.25em, black] {$\\frac{\\partial v}{\\partial x}$} node[below] {} } edge from parent [Red] node[above=0.5em, left= 0.25em, black] {$\\frac{\\partial f}{\\partial r}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} The theorem below formalises the idea discussed in this section; the proof of which follows along the same lines as that of (3.3). Theorem 3.3 (chain rule for functions of several variables) Let \\(m\\) and \\(n\\) denote two natural numbers. Suppose that \\(f\\) is a function of \\(n\\) real variables, \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), with continuous partial derivative with respect to \\(x_{i}\\) throughout a non-empty open region \\(R \\subseteq \\mathbb{R}^{n}\\), for all \\(i \\in \\{ 1, 2, \\dots, n \\}\\), each \\(x_j\\) is a function of \\(m\\) real variables, \\(t_{1}, t_{2}, \\dots, t_{m}\\), with continuous partial derivative with respect to \\(t_{i}\\) throughout a non-empty open set \\(D \\subseteq \\mathbb{R}^{m}\\), for all \\(i \\in \\{ 1, 2, \\dots, m\\}\\), and \\(\\{ (x_{1}(t_{1}, \\dots, t_{m}), \\dots, x_{n}(t_{1}, \\dots, t_{m})) \\in \\mathbb{R}^{n} \\, \\colon \\, (t_{1}, \\dots, t_{m}) \\in D \\} \\subseteq R\\). For all \\(i \\in \\{1, 2, \\dots, m \\}\\), the partial derivative of \\(f\\) with respect to \\(t_{i}\\) is given by \\[\\begin{align*} \\frac{\\partial f}{\\partial t_{i}} = \\frac{\\partial f}{\\partial x_{1}} \\frac{\\partial x_{1}}{\\partial t_{i}} + \\frac{\\partial f}{\\partial x_{2}} \\frac{\\partial x_{2}}{\\partial t_{i}} + \\dots + \\frac{\\partial f}{\\partial x_{n}} \\frac{\\partial x_{n}}{\\partial t_{i}}. \\end{align*}\\] "],["implicitdifferentiation.html", "3.3 Implicit differentiation", " 3.3 Implicit differentiation Partial differentiation and the chain rule can be used to find the derivatives of functions that are defined implicitly. As an example, consider a function \\(f\\) of two variables \\(x\\) and \\(y\\), and suppose that the partial derivatives of \\(f\\) are continuous throughout an open region \\(R \\subseteq \\mathbb{R}^{2}\\). Consider the equation \\(f(x, y) = 0\\) and let us assume that this gives rise to a function \\(v\\), such that \\(y = v(x)\\), that is \\(f(x, v(x)) = 0\\), for all \\(x \\in \\mathrm{Dom}(v)\\). Our aim is to determine the derivative of \\(v\\) using partial derivatives and the chain rule. To this end, let \\(u\\) denote the identity function on real line, that is \\(u(x) = x\\) and consider the composite function \\(w \\colon x \\mapsto f(u(x), v(x))\\) for which we have the tree diagram in Figure 3.5. FIGURE 3.5: Tree diagram for the composite function \\(x \\mapsto f(u(x), v(x))\\), where \\(u\\) and \\(v\\) are intermediate variables, and \\(x\\) is an independent variable. Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=3.5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=2cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$v$} child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above] {} node[below=0.25em,black] {$\\frac{\\partial v}{\\partial x}$} } edge from parent [Red] node[above] {} node[below=0.75em, left=0.25em, black] {$\\frac{\\partial f}{\\partial v}$} } child { node[Red] {$u$} child { node[label=right:{$\\color{Cerulean}x$}] {} edge from parent [Cerulean] node[above] {} node[above=0.25em,black] {$\\frac{\\partial u}{\\partial x}$} } edge from parent [Red] node[above=0.75em, left=0.25em, black] {$\\frac{\\partial f}{\\partial u}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} Applying the chain rule gives that \\[\\begin{align*} \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial u} \\frac{\\mathrm{d}u}{\\mathrm{d}x} + \\frac{\\partial f}{\\partial v} \\frac{\\mathrm{d}v}{\\mathrm{d}x}. \\end{align*}\\] Since \\(f(u(x),v(x)) = w(x) = 0\\) and since \\(u(x) = x\\), it follows that \\(\\mathrm{d}w/\\mathrm{d}x = 0\\) and \\(\\mathrm{d}u/\\mathrm{d}x = 1\\), and hence \\[\\begin{align*} 0 = \\frac{\\partial f}{\\partial u} + \\frac{\\partial f}{\\partial v} \\frac{\\mathrm{d}v}{\\mathrm{d}x}, \\end{align*}\\] on the set of points \\(\\{ (x,y) \\colon f(x,y) = 0 \\}\\). If \\(\\partial f / \\partial v\\) is non-zero, rearranging the above equality yields \\[\\begin{align*} \\frac{\\mathrm{d}v}{\\mathrm{d}x} = -\\frac{\\partial f / \\partial u}{\\partial f / \\partial v}. \\end{align*}\\] Namely, we have the following corollary. Corollary 3.1 Let \\(f\\) be a function of two variables \\(x\\) and \\(y\\), and suppose that the partial derivatives of \\(f\\) are continuous throughout a non-empty open region \\(R \\subseteq \\mathbb{R}^{2}\\). If \\(f(x, y) = 0\\) determines, implicitly, \\(y\\) as a differentiable function of \\(x\\), then \\[\\begin{align*} \\frac{\\partial f}{\\partial y}\\frac{\\mathrm{d}y}{\\mathrm{d}x} = - \\frac{\\partial f}{\\partial x}. \\end{align*}\\] An analogous result exists for when \\(f\\) is a function of three variables, \\(x\\), \\(y\\) and \\(z\\), and where \\(f(x, y, z) = 0\\) determines \\(z\\) implicitly as a function of \\(x\\) and \\(y\\). The proof of this result follows along the same lines as that of Corollary 3.1 above, where one uses a tree diagram with the same structure as Figure 3.4. Corollary 3.2 Let \\(f\\) be a function of three variables \\(x\\), \\(y\\) and \\(z\\), and suppose that the partial derivatives of \\(f\\) are continuous throughout a non-empty open region \\(R \\subseteq \\mathbb{R}^{3}\\). If \\(f(x, y, z) = 0\\) determines, implicitly, \\(z\\) as a function of \\(x\\) and \\(y\\) whose partial derivatives are continuous, then \\[\\begin{align*} \\frac{\\partial f}{\\partial z} \\frac{\\partial z}{\\partial x} = - \\frac{\\partial f}{\\partial x} \\quad \\text{and} \\quad \\frac{\\partial f}{\\partial z} \\frac{\\partial z}{\\partial y} = - \\frac{\\partial f}{\\partial y}. \\end{align*}\\] "],["pde.html", "3.4 Partial differential equations", " 3.4 Partial differential equations In this section by way of an example, let us consider an applications of the chain rule and implicit differentiation in solving a given partial differential equations. Partial differential equations are ubiquitous in the mathematically sciences. They are foundational in the understanding of sound, heat, diffusion, electrostatics, electrodynamics, fluid dynamics, elasticity, general relativity, and quantum mechanics. They also arise from many areas of pure mathematics, such as differential geometry, the calculus of variations, and geometric topology. A partial differential equation (PDE) is an equation which imposes relations between the various partial derivatives of a function of several variables. The function is often thought of as an unknown to be solved for, similarly to how \\(x\\) is thought of as an unknown number, to be solved for, in an algebraic expression like \\(x^{2} - x - 1 = 0\\). For instance, one may define a function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) via the partial differential equation \\[\\begin{align} x \\frac{\\partial f}{\\partial x} + y \\frac{\\partial f}{\\partial y} = x^2+y^2, \\tag{3.11} \\end{align}\\] and ask the question, what is \\(f\\)? Let us examine how we might go about solving this PDE using the chain rule, implicit differentiation and polar coordinates. The polar representation \\((r, \\theta)\\) of a Cartesian point \\((x, y)\\) is given by \\(x = r \\cos(\\theta)\\), \\(y = r \\sin(\\theta)\\), \\(r^{2} = x^{2} + y^{2}\\) and \\(\\tan(\\theta) = y/x\\). (Note, we may assume that \\(x \\neq 0\\), for if \\(x = 0\\), then (3.11) becomes a first order ordinary differential equation, with solution \\(f(0, y) = y^{2}/2 + c\\), where \\(c\\) is a constant to be determined by an initial condition.) With this, we may write \\(f\\) as a function \\(g\\) of the polar coordinates \\(r\\) and \\(\\theta\\), so that \\(f(x,y)=g(r(x,y),\\theta(x,y))\\), in which case \\[\\begin{align*} \\frac{\\partial f}{\\partial x} = \\frac{\\partial g}{\\partial x} = \\frac{\\partial g}{\\partial r} \\frac{\\partial r}{\\partial x} + \\frac{\\partial g}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial x} \\qquad \\text{and} \\qquad \\frac{\\partial f}{\\partial y} = \\frac{\\partial g}{\\partial y} = \\frac{\\partial g}{\\partial r} \\frac{\\partial r}{\\partial y} + \\frac{\\partial g}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial y}. \\end{align*}\\] Since \\(r^{2} = x^{2} + y^{2}\\) and \\(\\tan(\\theta) = y/x\\), differentiating implicitly yields \\[\\begin{align} 2 r r_{x} = 2 x, \\qquad 2 r r_{y} = 2 y, \\qquad \\sec^{2}(\\theta) \\theta_{x} = -y/x^{2} \\qquad \\text{and} \\qquad \\sec^{2}(\\theta) \\theta_{y} = 1/x. \\tag{3.12} \\end{align}\\] Note, we may assume that \\(r \\neq 0\\), for if \\(r = 0\\), then \\(x^{2} + y^{2} = 0\\) and so \\(x = y = 0\\), in this case, any function whose partial derivatives exist will satisfy (3.11) at \\((0, 0)\\). This, together with (3.11) and the observation \\[\\begin{align*} \\sec^{2}(\\theta) = 1 + \\tan^{2}(\\theta) = 1 + (y/x)^{2} = (x^{2} + y^{2})/x^{2}, \\end{align*}\\] yields that \\(r_{x} = x/r\\), \\(r_{y} = y/r\\), \\(\\theta_{x} = -y/(x^{2} + y^{2})\\) and \\(\\theta_{y} =x/(x^{2} + y^{2})\\). Hence, \\[\\begin{align*} \\frac{\\partial f}{\\partial x} = \\frac{\\partial g}{\\partial r} \\frac{x}{r} + \\frac{\\partial g}{\\partial \\theta} \\frac{-y}{x^{2} + y^{2}} \\qquad \\text{and} \\qquad \\frac{\\partial f}{\\partial y} = \\frac{\\partial g}{\\partial r} \\frac{y}{r} + \\frac{\\partial g}{\\partial \\theta} \\frac{x}{x^{2} + y^{2}}, \\end{align*}\\] and therefore \\[\\begin{align*} x^{2} + y^{2} = x \\frac{\\partial f}{\\partial x} + y \\frac{\\partial f}{\\partial y} = \\frac{x^{2}} r \\frac{\\partial g}{\\partial r} - \\frac{xy}{x^{2} + y^{2}} \\frac{\\partial g}{\\partial \\theta} + \\frac{y^{2}} r \\frac{\\partial g}{\\partial r} + \\frac{xy}{x^{2} + y^{2}} \\frac{\\partial g}{\\partial \\theta} = \\frac{x^{2} + y^{2}} r \\frac{\\partial g}{\\partial r}. \\end{align*}\\] In other words, \\(g_{r} = r\\). Integrating both sides of this equation with respect to \\(r\\) gives \\[\\begin{align*} g (r, \\theta) = r^{2}/2 + l(\\theta) \\end{align*}\\] where \\(l\\) is a arbitrary differentiable function dependent on \\(\\theta\\), and thus setting \\(h = l \\circ \\arctan\\), we have \\[\\begin{align*} f(x,y) = (x^{2}+y^{2})/2 + h(y/x) \\end{align*}\\] is a general solution to (3.11). In order to completely solve the problem we would require further data, name a boundary condition and an initial condition. "],["directionalderivative.html", "3.5 Directional derivative", " 3.5 Directional derivative In Chapter 2 we highlighted that a practical application of level curves is in the making of topographic maps. When studying such maps (see Figures 3.6), it becomes apparent that streams flow perpendicular to contour lines. Indeed, streams tend to follow paths of steepest decent, so that the water reaches lowest elevation (typically sea level) as quickly as possible. Therefore, the fastest instantaneous rate of change in a stream’s elevation above sea level has a particular direction. The theory we will build in this section will show why this direction is perpendicular to the contours. FIGURE 3.6: Contours within the Cullin Ridge on the Isle of Syke show streams, which follow paths of steepest decent, running perpendicular to the contours. Show/hide image source code ## Interactive web application generated using r library leaflet ## #Libraries library(leaflet) # Generating the figure fig &lt;- leaflet() %&gt;% # Set coordinates setView(lng =-6.22, lat = 57.225, zoom = 12)%&gt;% # Adds topography addProviderTiles(providers$OpenTopoMap, group=&#39;Topo&#39;) # Returns topographic map fig # Let \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) denote a function of two variables whose partial derivatives exist and are continuous, and consider a smooth parametric curve \\(C\\) in the plane, for instance the curve pictured in Figure 1.2(c), given by \\(x = g(t)\\) and \\(y = h(t)\\), for \\(t\\) belonging to some closed interval \\(I\\). The chain rule allows us to compute the rate at which \\(f\\) changes with respect to \\(t\\), in the interior of \\(I\\), along \\(C\\), namely \\[\\begin{align*} \\frac{\\mathrm{d}f}{\\mathrm{d}t} = \\frac{\\partial f}{\\partial x}\\frac{\\mathrm{d} x}{\\mathrm{d} t} + \\frac{\\partial f}{\\partial y} \\frac{\\mathrm{d}y}{\\mathrm{d}t}. \\end{align*}\\] From this, we see that the rate of change of \\(f\\) with respect to increasing \\(t\\) depends on the direction of motion along \\(C\\). Now let us suppose that our parametric curve is a straight line segment connecting a point \\((x_{1}, x_{2}) \\in \\mathbb{R}^{2}\\) to a point \\((p_{1}, p_{2}) \\in \\mathbb{R}^{2}\\) with \\(\\lvert (x_{1}, x_{2}) - (p_{1}, p_{2}) \\rvert = 1\\). Letting \\(\\mathbf{u}\\) denote the unit vector \\((p_{1} - x_{1}) \\mathbf{i} + (p_{2} - x_{2}) \\mathbf{j}\\), we obtain that \\(\\mathrm{d}f / \\mathrm{d}t\\), at \\((x_{1}, x_{2})\\), is the rate of change of \\(f\\) at \\((x_{1}, x_{2})\\) in the direction of \\(\\mathbf{u}\\), see Figure 3.7. FIGURE 3.7: A unit vector \\(\\mathbf{u}\\) in the \\(x\\)-\\(y\\) plane, determining a line \\(L\\) which passes through the point \\((a, b)\\) in the domain of a function \\(f\\) of two variables. The vertical plane containing \\(L\\) and parallel to the \\(z\\)-axis intersects the graph of \\(f\\) in a curve \\(C\\) whose tangent line \\(T\\) at \\((a,b,f(a,b))\\) has gradient \\(D_{\\mathbf{u}}f(a,b)\\). Show/hide image source code ## Interactive web application generated using r library leaflet ## # Libraries library(plotly) # Point density # Point density of surface pds^2 pds &lt;- 80 # Point density of level curve pdc &lt;-500 # Define the function F &lt;- function(ax, by) {1.75 + 0.125*sin(1.5*ax)*sin(by)+1.5*exp(-ax^2)*sin(by)} # Function data set of points t &lt;- seq( 0, 4, length.out=pds) s &lt;- seq( 0, 2*pi, length.out=pds) stgrid&lt;-expand.grid(t=t,s=s) st &lt;-data.frame( a = 2*stgrid$t*cos(stgrid$s), b = stgrid$t*sin(stgrid$s), c = F(2*stgrid$t*cos(stgrid$s), stgrid$t*sin(stgrid$s)), d = 0) # Curve in the direction of (i - j)/sqrt{2} tsecy &lt;- seq(-2.75, 4.34, length.out=pdc) ysec &lt;-data.frame( a = tsecy, b = 1-tsecy, c = F(tsecy, 1-tsecy), d = 0) # Tangent line ssecy &lt;- seq(-1.25, 0, length.out=pdc/2) xsec &lt;-data.frame( a = ssecy, b = 1-ssecy, c = 1.22551*ssecy + F(-0.5, 1.5) - 1.22551*(-0.5)) # Image annotation # Points Notepts &lt;- c(&#39;(a, b, 0)&#39;,&#39;(a, b, f(a,b))&#39;) xpts &lt;- c(-0.5, -0.5) ypts &lt;- c(1.5, 1.5) zpts &lt;- c(0, F(-0.5,1.5)) pts &lt;- data.frame(Notepts, xpts, ypts, zpts) # Initial view angle, axis labels and ticks scene = list( xaxis = list(range = c(-10,10), tickvals = c(-8,-6,-4,-2,0,2,4,6,8), title = &quot;x&quot;), yaxis = list(range = c(-5,5), tickvals = c(-4,-3,-2,-1,0,1,2,3,4), title = &quot;y&quot;), zaxis = list(range = c(-0.5,3.5), tickvals = c(-0,0.5,1,1.5,2,2.5,3), title = &quot;z&quot;), camera = list(eye = list(x = -1.1, y = 1.1, z = 0.5))) # Generating the figure fig &lt;- plot_ly() # Surface fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$c, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.6, showscale = FALSE, contour=list(show=TRUE, color=&quot;green&quot;)) #Vector fig &lt;- fig %&gt;% add_trace( type= &quot;cone&quot;, x= -1.5, y=2.5 , z= 0, u= -1, v= 1, w= 0, showscale = FALSE) fig &lt;- fig %&gt;% add_trace(x = c(-0.5,-1.5), y = c(1.5,2.5), z = c(0,0), type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 4), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Initial view angle, axis labels, ticks and background fig &lt;- fig %&gt;% layout( scene = scene, hoverlabel = list(font=list(size=8)), paper_bgcolor = &quot;rgba(0,0,0,0)&quot;, plot_bgcolor = &quot;rgba(0,0,0,0)&quot;, legend = list(orientation = &quot;h&quot;, # show entries horizontally xanchor = &quot;center&quot;, # use centre of legend as anchor x = 0.5)) # Domain fig &lt;- fig %&gt;% add_trace(st, x = ~st$a, y = ~st$b, z = ~st$d, intensity = ~st$c, type = &#39;mesh3d&#39;, opacity=0.2, showscale = FALSE, contour=list(show=TRUE, color=&quot;green&quot;)) # Annotation #Domain fig &lt;- fig %&gt;% add_trace(data, x = -7.5, y = -1, z = 0, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = &#39;Dom(f)&#39;, textposition = &#39;right&#39;, textfont = list(color =&quot;lightseagreen&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) #Line L fig &lt;- fig %&gt;% add_trace(x =1.25, y =-0.25, z = 0, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = &#39;L&#39;, textposition = &#39;right&#39;, textfont = list(color =&quot;orange&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) #Vector u fig &lt;- fig %&gt;% add_trace(x =-1, y =2.1, z = 0, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = &#39;u&#39;, textposition = &#39;right&#39;, textfont = list(color =&quot;green&quot;, font = 2), showlegend = FALSE, hoverinfo=&quot;none&quot;) #Curve C fig &lt;- fig %&gt;% add_trace(x =-1.8, y =3.5, z = 1.9, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = &#39;C&#39;, textposition = &#39;above&#39;, textfont = list(color =&quot;red&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) #Tangent line fig &lt;- fig %&gt;% add_trace(x =0.18, y =1.5, z = 3.2, type = &#39;scatter3d&#39;, mode = &#39;text&#39;, text = &#39;T&#39;, textfont = list(color =&quot;blue&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Curve in the direction of (i - j)/sqrt{2} fig &lt;- fig %&gt;% add_trace(ysec, x = ~ysec$a, y = ~ysec$b, z = ~ysec$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;red&quot;), showlegend = FALSE) fig &lt;- fig %&gt;% add_trace(ysec, x = ~ysec$a, y = ~ysec$b, z = ~ysec$d, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity = 0.6, line = list(width = 2, color=&quot;orange&quot;), showlegend = FALSE) # Tangent fig &lt;- fig %&gt;% add_trace(xsec, x = ~xsec$a, y = ~xsec$b, z = ~xsec$c, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, line = list(width = 2, color=&quot;blue&quot;), showlegend = FALSE) # Points fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;text+markers&#39;, marker = list(size=3, color = &quot;blue&quot;), text = ~Notepts, textposition = list(&#39;bottom left&#39;), textfont = list(color = &quot;blue&quot;), showlegend = FALSE, hoverinfo=&quot;none&quot;) # Line connecting points fig &lt;- fig %&gt;% add_trace(pts, x = ~pts$xpts, y = ~pts$ypts, z = ~pts$zpts, type = &#39;scatter3d&#39;, mode = &#39;lines&#39;, opacity=0.4, line = list(color = &quot;blue&quot;, width = 2, dash = &#39;longdash&#39;), showlegend = FALSE, hoverinfo=&quot;none&quot;) fig &lt;- fig %&gt;% layout() # Print figure fig # We formalise this idea in the following definition. Definition 3.2 (directional derivatives) Let \\(n \\geq 2\\) be a natural number, let \\(R\\) be a non-empty open region of \\(\\mathbb{R}^{n}\\), let \\(x = (x_{1}, x_{2}, \\dots, x_{n}) \\in R\\) and let \\(\\mathbf{u}\\) be a given non‑zero vector in \\(\\mathbb{R}^{n}\\). Denoting the unit vector in the direction of \\(\\mathbf{u}\\) by \\(\\widehat{\\mathbf{u}} = \\langle u_{1}, u_{2}, \\dots, u_{n} \\rangle\\) and letting \\(f \\, \\colon \\, R \\to \\mathbb{R}\\), the derivative of \\(f\\) at \\(x\\) in the direction of \\(\\mathbf{u}\\), is the limit \\[\\begin{align*} D_{\\mathbf{u}}f (x) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\lim_{h \\to 0} \\frac{f(x_{1}+h u_{1}, \\dots, x_{n} + h u_{n}) - f(x_{1}, \\dots, x_{n})}{h}, \\end{align*}\\] provided that the limit exist. In the setting of the above definition, if the directional derivative of \\(f\\) in the direction of \\(\\mathbf{u}\\) exists throughout \\(R\\), then \\(x \\mapsto D_{\\mathbf{u}}f(x)\\) is a function of several variables with domain \\(R\\), which we denote by \\(D_{\\mathbf{u}}f\\). In this way, the directional derivative can be thought of as a linear operator \\(D_{\\mathbf{u}}\\), namely, if \\(f\\) and \\(g\\) are two functions of \\(n\\) variables, and \\(\\lambda\\) and \\(\\mu\\) are two scalars (real numbers), then \\[\\begin{align*} D_\\mathbf{u}(\\lambda f+\\mu g) = \\lambda D_\\mathbf{u} f + \\mu D_\\mathbf{u} g, \\end{align*}\\] provided that the given directional derivatives exist. Also, observe that \\(D_{\\mathbf{u}}f = -D_{-\\mathbf{u}}f\\), again, provided that the given directional derivatives exist. Still keeping to the setting of Definition 3.2, letting \\(j \\in \\{ 1, 2, \\dots, n \\}\\) and setting \\(u_{i} = 1\\) if \\(i = j\\), and \\(0\\) otherwise, the directional derivative of \\(f\\) in the direction of \\(\\mathbf{u}\\), if it exists, is the partial derivative of \\(f\\) with respect to \\(x_{j}\\). In particular, when \\(n = 2\\), and \\(g\\) is a function of two variable \\(x\\) and \\(y\\), \\[\\begin{align*} D_{\\mathbf{i}}g = \\frac{\\partial g}{\\partial x} \\quad \\text{and} \\quad D_{\\mathbf{j}}g = \\frac{\\partial g}{\\partial y}, \\end{align*}\\] and when \\(n = 3\\), and \\(h\\) is a function of three variable \\(x\\), \\(y\\) and \\(z\\), \\[\\begin{align*} D_{\\mathbf{i}}h = \\frac{\\partial h}{\\partial x} \\quad \\quad D_{\\mathbf{j}}h = \\frac{\\partial h}{\\partial y} \\quad \\text{and} \\quad D_{\\mathbf{k}}h = \\frac{\\partial h}{\\partial z} \\end{align*}\\] provided the involved partial derivatives exist. When computing directional derivatives, as in the case of derivatives of functions of a single variable, and partial derivatives of functions of several variables, we use our knowledge of known derivatives and powerful techniques (for instance, the product, quotient and chain rule) as much as possible, and only revert to first principles when absolutely necessary. Therefore, let us investigate how we may apply such techniques when calculating directional derivatives. Proposition 3.1 Let \\(n \\geq 2\\) be a natural number, \\(R \\subseteq \\mathbb{R}^{n}\\) be non-empty and open, \\(f \\, \\colon \\, R \\to \\mathbb{R}\\) denote a function of \\(n\\) variables, \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), and \\(\\mathbf{u} = \\langle u_{1}, u_{2}, \\dots, u_{n} \\rangle\\) be a unit vector in \\(\\mathbb{R}^{n}\\). If \\(a = (a_{1}, a_{2}, \\dots, a_{n})\\in R\\) and if the limits exist, then \\[\\begin{align*} D_{\\mathbf{u}} f(a) = \\frac{\\mathrm{d}}{\\mathrm{d}t} f(a + tu)) \\bigg\\vert_{t=0,} \\end{align*}\\] where \\(u = (u_{1}, u_{2}, \\dots, u_{n})\\) is the terminal point of the vector \\(\\mathbf{u}\\). Show/hide proof Proof. From the definition of the derivative of a function of single variable (Definition 1.7) and the definition of the directional derivative (Definition 3.2) we have the following chain of equalities. \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}t} f(a + tu)\\bigg\\vert_{t=0} &amp;= \\lim_{h \\to 0} \\frac{f (a_{1}+(t+h)u_{1}, \\dots, a_{n}+(t+h)u_{n})) - f(a_{1}+tu_{1}, \\dots, a_{n}+tu_{n})}{h} \\bigg\\vert_{t=0}\\\\[0.5em] &amp;= \\lim_{h \\to 0} \\frac{f (a_{1}+ h u_{1}, \\dots, a_{n}+ h u_{n}) - f(a_{1}, a_{2}, \\dots, a_{n})}{h} = D_{\\mathbf{u}} f(a) \\end{align*}\\] The above proposition tells us that \\[\\begin{align*} D_{\\mathbf{u}} f(a) = \\frac{\\mathrm{d}}{\\mathrm{d}t} f(a + tu) \\bigg\\vert_{t=0,} \\end{align*}\\] but by the chain rule, \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}t} f(a + tu) = \\frac{\\mathrm{d}}{\\mathrm{d}t} f(a_{1} + t u_{1}, \\dots, a_{n} + t u_{n}) = \\sum_{k = 1}^{n} \\frac{\\mathrm{d}}{\\mathrm{d}t} (a_{k} + t u_{k}) \\frac{\\partial}{\\partial x_{k}} f(a + t u) = \\sum_{k = 1}^{n} u_{k} \\frac{\\partial}{\\partial x_{k}} f(a + t u). \\end{align*}\\] This implies that \\[\\begin{align} D_{\\mathbf{u}} f(a) = \\mathbf{u} \\cdot \\left( \\frac{\\partial}{\\partial x_{1}} f(a) \\mathbf{x}_{1} + \\frac{\\partial}{\\partial x_{2}} f(a) \\mathbf{x}_{2} + \\dots + \\frac{\\partial}{\\partial x_{n}} f(a) \\mathbf{x}_{n} \\right), \\tag{3.13} \\end{align}\\] where \\(\\mathbf{x}_{1} = \\langle 1, 0, 0 \\dots, 0 \\rangle\\), \\(\\mathbf{x}_{2} = \\langle 0, 1, 0 \\dots, 0 \\rangle\\), …, \\(\\mathbf{x}_{n} = \\langle 0, 0, \\dots, 0, 1 \\rangle\\) denote the standard unit vectors of \\(\\mathbb{R}^{n}\\). The formula given in (3.13) says that the derivative of \\(f\\) at \\(a\\) in the direction of \\(\\mathbf{u}\\) is the dot product of \\(\\mathbf{u}\\) with a special vector called the gradient vector of \\(f\\) at \\(a\\). Definition 3.3 (gradient vector) Assume the setting of Proposition 3.1 and that the partial derivative of \\(f\\) with respect to \\(x_{i}\\) at \\(a\\) exists for all \\(i \\in \\{1, 2, \\dots, n\\}\\). The gradient vector of \\(f\\) at \\(a\\) is the vector \\[\\begin{align*} \\nabla f(a) \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\partial}{\\partial x_{1}}f(a) \\mathbf{x}_{1} + \\frac{\\partial}{\\partial x_{2}}f(a) \\mathbf{x_{2}} + \\dots + \\frac{\\partial}{\\partial x_{n}}f(a) \\mathbf{x_{n}}. \\end{align*}\\] where \\(\\mathbf{x}_{1} = \\langle 1, 0, 0 \\dots, 0 \\rangle\\), \\(\\mathbf{x}_{2} = \\langle 0, 1, 0 \\dots, 0 \\rangle\\), …, \\(\\mathbf{x}_{n} = \\langle 0, 0, \\dots, 0, 1 \\rangle\\) denote the standard unit vectors of \\(\\mathbb{R}^{n}\\). In the setting of the above definition, if the gradient vector of \\(f\\) exists throughout \\(R\\), then \\(x \\mapsto \\nabla f(x)\\) is a function of several variables with domain \\(R\\), which we denote by \\(\\nabla f\\). The notation \\(\\nabla f\\) is read nabla \\(f\\), you may also hear it being referred to as grad \\(f\\) or gradient of \\(f\\) and sometimes del \\(f\\). The symbol \\(\\nabla\\) by itself is read as nabla. Another notation which is commonly used to denote the gradient vector of \\(f\\) is \\(\\mathrm{grad}(f)\\). Just as we may view differentiation of a function of a single variable as an operator that acts on differentiable functions, we may also view \\(\\nabla\\) as an operator, for instance in \\(\\mathbb{R}^{3}\\), \\[\\begin{align*} \\nabla = \\mathbf{i} \\frac{\\partial}{\\partial x} + \\mathbf{j} \\frac{\\partial}{\\partial y} + \\mathbf{k} \\frac{\\partial}{\\partial z}. \\end{align*}\\] In fact \\(\\nabla\\) is a linear operator, that is, for any functions \\(f\\) and \\(g\\) of \\(n\\) variables and any scalars \\(\\lambda\\) and \\(\\mu\\) we have that \\(\\nabla(\\lambda f+\\mu g)=\\lambda \\nabla f+\\mu\\nabla g\\), provided that the required partial derivatives of \\(f\\) and \\(g\\) exist. This follows as the partial derivatives of a function of several variables is linear, that is \\[\\begin{align*} \\frac{\\partial}{\\partial x_{i}} (\\lambda f + \\mu g) = \\lambda \\frac{\\partial f}{\\partial x_{i}} + \\mu \\frac{\\partial g}{\\partial x_{i}}, \\end{align*}\\] for \\(i \\in \\{ 1, 2, \\dots, n\\}\\). Corollary 3.3 (directional derivatives are dot products) Assuming the setting of Definition 3.3 and letting \\(\\mathbf{u}\\) denote a unit vector in \\(\\mathbb{R}^{n}\\), if \\(\\phi\\) is the acute angle between the vectors \\(\\nabla f(a)\\) and \\(\\mathbf{u}\\), provided that \\(D_{\\mathbf{u}} f(a)\\) exists, then \\[\\begin{align*} D_{\\mathbf{u}} f(a) = \\nabla f(a) \\cdot \\mathbf{u} = \\lvert \\nabla f(a)\\rvert \\lvert \\mathbf{u} \\rvert \\cos(\\phi) = \\lvert \\nabla f(a) \\rvert \\cos(\\phi) = u_{1} f_{x_{1}}(a) + u_{2} f_{x_{2}}(a) + \\dots + u_{n} f_{x_{n}}(a). \\end{align*}\\] Exercise 3.4 Compute the gradient vector of the given function \\(f\\) at the given point \\(p\\). The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y) = x^{2}y + \\sin(y)\\) at \\(p = (1, \\pi)\\) The function \\(f \\, \\colon \\, \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, y \\neq 0 \\} \\to \\mathbb{R}\\) given by \\(f(x,y,z) = 2xz^{2} + z y^{-1}\\) at \\(p = (1,1,1)\\) Show/hide solution Solution (part a). By Definition 3.3, \\[\\begin{align*} \\nabla f(x, y) = \\frac{\\partial f}{\\partial x}(x,y) \\mathbf{i} + \\frac{\\partial f}{\\partial y}(x,y) \\mathbf{j} = 2xy \\mathbf{i} + (x^2 +\\cos(y))\\mathbf{j}, \\end{align*}\\] and hence the gradient vector of \\(f\\) at \\((1, \\pi)\\) is \\[\\begin{align*} \\nabla f (1,\\pi) = 2 \\pi \\mathbf{i} + (1 - 1)\\mathbf{j} = 2 \\pi \\mathbf{i}. \\end{align*}\\] Solution (part b). By Definition 3.3, \\[\\begin{align*} \\nabla f(x, y, z) = \\frac{\\partial f}{\\partial x}(x,y,z) \\mathbf{i} + \\frac{\\partial f}{\\partial y}(x,y,z) \\mathbf{j} + \\frac{\\partial f}{\\partial z}(x,y,z) \\mathbf{k} = 2z^2 \\mathbf{i} - z y^{-2} \\mathbf{j} + (4xz + y^{-1}) \\mathbf{k}, \\end{align*}\\] and hence the gradient vector of \\(f\\) at \\((1,1,1)\\) is \\[\\begin{align*} \\nabla f(1, 1, 1) = 2 \\mathbf{i} - \\mathbf{j} + 5 \\mathbf{k}. \\end{align*}\\] Exercise 3.5 In the following you may assume that the required directional derivatives exist. Find the rate of change of \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y) = x^{3} - xy^{2} + x^{2}y^{3}\\) in the following directions. \\(\\mathbf{u} = \\mathbf{i} + \\mathbf{j}\\) \\(\\mathbf{v} = \\mathbf{i} + 2 \\mathbf{j}\\) \\(\\mathbf{w} = 3\\mathbf{i}\\) Calculate \\(D^{2}_{\\mathbf{u}}(f) = D_{\\mathbf{u}} (D_{\\mathbf{u}}(f))\\), where \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) is given by \\(f(x,y) = \\sin(x \\mathrm{e}^{y})\\) and \\(\\mathbf{u} = 2\\mathbf{i} - \\mathbf{j}\\). Show/hide solution Solution (part a). Here we are asked to compute \\(D_{\\mathbf{u}} f(x, y)\\), \\(D_{\\mathbf{v}} f(x, y)\\) and \\(D_{\\mathbf{w}} f(x, y)\\). Since we may assume that the required directional derivatives exist, we may apply Corollary 3.3. For this we require the gradient vector of \\(f\\). This is given by \\[\\begin{align*} \\nabla f (x, y) = \\frac{\\partial}{\\partial x}f(x, y) \\mathbf{i} + \\frac{\\partial}{\\partial y}f(x, y) \\mathbf{j} = (3x^{2} - y^{2} + 2xy^{3}) \\mathbf{i} + (-2xy + 3x^{2}y^{2}) \\mathbf{j}. \\end{align*}\\] We also require the unit vectors \\(\\widehat{\\mathbf{u}}\\), \\(\\widehat{\\mathbf{v}}\\) and \\(\\widehat{\\mathbf{w}}\\) in the directions of \\(\\mathbf{u}\\), \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\), respectively. These are given by \\[\\begin{align*} \\widehat{\\mathbf{u}} = \\frac{\\mathbf{u}}{\\lvert \\mathbf{u} \\rvert} = \\frac{\\mathbf{i} + \\mathbf{j}}{\\sqrt{1^{2} + 1^{2}}} = \\frac{\\mathbf{i} + \\mathbf{j}}{\\sqrt{2}}, \\quad \\widehat{\\mathbf{v}} = \\frac{\\mathbf{v}}{\\lvert \\mathbf{v} \\rvert} = \\frac{\\mathbf{i} + 2 \\mathbf{j}}{\\sqrt{1^{2} + 2^{2}}} = \\frac{\\mathbf{i} + 2 \\mathbf{j} }{\\sqrt{5}} \\quad \\text{and} \\quad \\widehat{\\mathbf{w}} = \\frac{\\mathbf{w}}{\\lvert \\mathbf{w} \\rvert} = \\frac{3\\mathbf{i}}{\\sqrt{3^{2}}} = \\mathbf{i}. \\end{align*}\\] Combining the above yields the following. \\[\\begin{align*} D_{\\mathbf{u}} f(x, y) &amp;= \\langle 3x^{2} - y^{2} + 2xy^{3}, -2xy + 3x^{2}y^{2} \\rangle \\cdot \\langle 2^{-1/2}, 2^{-1/2} \\rangle = 2^{-1/2}(3x^{2} - y^{2} + 2xy^{3} - 2xy + 3x^{2}y^{2})\\\\[0.5em] D_{\\mathbf{v}}f(x, y) &amp;= \\langle 3x^{2} - y^{2} + 2xy^{3}, -2xy + 3x^{2}y^{2} \\rangle \\cdot \\langle 5^{-1/2}, 2 \\cdot 5^{-1/2} \\rangle = 5^{-1/2} (3x^{2} - y^{2} + 2xy^{3} - 4xy + 6x^{2}y^{2})\\\\[0.5em] D_{\\mathbf{w}}f(x, y) &amp;= \\langle 3x^{2} - y^{2} + 2xy^{3}, -2xy + 3x^{2}y^{2} \\rangle \\cdot \\langle 1, 0 \\rangle = 3x^{2} - y^{2} + 2xy^{3} \\end{align*}\\] Solution (part b). Here we are asked to compute \\(D^{2}_{\\mathbf{u}} f = D_{\\mathbf{u}} (D_{\\mathbf{u}}(f))\\). Since we may assume that the required directional derivatives exist, we may apply Corollary 3.3. For this we require the gradient vector of \\(f\\). By the definition of \\(\\nabla\\) and the chain rule, this is given by \\[\\begin{align*} \\nabla f(x, y) = \\frac{\\partial}{\\partial x}f(x, y) \\mathbf{i} + \\frac{\\partial}{\\partial y}f(x, y) \\mathbf{j} = e^{y} \\cos(xe^{y}) \\mathbf{i} + xe^{y} \\cos(xe^{y}) \\mathbf{j}. \\end{align*}\\] We also require the unit vector \\(\\widehat{\\mathbf{u}}\\) in the direction of \\(\\mathbf{u}\\). This is given by \\[\\begin{align*} \\widehat{\\mathbf{u}} = \\frac{\\mathbf{u}}{\\lvert \\mathbf{u} \\rvert} = \\frac{2 \\mathbf{i} - \\mathbf{j}}{\\sqrt{2^{2} + 1^{2}}} = \\frac{2 \\mathbf{i} - \\mathbf{j}}{\\sqrt{5}}. \\end{align*}\\] Combining the above yields the following. \\[\\begin{align*} D_{\\mathbf{u}}f(x, y) = \\nabla f(x, y) \\cdot \\widehat{\\mathbf{u}} = \\langle e^{y} \\cos(xe^{y}), xe^{y} \\cos(xe^{y}) \\rangle \\cdot \\langle 2 \\cdot 5^{-1/2}, -5^{-1/2} \\rangle = 5^{-1/2} (2 e^{y} \\cos(xe^{y}) - xe^{y} \\cos(xe^{y})). \\end{align*}\\] To conclude our computation, we once again apply Corollary 3.3, noting that, by the definition of \\(\\nabla\\) and the chain rule, \\[\\begin{align*} \\nabla (D_{\\mathbf{u}}f) (x, y) = &amp;5^{-1/2} ( (-2 e^{2y} \\sin(xe^{y}) - e^{y} \\cos(xe^{y}) + x e^{2y} \\sin(x e^{y}))\\mathbf{i}\\\\[0.5em] &amp;+ (2 e^{y} \\cos(xe^{y}) - 2xe^{2y}\\sin(xe^{y})- xe^{y}\\cos(xe^{y}) + x^{2}e^{2y}\\sin(xe^{y})) \\mathbf{j}) \\end{align*}\\] and hence \\[\\begin{align*} D_{\\mathbf{u}} (D_{\\mathbf{u}} f) (x, y) = \\nabla (D_{\\mathbf{u}}f) (x, y) \\cdot \\widehat{\\mathbf{u}} = 5^{-1}(-4 e^{2y} \\sin(xe^{y}) - 4e^{y} \\cos(xe^{y}) + 4x e^{2y} \\sin(x e^{y}) + xe^{y}\\cos(xe^{y}) - x^2 e^{2y}\\sin(xe^{y})). \\end{align*}\\] Corollary 3.3 gives us a relationship between the gradient vector \\(\\nabla f\\) of a function \\(f\\) and its directional derivative in the direction of a given unit vector. This gives us one geometric interpretation of \\(\\nabla f\\). A second geometric interpretation is given in the following theorem, which we will see allows us to find tangent hyper-surfaces to graphs of functions of several variables. Theorem 3.4 (gradient vectors are normal vectors) Let \\(f\\) denote a function of \\(n\\) variables, \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), with \\(f_{x_{i}}\\) continuous for all \\(i \\in \\{ 1, 2, \\dots, n \\}\\), and let \\(h \\in \\mathbb{R}\\) be such that the level hyper-surface \\(S\\) of \\(f\\) at height \\(h\\) is non-empty. If \\(a\\) belongs to a non-degenerate connected component of \\(S\\), and if \\(\\nabla f(a) \\neq \\mathbf{0}\\), then \\(\\nabla f(a)\\) is a normal vector to \\(S\\) at \\(a\\). To gain a better understanding of the statement, let us write it out in the simplest case, namely when \\(n=2\\). Let \\(f\\) denote a function of two variables \\(x\\) and \\(y\\), with \\(f_x\\) and \\(f_y\\) continuous, and let \\(h \\in \\mathbb{R}\\) be such that the level curve \\(S\\) of \\(f\\) at height \\(h\\) is non-empty, as in Figures 2.2. If \\((a, b)\\) belongs to a non-degenerate connected component of \\(S\\), and if \\(\\nabla f(a, b) \\neq \\mathbf{0}\\), then \\(\\nabla f(a,b)\\) is a normal vector to \\(S\\) at \\((a,b)\\). Show/hide proof of Theorem 3.4 for \\(n = 2\\) Proof. Let \\(\\mathbf{r}(t) = x(t) \\mathbf{i} + y(t) \\mathbf{j}\\) denote a parametrisation of the connected component \\(C\\) of \\(S\\) containing \\((a, b)\\). Since, by our hypothesis, the partial derivatives of \\(f\\) are continuous, \\(x\\) and \\(y\\) are differentiable with respect to \\(t\\). Differentiating \\(f(x(t),y(t)) = k\\) with respect to \\(t\\) using the chain rule, we obtain \\[\\begin{align*} \\frac{\\mathrm{d}}{\\mathrm{d}t} x(t) \\frac{\\partial}{\\partial x}f (x, y) + \\frac{\\mathrm{d}}{\\mathrm{d}t} y(t) \\frac{\\partial}{\\partial y} f(x, y) = 0. \\end{align*}\\] In other words, \\((x&#39;(t) \\mathbf{i} + y&#39;(t) \\mathbf{j}) \\cdot (f_x(x,y) \\mathbf{i} + f_y(x, y)\\mathbf{j}) =0\\), or equivalently, \\[\\begin{align*} \\mathbf{r}&#39;(t) \\cdot \\nabla f(x,y) = 0. \\end{align*}\\] Further, since \\(C\\) is non-degenerate, \\(\\mathbf{r}&#39;(t) \\neq \\mathbf{0}\\) for all \\(t \\in \\mathrm{Dom}(\\mathbf{r})\\). Letting \\(s \\in \\mathrm{Dom}(\\mathbf{r})\\) be such that \\(\\mathbf{r}(s) = (a, b)\\), since \\(\\mathbf{r}&#39;(s)\\) is a tangent vector to \\(C\\) at \\((a, b)\\) and since \\(\\mathbf{r}&#39;(s) \\neq \\mathbf{0}\\), if \\(\\nabla f(a, b) \\neq \\mathbf{0}\\), then \\(\\nabla f(a, b)\\) is perpendicular to \\(\\mathbf{r}&#39;(s)\\) and thus a normal vector to \\(C\\), and hence to \\(S\\), at \\((a, b)\\). Let us now investigate how Theorem 3.4 allows us to find tangent hyper-surfaces to graphs of functions of several variables. For ease of exposition let us look how we can compute the tangent plane of a surface in \\(\\mathbb{R}^{3}\\) that is the graph of a function of two variables. To this end, let \\(f\\) be a function of two variables \\(x\\) and \\(y\\) with domain \\(D\\), a non-empty open subset of \\(\\mathbb{R}^{2}\\), with \\(f_{x}\\) and \\(f_{y}\\) continuous, and let \\(g \\, \\colon \\, D \\times \\mathbb{R} \\to \\mathbb{R}\\) be defined by \\(g(x, y, z) = f(x, y) - z\\). By construction, the graph of \\(f\\) and the level surface of \\(g\\) at height zero are equal. Thus, \\(\\mathbf{n}\\) is a normal vector to the graph of \\(f\\) at \\((a, b, f(a, b))\\), for some \\((a, b) \\in D\\), if any only if it is a normal vector to the level surface of \\(g\\) with height zero at \\((a, b, f(a, b))\\). By Theorem 3.4, such a vector is given by the gradient vector of \\(g\\) at \\((a, b, f(a, b))\\), provided that it is non-zero – note \\(\\mathbf{n}\\) and \\(\\nabla g (a, b, f(a, b))\\) are not necessarily equal, but are parallel. Since the tangent plane \\(T\\) to graph of \\(f\\) at \\((a, b, f(a, b) )\\) is orthogonal to any non-zero normal vector to the graph of \\(f\\) at \\((a, b, f(a, b))\\), a vector equation for \\(T\\) is given by \\[\\begin{align*} (\\langle x, y, z \\rangle - \\langle a, b, f(a, b) \\rangle ) \\cdot \\nabla g (a, b, f(a, b)) = 0, \\end{align*}\\] provided \\(\\nabla g (a, b, f(a, b))\\) is non-zero. We can also use Theorem 3.4 to find the tangent planes to surfaces given implicitly, for instance the surfaces \\[\\begin{align*} \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, x^{2} + y^{2} + z^{2} = 1 \\} \\qquad \\text{or} \\qquad \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, x = z^2 + y^2 \\}. \\end{align*}\\] For example, suppose that \\[\\begin{align} S = \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, g(x, y, z) = 0 \\} \\tag{3.14} \\end{align}\\] is an implicitly defined surface, where \\(g\\) is a function of three variables \\(x\\), \\(y\\) and \\(z\\) whose partial derivatives \\(g_{x}\\), \\(g_{y}\\) and \\(g_{z}\\) are continuous. Since \\(S\\) is the level surface of \\(g\\) at height zero, by Theorem 3.4, if \\((a, b, c) \\in S\\), then a normal vector to \\(S\\) at \\((a, b, c)\\) is given by \\(\\nabla g(a, b, c)\\), provided that it is non-zero. Since the tangent plane \\(T\\) to \\(S\\) at \\((a, b, c )\\) is orthogonal to any non-zero normal vector to the surface \\(S\\) at \\((a, b, c)\\), a vector equation for \\(T\\) is given by \\[\\begin{align} (\\langle x, y, z \\rangle - \\langle a, b, c \\rangle ) \\cdot \\nabla g (a, b, c) = 0. \\tag{3.15} \\end{align}\\] Exercise 3.6 Using Theorem 3.4, find an equation for the tangent plane to the following surfaces at the given points. The surface \\(S\\) given by \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, z = x^{2}-y^{2} \\}\\) at the point \\(p = (2, 1, 3)\\) The surface \\(S\\) given by \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, x^{2}+y^{2}+z^{2}=1 \\}\\) at the point \\(p = (3^{-1/2}, 3^{-1/2}, 3^{-1/2})\\) The surface \\(S\\) given by \\(\\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, z - x^{2}y = yz^{2} - 1 \\}\\) at the point \\(p = (-1, 1, 1)\\) Show/hide solution Solution (part a). Rewriting \\(S\\) in the form given in (3.14) we have that \\[\\begin{align*} \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, z - x^{2} + y^{2} = 0 \\} \\end{align*}\\] and hence \\(g \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) is defined by \\(g(x, y, z) = z - x^{2} + y^{2}\\). Before proceeding, let us check that \\(p \\in S\\), for if not, then the tangent plane does not exist. Since \\[\\begin{align*} g(p) = g(2,1,3) = 3 - 2^{2} + 1^{2} = 0, \\end{align*}\\] it follows that \\(p \\in S\\). Noting that, \\[\\begin{align*} \\nabla g(x, y, z) = \\frac{\\partial}{\\partial x} g(x,y,z) \\mathbf{i} + \\frac{\\partial}{\\partial y} g(x,y,z) \\mathbf{j} + \\frac{\\partial}{\\partial z} g(x,y,z) \\mathbf{k} = -2x \\mathbf{i} + 2y\\mathbf{j} + \\mathbf{k}, \\end{align*}\\] we have that \\(\\nabla g(p) = \\nabla g(2,1,3) = -4\\mathbf{i} + 2 \\mathbf{j} + \\mathbf{k} \\neq \\mathbf{0}\\) and hence the plane determined by the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\[\\begin{align*} (\\langle x, y, z \\rangle - \\langle 2, 1, 3 \\rangle) \\cdot \\langle -4, 2, 1\\rangle = 0, \\end{align*}\\] or equivalently \\(z = 4x − 2y − 3\\), is the tangent plane to \\(S\\) at \\(p\\). Solution (part b). Rewriting \\(S\\) in the form given in (3.14) we have that \\[\\begin{align*} \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, x^{2} + y^{2} + z^{2} - 1 = 0 \\} \\end{align*}\\] and hence \\(g \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) is defined by \\(g(x, y, z) = x^{2} + y^{2} + z^{2}\\). Before proceeding, let us check that \\(p \\in S\\), for if not, then the tangent plane does not exist. Since \\[\\begin{align*} g(p) = g(3^{-1/2},3^{-1/2},3^{-1/2}) = (3^{-1/2})^{2} + (3^{-1/2})^{2} + (3^{-1/2})^{2} - 1 = 0, \\end{align*}\\] it follows that \\(p \\in S\\). Noting that, \\[\\begin{align*} \\nabla g(x, y, z) = \\frac{\\partial}{\\partial x} g(x,y,z) \\mathbf{i} + \\frac{\\partial}{\\partial y} g(x,y,z) \\mathbf{j} + \\frac{\\partial}{\\partial z} g(x,y,z) \\mathbf{k} = 2x \\mathbf{i} + 2y + 2z\\mathbf{k}, \\end{align*}\\] we have that \\(\\nabla g(p) = \\nabla g(3^{-1/2},3^{-1/2},3^{-1/2}) = 2 \\cdot 3^{-1/2} (\\mathbf{i} + \\mathbf{j} + \\mathbf{k}) \\neq \\mathbf{0}\\) and hence the plane determined by the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\[\\begin{align*} (\\langle x, y, z \\rangle - \\langle 3^{-1/2}, 3^{-1/2}, 3^{-1/2} \\rangle) \\cdot \\langle 2 \\cdot 3^{-1/2}, 2 \\cdot 3^{-1/2}, 2 \\cdot 3^{-1/2} \\rangle = 0, \\end{align*}\\] or equivalently \\(z = 3^{1/2} - x- y\\), is the tangent plane to \\(S\\) at \\(p\\). Solution (part c). Rewriting \\(S\\) in the form given in (3.14) we have that \\[\\begin{align*} \\{ (x, y, z) \\in \\mathbb{R}^{3} \\, \\colon \\, z - x^{2}y - yz^{2} + 1 = 0 \\} \\end{align*}\\] and hence \\(g \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) is defined by \\(g(x, y, z) = z - x^{2}y - yz^{2} + 1\\). Before proceeding, let us check that \\(p \\in S\\), for if not, then the tangent plane does not exist. Since \\[\\begin{align*} g(p) = g(-1,1,1) = 1 - 1 - 1 + 1 = 0, \\end{align*}\\] it follows that \\(p \\in S\\). Noting that, \\[\\begin{align*} \\nabla g(x, y, z) = \\frac{\\partial}{\\partial x} g(x,y,z) \\mathbf{i} + \\frac{\\partial}{\\partial y} g(x,y,z) \\mathbf{j} + \\frac{\\partial}{\\partial z} g(x,y,z) \\mathbf{k} = -2xy \\mathbf{i} - (x^2 + z^2) \\mathbf{j} + (1 -2yz)\\mathbf{k}, \\end{align*}\\] we have that \\(\\nabla g(p) = \\nabla g(-1,1,1) = 2 \\mathbf{i} - 2 \\mathbf{j} - \\mathbf{k} \\neq \\mathbf{0}\\) and hence the plane determined by the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\[\\begin{align*} (\\langle x, y, z \\rangle - \\langle -1,1,1 \\rangle) \\cdot \\langle 2, -2, -1 \\rangle = 0, \\end{align*}\\] or equivalently \\(z = 5 + 2x - 2y\\), is the tangent plane to \\(S\\) at \\(p\\). Question Corollary 3.3 gives an easy way to compute directional derivatives. However, it relies on the assumption that the required directional derivative exists. Is is true that, if for a function \\(f\\) of \\(n\\) variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), for some natural number \\(n \\geq 2\\), the partial derivative \\(f_{x_{i}}\\) exists for all \\(i \\in \\{1, 2, \\dots, n\\}\\), then \\(D_{\\mathbf{u}}f\\) exists, for any vector \\(\\mathbf{u}\\) in \\(\\mathbb{R}^{n}\\)? Show/hide solution Solution. The statement is false. Consider the function \\(f\\) given in Exercise 3.2, namely \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) defined by \\[\\begin{align*} f(x, y) = \\begin{cases} 0 &amp; \\text{if} \\; (x, y) = (0,0),\\\\[0.5em] \\displaystyle{\\frac{xy}{x^{2}+y^{2}}} &amp; \\text{otherwise.}\\end{cases} \\end{align*}\\] We showed in Exercise 3.2 that the partial derivatives of \\(f\\) exist at the origin. We will now show that the directional derivative of \\(f\\) at the origin in the direction of \\(\\mathbf{u} = \\mathbf{i} + \\mathbf{j}\\) does not exist. Since \\[\\begin{align*} \\lim_{h \\to 0} \\frac{f(0 + 2^{-1/2}h, 0 + 2^{-1/2}h) - f(0,0)}{h} = \\lim_{h \\to 0} \\frac{f(2^{-1/2}h, 2^{-1/2}h) - f(0,0)}{h} = \\lim_{h \\to 0} \\frac{ (h^{2}/2)/(h^{2})}{h} = \\lim_{h \\to 0} \\frac{1}{2 h} \\end{align*}\\] diverges to infinity, the directional derivative of \\(f\\) at the origin in the direction of \\(\\mathbf{u} = \\mathbf{i} + \\mathbf{j}\\) does not exist. Remark. It is the case that if the partial derivatives of a function of several variables are continuous, then all directional derivatives exist and are continuous. This naturally leads us to our next definition. Definition 3.4 (differentiability for functions of several variabels) If \\(f\\) is a function of \\(n\\) variables \\(x_{1}\\), \\(x_{2}\\), …, \\(x_{n}\\), for some natural number \\(n \\geq 2\\), and if \\(f_{x_{i}}\\) is continuous at a given point \\(p \\in \\mathrm{Dom}(f)\\), for all \\(i \\in \\{1, 2, \\dots, n\\}\\), then \\(f\\) is said to be differentiable at \\(p\\). If \\(f\\) is differentiable at all points in its domain, then it is called differentiable. A third geometric interpretation of the gradient vector is given by our next result, which tells us that the gradient vector gives the direction in which the maximal rate of change occurs. Theorem 3.5 Assume the setting of Theorem 3.4. The direction of the vector \\(\\nabla f(a)\\) is the direction in which the maximum rate of change of \\(f\\) at \\(a\\) occurs, and the maximum rate of change of \\(f\\) at \\(a\\) is given by \\(\\lvert \\nabla f(a) \\rvert\\). Additionally, the rate of change of \\(f\\) at \\(a\\) is zero in the directions tangent to the level hyper-surface at height \\(f(a)\\). To gain a better understanding of the statement, let us write it out in the simplest case, namely when \\(n=2\\). Let \\(f\\) denote a real valued function of two variables \\(x\\) and \\(y\\), with \\(f_x\\) and \\(f_y\\) continuous. The direction of the vector \\(\\nabla f(a, b)\\), for a given \\((a, b) \\in \\mathrm{Dom}(f)\\), is the direction in which the maximum rate of change of \\(f\\) at \\((a, b)\\) occurs, and the maximum rate of change of \\(f\\) at \\((a,b)\\) is given by \\(\\lvert \\nabla f(a, b) \\rvert\\). Additionally, the rate of change of \\(f\\) at \\((a, b)\\) is zero in directions tangent to the level curve at height \\(f(a, b)\\). Show/hide proof of Theorem 3.5 for \\(n = 2\\) Proof. Letting \\(\\mathbf{u}\\) denote a unit vector in \\(\\mathbb{R}^{2}\\) and \\((a, b) \\in \\mathrm{Dom}(f)\\), by Corollary 3.3, \\[\\begin{align} D_\\mathbf{u} f(a,b) = \\lvert \\nabla f(a,b) \\rvert \\cos(\\phi), \\tag{3.16} \\end{align}\\] where \\(\\phi\\) is the acute angle between \\(\\nabla f(a,b)\\) and \\(\\mathbf{u}\\). Note, by our remark to the above question, since we have assumed that \\(f_{x}\\) and \\(f_{y}\\) are continuous this guarantees that \\(D_\\mathbf{u}\\) exists. The value of \\(\\lvert \\nabla f(a,b) \\rvert \\cos(\\phi)\\) is maximised when \\(\\phi = 0\\), namely when \\(\\mathbf{u}\\) and \\(\\nabla f(a,b)\\) are parallel. Further, letting \\(\\theta = \\pi/2\\) or \\(-\\pi/2\\), so that \\(\\nabla f(a,b)\\) and \\(\\mathbf{u}\\) are perpendicular, by Theorem 3.4 and (3.16), the rate of change of \\(f\\) at \\((a,b)\\) is zero in directions tangent to the level curve passing through \\((a,b)\\). Exercise 3.7 The temperature at a point of a metal sheet lying in the plane is given by \\(t(x,y) = xe^{-y}+y^2\\). In what direction does the temperature change most rapidly at the point \\((1,1)\\) and what is the maximum rate of change at \\((1, 1)\\)? Show/hide solution Solution. By Theorem 3.5, the direction in which the temperature changes most rapidly is given by the unit vector in the direction of \\(\\nabla t (1, 1)\\) and the maximum rate of change is given by \\(\\lvert \\nabla t (1, 1) \\rvert\\). Since \\[\\begin{align*} \\nabla t (x, y) = \\frac{\\partial}{\\partial x}t(x, y) \\mathbf{i} + \\frac{\\partial}{\\partial y}t(x, y) \\mathbf{j} = e^{-y} \\mathbf{i} + (-xe^{-y}+2y) \\mathbf{j}, \\end{align*}\\] the direction in which the temperature changes most rapidly is \\[\\begin{align*} \\frac{\\nabla t (1, 1)}{\\lvert \\nabla t (1, 1) \\rvert} = \\frac{e^{-1}\\mathbf{i} + (2 - e^{-1}) \\mathbf{j}}{\\sqrt{e^{-2} + (2 - e^{-1})^{2}}}, \\end{align*}\\] and the maximum rate of change is given by \\(\\lvert \\nabla t (1, 1) \\rvert = \\sqrt{e^{-2} + (2 - e^{-1})^{2}}\\). Exercise 3.8 In a field there is a hound and a fox, and the hound is chasing the fox. The scent the fox leaves as it runs through the field is given by \\(s(x,y)=x\\mathrm{e}^{-y}\\). Assuming that the hound always follows the path of strongest scent and that this path is smooth, find the path the hound follows given that its starting position is at \\((2,1)\\). Show/hide solution Solution. Two vectors \\(\\mathbf{v} = a\\mathbf{i} + b\\mathbf{j}\\) and \\(\\mathbf{u} = \\alpha\\mathbf{i} + \\beta\\mathbf{j}\\) in \\(\\mathbb{R}^{2}\\) are parallel if and only if \\(\\mathbf{v} = \\lambda \\mathbf{u}\\), namely if \\(a = \\lambda \\alpha\\) and \\(b = \\lambda \\beta\\), or equivalently, if \\(b/a=\\beta/\\alpha\\), provided that \\(a\\) and \\(\\alpha\\) are non-zero. Let the vector equation of the path the hound follows be denoted by \\(\\mathbf{r}(t) = x(t)\\mathbf{i} + y(t)\\mathbf{j}\\) for \\(t \\in \\mathbb{R}^{+}_{0}\\). At a given point \\(t \\in \\mathbb{R}^{+}_{0}\\), the direction of the path is given by its tangent vector \\(\\mathbf{r}&#39;(t) = x&#39;(t)\\mathbf{i} + y&#39;(t)\\mathbf{j}\\). Note, for \\(t \\in \\mathbb{R}^{+}_{0}\\), \\(\\mathbf{r}&#39;(t)\\) exists as we have assumed that the path the hound follows is smooth. Since the partial derivatives \\(s_{x}(x,y) = \\mathrm{e}^{-y}\\) and \\(s_{y}(x, y) = -x \\mathrm{e}^{-y}\\) are continuous, by Theorem 3.5, we have that \\(\\nabla s(x,y)\\) points in the direction of the maximum increase of \\(s\\) at \\((x, y)\\), so that \\(\\nabla s(x(t),y(t))\\) is parallel to the direction of the path of the hound, namely \\(\\nabla s (x(t),y(t)) = e^{-y(t)}\\mathbf{i} - x(t)e^{-y(t)}\\mathbf{j}\\) and \\(\\mathbf{r}&#39;(t) = x&#39;(t)\\mathbf{i} + y&#39;(t)\\mathbf{j}\\) are parallel. By our first observation, this means \\[\\begin{align*} \\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\frac{\\mathrm{d}y/\\mathrm{d}t}{\\mathrm{d}x/\\mathrm{d}t} = \\frac{-xe^{-y}}{e^{-y}} = -x. \\end{align*}\\] Integrating both sides of this equation with respect to \\(x\\) and applying the fundamental theorem of calculus, yields \\(y=-x^2/2+c\\). Applying our initial condition, that the hound starts at \\((2,1)\\), we have \\(1 = -2^{2}/2 + c\\), or equivalently \\(c = 3\\). Therefore, the path the hound follows is given by \\(\\mathbf{r}(t) = t \\mathbf{i} + (-t^2/2+3) \\mathbf{j}\\), for \\(t \\in \\mathbb{R}^{+}_{0}\\). "],["practiceproblemschapterthree.html", "Practice problems – Chapter 3", " Practice problems – Chapter 3 Exercise 3.9 Find the partial derivatives of the following functions at the given points. The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y) = x\\mathrm{e}^{-y}+3y\\) at \\((1, 0)\\) The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y)=\\sin(x-y)\\) at \\((3,3)\\) The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(u, v) = (u^{3} + v^{3})(1+u^{2} + v^{2})^{-1}\\) at \\((-2,1)\\) Show/hide solution Solution (part a). If \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) is given by \\(f(x,y)=x\\mathrm{e}^{-y}+3y\\), then \\[\\begin{align*} f_{x}(x, y) = \\mathrm{e}^{-y} \\quad \\text{and} \\quad f_{y}(x, y) = -x\\mathrm{e}^{-y}+3. \\end{align*}\\] In which case \\(f_{x}(1,0) = \\mathrm{e}^{-0} = 1\\) and \\(f_{y}(1,0) = - 1 \\cdot \\mathrm{e}^{-0}+3 = -1+3=2\\). Solution (part b). If \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) is given by \\(f(x,y)=\\sin(x-y)\\), then \\[\\begin{align*} f_{x}(x, y) = \\cos(x-y) \\quad \\text{and} \\quad f_{y}(x, y) = -\\cos(x-y). \\end{align*}\\] In which case \\(f_{x}(3,3) = \\cos(3-3) = \\cos(0) = 1\\) and \\(f_y(3,3) = -\\cos(3-3) = -\\cos(0) = -1\\). Solution (part c). If \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}^{2}\\) is given by \\(f(u, v) = (u^{3} + v^{3})(1 + u^{2} + v^{2})^{-1}\\), then \\[\\begin{align*} f_{u}(u, v) = \\frac{3u^2(1+u^2+v^2)-2u(u^3+v^3)}{(1 + u^2+v^2)^{2}} \\quad \\text{and} \\quad f_{v}(u, v)= \\frac{3v^2(1+u^2+v^2)-2v(u^3+v^3)}{(1+u^2+v^2)^{2}}. \\end{align*}\\] In which case \\[\\begin{align*} f_{u}(-2, 1) = \\frac{3(-2)^2(1+(-2)^2+1^2)-2(-2)((-2)^3+1^3)}{(1 + (-2)^2+1^2)^{2}} = \\frac{11}{9} \\end{align*}\\] and \\[\\begin{align*} f_{v}(-2, 1)= \\frac{3(1)^2(1+(-2)^2+1^2)-2(1)((-2)^3+1^3)}{(1+(-2)^2+1^2)^{2}} = \\frac{8}{9}. \\end{align*}\\] Exercise 3.10 Find all second order partial derivatives of the following functions and state (with a justification) if there are any points in in the given domains at which the second order partial derivatives do not exist. The function \\(f \\, \\colon \\, \\mathbb{R} \\times \\mathbb{R}_{0}^{+} \\to \\mathbb{R}\\) given by \\(f(x,y)=x^2y+x\\sqrt y\\) The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y)=\\sin(x+y)+\\cos(x-y)\\) Exercise 3.11 In the Parts a. – f. below let \\(x\\) and \\(y\\) denote independent variables and let \\(z\\) denote a variable dependent on \\(x\\) and \\(y\\). Use implicit differentiation to find \\(\\partial z / \\partial x\\) and \\(\\partial z / \\partial y\\). \\(\\quad x^2-y^2+z^2=1\\) \\(\\quad z^2-4xz+y^2=4\\) \\(\\quad xy+xz+yz=3\\) \\(\\quad x^2+z^2=4yz\\) \\(\\quad xyz=x+y+z\\) \\(\\quad x^3z^2-z^2y^2=\\sin(x)\\) Show/hide solution Solution (part a). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = x^2-y^2+z^2 - 1\\) yields \\[\\begin{align*} 2z \\frac{\\partial z}{\\partial x} = -2x \\quad \\text{and} \\quad 2z \\frac{\\partial z}{\\partial y} = 2y, \\end{align*}\\] or equivalently, provided that \\(z\\neq 0\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} =-\\frac{x}{z} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = \\frac{y}{z}. \\end{align*}\\] Solution (part b). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = z^{2}-4xz+y^{2}-4\\) yields \\[\\begin{align*} (2z - 4x) \\frac{\\partial z}{\\partial x} = 4z \\quad \\text{and} \\quad (2z - 4x) \\frac{\\partial z}{\\partial y} = -2y, \\end{align*}\\] or equivalently, provided that \\(z \\neq 2x\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} = \\frac{2z}{z-2x} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = -\\frac{y}{z-2x}. \\end{align*}\\] Solution (part c). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = xy+xz+yz-3\\) yields \\[\\begin{align*} (x+y) \\frac{\\partial z}{\\partial x} = -(y+z) \\quad \\text{and} \\quad (x+y) \\frac{\\partial z}{\\partial y} = -(x+z), \\end{align*}\\] or equivalently, provided that \\(x \\neq -y\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} = -\\frac{y+z}{x+y} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = -\\frac{x+z}{x+y}. \\end{align*}\\] Solution (part d). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = x^2+z^2-4yz\\) yields \\[\\begin{align*} (2z-4y) \\frac{\\partial z}{\\partial x} = -2x \\quad \\text{and} \\quad (2z-4y) \\frac{\\partial z}{\\partial y} = 4z, \\end{align*}\\] or equivalently, provided that \\(z\\neq2y\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} = - \\frac{x}{z - 2y} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = \\frac{2z}{z - 2y}. \\end{align*}\\] Solution (part e). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = xyz-x-y-z\\) yields \\[\\begin{align*} (xy-1)\\frac{z}{x} = yz-1 \\quad \\text{and} \\quad (xy-1)\\frac{z}{y} = xz-1, \\end{align*}\\] or equivalently, provided that \\(xy\\neq1\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} = \\frac{yz-1}{1-xy} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = \\frac{xz-1}{1-xy}. \\end{align*}\\] Solution (part f). Applying Corollary 3.2 with \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) defined by \\(f(x, y, z) = x^3z^2-z^2y^2-\\sin(x)\\) yields \\[\\begin{align*} (2x^3z-2zy^2) \\frac{\\partial z}{\\partial x} = \\cos(x) - 3x^2z^2 \\quad \\text{and} \\quad (2x^3z -2zy^2)\\frac{\\partial z}{\\partial y} = 2yz^2, \\end{align*}\\] or equivalently, provided that \\(z\\neq 0\\) and \\(x^{3} \\neq y^{2}\\), \\[\\begin{align*} \\frac{\\partial z}{\\partial x} = \\frac{\\cos(x)-3x^2z^2}{2x^3z-2y^2z} \\quad \\text{and} \\quad \\frac{\\partial z}{\\partial y} = \\frac{zy}{x^3-y^2}. \\end{align*}\\] Exercise 3.12 By explicitly calculating all necessary mixed second order partial derivatives, show that \\[\\begin{align*} \\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial^2 f}{\\partial y \\partial x} \\end{align*}\\] for the following functions \\(f\\). The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y)=x^2y^3\\) The function \\(f \\, \\colon \\, \\mathbb{R}^2 \\to \\mathbb{R}\\) given by \\(f(x,y)=\\mathrm{e}^{xy}\\cos(x)\\) The function \\(f \\, \\colon \\, \\mathbb{R}^3 \\to \\mathbb{R}\\) given by \\(f(x,y,z)=x\\mathrm{e}^{-z}-3xy\\) Exercise 3.13 Suppose \\(u\\) and \\(v\\) are independent variables, taking values in \\(\\mathbb{R}\\), that \\(x\\) and \\(y \\colon \\mathbb{R}^{2} \\to \\mathbb{R}\\) are given by \\(x(u,v) = u + v\\) and \\(y(u,v) = u^{2}\\) and that \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) is defined by \\(f(x,y)=\\cos(xy)\\). Calculate the partial derivatives \\(\\partial f / \\partial u\\) and \\(\\partial f / \\partial v\\): by using the chain rule; directly by substituting \\(x\\) with \\(u + v\\), and \\(y\\) with \\(u^{2}\\) in the definition of \\(f\\), and then computing the necessary partial derivatives. Show/hide solution Solution (part a). In this question we have that \\(f\\) is a function of two intermediate variables \\(x\\) and \\(y\\), and that \\(x\\) and \\(y\\) are in turn functions of two independent variables \\(u\\) and \\(v\\). To help us apply the chain rule in the figure directly below we have sketched a tree diagram of our set up. FIGURE 3.8: Tree diagram for a function \\(f\\) of two intermediate variables \\(x\\) and \\(y\\), which are in turn functions of two independent variables \\(u\\) and \\(v\\). Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=1.5cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$y$} child { node[label=right:{$\\color{Cerulean}v$}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial y}{\\partial v}$} } child { node[label=right:{$\\color{Cerulean}u$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial y}{\\partial u}$} node[below] {} } edge from parent [Red] node[above] {} node[below=0.5em, left=0.25em, black] {$\\frac{\\partial f}{\\partial y}$} } child { node[Red] {$x$} child { node[label=right:{{$\\color{Cerulean}v$}}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial x}{\\partial v}$} } child { node[label=right:{$\\color{Cerulean}u$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial x}{\\partial u}$} node[below] {} } edge from parent [Red] node[above=0.5em, left= 0.25em, black] {$\\frac{\\partial f}{\\partial x}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} To find the derivative of \\(f\\) with respect to \\(u\\) we consider all pairs of branches that lead from \\(f\\) to \\(u\\). Here there are two possibilities: \\[\\begin{align*} f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial x} \\quad} x \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} x}{\\mathrm{d} u} \\quad} u \\qquad \\text{and} \\qquad f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial y} \\quad} y \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} y}{\\mathrm{d} u} \\quad} u \\end{align*}\\] Next, we add the products of the corresponding pairs of partial derivatives to obtain \\[\\begin{align*} \\frac{\\partial f}{\\partial u} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial u} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial u}. \\end{align*}\\] Observing that \\[\\begin{align*} \\frac{\\partial}{\\partial x}f(x,y) = -y\\sin(xy), \\qquad \\frac{\\partial}{\\partial u}x(u,v) = 1, \\qquad \\frac{\\partial f}{\\partial y}f(x,y) = -x\\sin(xy), \\qquad \\text{and} \\qquad \\frac{\\partial y}{\\partial u}y(u,v) = 2u, \\end{align*}\\] and substituting in \\(x = u + v\\) and \\(v=u^{2}\\), we have that \\[\\begin{align*} \\frac{\\partial}{\\partial u}f(u,v) = -y\\sin (xy) - 2 u x \\sin (xy) =-u^2\\sin(u^2(u+v))-2u(u+v)\\sin(u^2(u+v)). \\end{align*}\\] To find the derivative of \\(f\\) with respect to \\(v\\) we consider all pairs of branches in our tree diagram that lead from \\(f\\) to \\(v\\). Here there are two possibilities: \\[\\begin{align*} f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial x} \\quad} x \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} x}{\\mathrm{d} v} \\quad} v \\qquad \\text{and} \\qquad f \\xrightarrow{\\quad \\textstyle \\frac{\\partial f}{\\partial y} \\quad} y \\xrightarrow{\\quad \\textstyle \\frac{\\mathrm{d} y}{\\mathrm{d} v} \\quad} v \\end{align*}\\] Next, we add the products of the corresponding pairs of partial derivatives to obtain \\[\\begin{align*} \\frac{\\partial f}{\\partial v} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial v} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial v}. \\end{align*}\\] Observing that \\[\\begin{align*} \\frac{\\partial}{\\partial x}f(x,y) = -y\\sin(xy), \\qquad \\frac{\\partial}{\\partial v}x(u,v) = 1, \\qquad \\frac{\\partial}{\\partial y}f(x, y) = -x\\sin(xy), \\qquad \\text{and} \\qquad \\frac{\\partial}{\\partial v}y(u,v) = 0, \\end{align*}\\] and substituting in \\(x = u + v\\) and \\(v=u^{2}\\), we have that \\[\\begin{align*} \\frac{\\partial}{\\partial u}f(u, v) = -y\\sin (xy) = -u^{2}\\sin(u^2(u+v)). \\end{align*}\\] Solution (part b). Substituting \\(u + v\\) for \\(x\\), and \\(u^{2}\\) for \\(y\\), in the in definition of \\(f\\) we obtain that \\[\\begin{align*} f(x,y) = \\cos(xy) = \\cos(u^{2}(u+v)). \\end{align*}\\] Hence, we obtain the following. \\[\\begin{align*} \\frac{\\partial f}{\\partial u} &amp;= -(3u^2+2uv)\\sin(u^2(u+v))= -u^2\\sin(u^2(u+v))-2u(u+v)\\sin(u^2(u+v))\\\\[0.5em] \\frac{\\partial f}{\\partial v} &amp;= -u^{2}\\sin(u^{2}(u+v)) \\end{align*}\\] Exercise 3.14 Suppose that \\(u\\), \\(v\\) and \\(z \\colon \\mathbb{R}^{2} \\to \\mathbb{R}\\) are functions of two independent variables \\(x\\) and \\(y\\), with \\(u\\) and \\(v\\) given explicitly by \\(u(x,y) = x^{2}y\\) and \\(v(x,y)=x^2+y^2\\), and with \\(z\\) given implicitly by the partial differential equation \\[\\begin{align*} x \\frac{\\partial z}{\\partial x} - 2y\\frac{\\partial z}{\\partial y} = 2x^{2}-4y^2 \\end{align*}\\] with boundary condition \\((\\partial z / \\partial x)(0, y) = (\\partial z /\\partial y)(1, y)\\), and initial condition \\(z(0, 0) = 12\\). By using a change of variables, from \\(x\\) and \\(y\\) to \\(u\\) and \\(v\\), find the general solution for \\(z\\) in terms of \\(x\\) and \\(y\\). For the purposes of this question, you may assume that there exists a function \\(w \\colon \\mathbb{R} \\times \\mathbb{R}^{+}_{0} \\to \\mathbb{R}\\) such that \\(w(u(x,y),v(x,y)) = z(x,y)\\) for all \\((x, y) \\mathbb{R}^{2}\\). Exercise 3.15 Suppose that \\(f \\, \\colon \\, \\{ (x, y) \\in \\mathbb{R}^{2} \\, \\colon \\, x \\neq 0 \\} \\to \\mathbb{R}\\) is a functions of the variables \\(x\\) and \\(y\\) and let \\((r, \\theta)\\) denote the polar representation of the Cartesian point \\((x, y)\\). Express \\(\\partial f / \\partial x\\) and \\(\\partial^{2} f / \\partial x^{2}\\) in terms of partial derivatives of \\(f\\) with respect to \\(r\\) and with respect to \\(\\theta\\). Express \\(\\partial f / \\partial y\\) and \\(\\partial^{2} f / \\partial y^{2}\\) in terms of the partial derivatives of \\(f\\) with respect to \\(r\\) and with respect to \\(\\theta\\). Using Parts a. and b. express the Laplacian \\[\\begin{align*} \\Delta f \\,{\\colon}\\mathrel{\\mkern-5mu}=\\frac{\\partial^2 f}{\\partial x^2}+\\frac{\\partial^2 f}{\\partial y^2} \\end{align*}\\] of \\(f\\) in terms of the partial derivatives of \\(f\\) with respect to \\(r\\) and \\(\\theta\\). Show/hide solution For the parts a. and b. of this question we will utilise the chain rule and the following tree diagram. FIGURE 3.9: Tree diagram for \\(f\\) a function of two intermediate variables \\(x\\) and \\(y\\), which are in turn functions of the variables \\(r\\) and \\(\\theta\\). Show/hide image source code %%Image generated using \\LaTeX package *tikz*.%% \\documentclass[convert={density=600,outext=.png}]{standalone} \\include{preview} \\usepackage[pdftex,active,tightpage]{preview} \\usepackage{amsmath} \\usepackage[dvipsnames]{xcolor} \\usepackage{tikz} \\usetikzlibrary{matrix} \\usetikzlibrary{decorations.markings} \\usetikzlibrary{arrows,shapes,snakes,automata,backgrounds,petri} \\usepackage{pgfplots} % \\begin{document} \\begin{preview} %% TIKZ_CODE %% % \\tikzstyle{level 1}=[level distance=3.5cm, sibling distance=5cm] \\tikzstyle{level 2}=[level distance=3.5cm, sibling distance=1.5cm] % \\begin{tikzpicture}[grow=right] \\node {$f$} child { node[Red] {$y$} child { node[label=right:{$\\color{Cerulean}\\theta$}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial y}{\\partial \\theta}$} } child { node[label=right:{$\\color{Cerulean}r$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial y}{\\partial r}$} node[below] {} } edge from parent [Red] node[above] {} node[below=0.5em, left=0.25em, black] {$\\frac{\\partial f}{\\partial y}$} } child { node[Red] {$x$} child { node[label=right:{{$\\color{Cerulean}\\theta$}}] {} edge from parent [Cerulean] node[above] {} node[below=1.375em,right=0.1em,black] {$\\frac{\\partial x}{\\partial \\theta}$} } child { node[label=right:{$\\color{Cerulean}r$}] {} edge from parent [Cerulean] node[above=1.375em,right=0.1em,black] {$\\frac{\\partial x}{\\partial r}$} node[below] {} } edge from parent [Red] node[above=0.5em, left= 0.25em, black] {$\\frac{\\partial f}{\\partial x}$} node[below] {} }; \\end{tikzpicture} \\end{preview} \\end{document} Solution (part a). By the chain rule and utilising the above tree diagram, we have that \\[\\begin{align} \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial r} \\frac{\\partial r}{\\partial x} + \\frac{\\partial f}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial x}. \\tag{3.17} \\end{align}\\] The variables \\(x\\) and \\(y\\) are independent of each other, and the variables \\(r\\) and \\(\\theta\\) are independent of each other, but both \\(r\\) and \\(\\theta\\) are functions of \\(x\\) and \\(y\\), and vice versa. This means, for example, that \\(\\theta\\) does not remain constant as \\(x\\) varies, so we cannot treat \\(\\theta\\) as constant when we differentiate with respect to \\(x\\). Our aim is to calculate \\[\\begin{align*} \\frac{\\partial r}{\\partial x} \\qquad \\text{and} \\qquad \\frac{\\partial \\theta}{\\partial x} \\end{align*}\\] in terms of \\(r\\) and \\(\\theta\\). We can do this by writing \\(r\\) and \\(\\theta\\) in terms of \\(x\\) and \\(y\\) and then differentiating. Note, if we write \\(r(x,y)=x/\\cos(\\theta(x,y))\\) and differentiate, then we have to take into account that \\(\\theta\\) is a function of \\(x\\) and \\(y\\). However, if we write \\(r^{2}(x,y) =x^{2}+y^{2}\\), and then differentiate with respect to \\(x\\) implicitly treating \\(y\\) as constant, this gives \\[\\begin{align*} 2r(x,y)\\frac{\\partial}{\\partial x}r(x, y) = 2x \\qquad \\text{or equivalently} \\qquad \\frac{\\partial}{\\partial x}r(x,y) = \\frac{x}{r(x,y)}. \\end{align*}\\] Since \\(x(r, \\theta) = r\\cos(\\theta)\\) and \\(\\tan(\\theta(x, y)) = y/x\\), we have that \\[\\begin{align*} \\frac{\\partial}{\\partial x}r(x,y) = \\cos(\\theta(x,y)) \\qquad \\text{and} \\qquad \\sec^{2}(\\theta(x,y)) \\frac{\\partial}{\\partial x}\\theta(x,y) = \\frac{-y}{x^{2}}, \\end{align*}\\] and since \\(x(r, \\theta) = r\\cos(\\theta)\\) and \\(y(r, \\theta)=r\\sin(\\theta)\\), we obtain that \\[\\begin{align*} \\frac{\\partial}{\\partial x}\\theta(x,y) = \\frac{-\\sin(\\theta(x,y))}{r(x,y)}. \\end{align*}\\] Substituting these values into (3.17) yields. \\[\\begin{align*} \\frac{\\partial}{\\partial x}f(x(r,\\theta),y(r,\\theta)) = \\cos(\\theta) \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta)) - \\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)) \\end{align*}\\] Note, given the domain of \\(f\\), we have that neither \\(r = 0\\) nor \\(x = 0\\). Now, viewing \\(\\partial / \\partial x\\) as an operator (function) which acting on functions (when regarded as a function of \\(x\\) and \\(y\\)) whose first order partial derivatives are continuous is the same as the operator \\[\\begin{align*} \\cos(\\theta) \\frac{\\partial}{\\partial r} - \\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta} \\end{align*}\\] acting on that function (when regarded as a function of \\(r\\) and \\(\\theta\\)) whose first order partial derivatives are continuous. Hence, setting \\[\\begin{align*} g(x, y) = \\frac{\\partial}{\\partial x}f(x, y), \\end{align*}\\] we have that \\[\\begin{align*} \\frac{\\partial^2}{\\partial x^2}f(x(r,\\theta),y(r,\\theta)) =&amp;\\frac{\\partial}{\\partial x} \\frac{\\partial}{\\partial x} f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp;\\frac{\\partial}{\\partial x}g(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp; \\left(\\cos(\\theta)\\frac{\\partial}{\\partial r} - \\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta} \\right) \\left(\\cos(\\theta) \\frac{\\partial}{\\partial r} - \\frac{\\sin(\\theta)}{r}\\frac{\\partial }{\\partial \\theta} \\right)f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp; \\cos(\\theta)\\frac{\\partial}{\\partial r} \\left(\\cos(\\theta)\\frac{\\partial }{\\partial r}f(x(r,\\theta),y(r,\\theta)) \\right)+\\cos(\\theta)\\frac{\\partial}{\\partial r} \\left(-\\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)) \\right)\\\\[0.5em] &amp;-\\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta} \\left(\\cos(\\theta)\\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta)) \\right) - \\frac{\\sin(\\theta)}{r}\\frac{\\partial}{\\partial \\theta} \\left(-\\frac{\\sin(\\theta)}{r} \\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)) \\right) \\end{align*}\\] which, given our assumptions, reduces to \\[\\begin{align*} \\cos^{2}(\\theta) \\frac{\\partial^2}{\\partial r^2}f(x(r,\\theta),y(r,\\theta)) &amp;+ \\frac{\\sin^{2}(\\theta)}{r^2}\\frac{\\partial^2}{\\partial\\theta^2}f(x(r,\\theta),y(r,\\theta))-\\frac{2\\sin(\\theta)\\cos(\\theta)}r\\frac{\\partial^2}{\\partial r\\partial\\theta}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;+\\frac{\\sin^{2}(\\theta)}r\\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta)) + \\frac{2\\sin(\\theta)\\cos(\\theta)}{r^2}\\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)). \\end{align*}\\] Solution (part b). By the chain rule and utilising the above tree diagram preceding Part a., we have that \\[\\begin{align} \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial r} \\frac{\\partial r}{\\partial x} + \\frac{\\partial f}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial x}. \\tag{3.18} \\end{align}\\] The variables \\(x\\) and \\(y\\) are independent of each other, and the variables \\(r\\) and \\(\\theta\\) are independent of each other, but both \\(r\\) and \\(\\theta\\) are functions of \\(x\\) and \\(y\\), and vice versa. Noting that \\(r^{2}(x,y) = x^{2} + y^{2}\\) and \\(\\tan(\\theta(x,y)) = y/x\\), and differentiating implicitly with respect to \\(y\\) yields \\[\\begin{align*} \\frac{\\partial}{\\partial y}r(x,y) = y/ r(x,y) = \\sin(\\theta(x,y)) \\qquad \\text{and} \\qquad \\sec^{2}(\\theta(x,y)) \\frac{\\partial}{\\partial y}\\theta(x,y) = \\frac{1}{x}. \\end{align*}\\] Since, \\(\\sec^{2}(\\theta(x,y)) = 1 + \\tan^{2}(\\theta(x,y)) = 1 + (y/x)^{2} = (y^{2} + x^{2})/x^{2}\\), it follows that \\[\\begin{align*} \\frac{\\partial}{\\partial y}\\theta(x,y) = \\frac{x}{x^{2}+y^{2}} = \\frac{\\cos(\\theta(x,y))}{r(x,y)}. \\end{align*}\\] Substituting these values into (3.18) yields. \\[\\begin{align*} \\frac{\\partial}{\\partial y} f(x(r,\\theta),y(r,\\theta)) = \\sin(\\theta) \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta)) + \\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial\\theta}f(x(r,\\theta),y(r,\\theta)). \\end{align*}\\] Note, given the domain of \\(f\\), we have that neither \\(r = 0\\) nor \\(x = 0\\). Now, viewing \\(\\partial / \\partial y\\) as an operator (function) which acting on functions (when regarded as a function of \\(x\\) and \\(y\\)) whose first order partial derivatives are continuous is the same as the operator \\[\\begin{align*} \\sin(\\theta) \\frac{\\partial}{\\partial r} + \\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial\\theta} \\end{align*}\\] acting on that function (when regarded as a function of \\(r\\) and \\(\\theta\\)) whose first order partial derivatives are continuous. Hence, setting \\[\\begin{align*} h(x, y) = \\frac{\\partial}{\\partial y}f(x, y), \\end{align*}\\] we have that \\[\\begin{align*} \\frac{\\partial^2}{\\partial y^2}f(x(r,\\theta),y(r,\\theta)) =&amp; \\frac{\\partial}{\\partial y} \\frac{\\partial}{\\partial y} f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp; \\frac{\\partial}{\\partial x}h(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp; \\left(\\sin(\\theta) \\frac{\\partial}{\\partial r} + \\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial\\theta} \\right) \\left(\\sin(\\theta) \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta))+ \\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta))\\right)\\\\[0.5em] =&amp; \\sin(\\theta) \\frac{\\partial}{\\partial r} \\left( \\sin(\\theta) \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta))\\right) + \\sin(\\theta) \\frac{\\partial}{\\partial r} \\left(\\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)) \\right)\\\\[0.5em] &amp;+ \\frac{\\cos(\\theta)}{r}\\frac{\\partial}{\\partial\\theta} \\left( \\sin(\\theta) \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta)) \\right) + \\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial \\theta} \\left(\\frac{\\cos(\\theta)}{r} \\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta))\\right)\\\\[0.5em] =&amp; \\sin^{2}(\\theta) \\frac{\\partial^{2}}{\\partial r^{2}}f(x(r,\\theta),y(r,\\theta)) -\\frac{\\sin(\\theta)\\cos(\\theta)}{r^{2}}\\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;+ \\frac{\\sin(\\theta)\\cos(\\theta)}{r} \\frac{\\partial^{2}}{\\partial r \\partial \\theta}f(x(r,\\theta),y(r,\\theta)) + \\frac{\\cos^{2}(\\theta)}{r} \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;+ \\frac{\\cos(\\theta)\\sin(\\theta)}{r}\\frac{\\partial^{2}}{\\partial \\theta \\partial r}f(x(r,\\theta),y(r,\\theta)) - \\frac{\\cos(\\theta)\\sin(\\theta)}{r^{2}}\\frac{\\partial}{\\partial\\theta}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;+ \\frac{\\cos^2(\\theta)}{r^{2}} \\frac{\\partial^{2}}{\\partial \\theta^{2}}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] =&amp; \\sin^{2}(\\theta) \\frac{\\partial^{2}}{\\partial r^{2}}f(x(r,\\theta),y(r,\\theta)) + \\frac{\\cos^{2}(\\theta)}{r^{2}} \\frac{\\partial^{2}}{\\partial \\theta^{2}}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;+ \\frac{2\\cos(\\theta)\\sin(\\theta)}{r} \\frac{\\partial^{2}}{\\partial r \\partial\\theta}f(x(r,\\theta),y(r,\\theta)) + \\frac{\\cos^{2}(\\theta)}{r} \\frac{\\partial}{\\partial r}f(x(r,\\theta),y(r,\\theta))\\\\[0.5em] &amp;- \\frac{2\\cos(\\theta)\\sin(\\theta)}{r^{2}}\\frac{\\partial}{\\partial \\theta}f(x(r,\\theta),y(r,\\theta)). \\end{align*}\\] Solution (part c). Combing Parts a. and b. we obtain that \\[\\begin{align*} \\Delta = \\frac{\\partial^{2}}{\\partial x^{2}}+\\frac{\\partial^{2}}{\\partial y^{2}} = \\frac{\\partial^{2}}{\\partial r^{2}}+\\frac{1}{r^{2}}\\frac{\\partial^{2}}{\\partial \\theta^{2}}+\\frac{1}{r} \\frac{\\partial f}{\\partial r}. \\end{align*}\\] Exercise 3.16 For each of the following functions compute \\(\\nabla f\\) and the directional derivative in the direction of the given vector \\(\\mathbf{u}\\). For the purposes of this question, you may assume the directional derivative exists. The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y) = y\\sin(x)\\) The vector \\(\\mathbf{u} = 2\\mathbf{i} - \\mathbf{j}\\) The function \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) given by \\(f(x,y,z) = x\\mathrm{e}^{yz}\\) The vector \\(\\mathbf{u} = \\mathbf{i} - \\mathbf{j} + 3\\mathbf{k}\\) The function \\(f \\, \\colon \\, \\mathbb{R}^{2} \\to \\mathbb{R}\\) given by \\(f(x,y) = x^{2}y + y^{3}x\\) The vector \\(\\mathbf{u} = \\langle 3,4 \\rangle\\) Exercise 3.17 Let \\(f \\, \\colon \\, \\mathbb{R}^{3} \\to \\mathbb{R}\\) be given by \\(f(x,y,z)=(y^{2}+\\sin(z))e^{-x}\\). Calculate the directional derivative of \\(f\\) at \\((1,2,\\pi/2)\\) in the direction of \\(\\mathbf{u}\\), where \\(\\mathbf{u}\\) is the vector with initial point \\((1,2,\\pi/2)\\) and terminal point \\((1,1,1)\\) . For the purposes of this question, you may assume the directional derivative exists. Show/hide solution Solution. A vector pointing towards \\((1,1,1)\\) from \\((1,2,\\pi/2)\\) is \\[\\begin{align*} \\mathbf{u} = (1-1)\\mathbf{i}+(1-2)\\mathbf{j}+(1-\\pi/2)\\mathbf{k}=-\\mathbf{j}+(1-\\pi/2)\\mathbf{k}. \\end{align*}\\] Hence, the unit vector in the direction of \\(\\mathbf{u}\\), is given by \\[\\begin{align*} \\hat{\\mathbf{u}} = \\frac{\\mathbf{u}}{\\lvert \\mathbf{u} \\rvert} =\\frac{-\\mathbf{j}+(1-\\pi/2)\\mathbf{k}}{\\sqrt{(\\pi^2/4-\\pi+2)}}. \\end{align*}\\] Since, \\[\\begin{align*} \\nabla f(x,y,z)=-(y^2+\\sin(z))e^{-x}\\mathbf{i}+2ye^{-x}\\mathbf{j}+\\cos(z)e^{-x}\\mathbf{k}, \\end{align*}\\] we have that \\(\\nabla f(1,2,\\pi/2)=-5e^{-1}\\mathbf{i}+4e^{-1}\\mathbf{j}\\) and hence, by Corollary 3.3 and the the hypotheses of the question, the directional derivative of \\(f\\) at \\((1,2,\\pi/2)\\) in the direction of \\(\\mathbf{u}\\) is given by \\[\\begin{align*} D_{\\hat{\\mathbf{u}}}(1,2,\\pi/2) =\\nabla f(1,2,\\pi/2)\\cdot\\hat{\\mathbf{u}} =\\frac{-4 e^{-1}}{\\sqrt{\\pi^2/4-\\pi+2}}. \\end{align*}\\] Exercise 3.18 The voltage \\(V\\) on a sheet of semi-conductor lying in the \\(x\\)-\\(y\\) plane is given by \\(V=(x+1)^2+e^{-xy}\\), for \\((x, y) \\in \\mathbb{R}^{2}\\). Here we view \\(V\\) as a dependent variable, and \\(x\\) and \\(y\\) as independent variables. In what direction does the voltage change most rapidly at the origin and what is the rate of change in that direction? For a fixed \\(k \\in \\mathbb{R}\\), what is the rate of change of \\(V\\) in the direction of the positive \\(x\\)-axis at the point \\((k,0)\\)? For the purposes of this question, you may assume \\(V\\) is differentiable. Exercise 3.19 Find the equations of the tangent planes to the given surface \\(S\\) at the given points \\(p\\). The surface \\(S\\) consisting of the the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\(4z = x^2+4y^2\\) and the point \\(p = (2, 1, 2)\\) The surface \\(S\\) consisting of the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\(xy^2+3x-z^2 = 4\\) at the point \\(p = (2,1,-2)\\) The surface \\(S\\) consisting of the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\(z = \\mathrm{e}^{xy^2}\\) at the point \\(p = (1,1,\\mathrm{e}^{1})\\) Remember in this question, the first step is to check that the point \\(p\\) lies on the given surface \\(S\\), if it does not, then no tangent plane exists. Show/hide solution Solution (part a). Let \\(f \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) denote the function \\(f(x,y,z)=x^2+4y^2-4z\\), so that the given surface \\(S\\) is the level surface of \\(f\\) at height zero. Further, we observe that \\(f(p)=f(2,1,1)=2^2+4\\cdot1^2-4\\cdot1=0\\) and so \\(p\\in S\\). Noting that, \\[\\begin{align*} \\nabla f(x,y,z) = \\frac{\\partial}{\\partial x}f(x,y,z)\\mathbf{i} + \\frac{\\partial}{\\partial y}f(x,y,z)\\mathbf{j} + \\frac{\\partial}{\\partial z}f(x,y,z)\\mathbf{k} = 2x\\mathbf{i} + 8y\\mathbf{j} - 4\\mathbf{k}, \\end{align*}\\] we have that \\[\\begin{align*} \\nabla f(2,1,2) = 4\\mathbf{i} + 8\\mathbf{j} - 4\\mathbf{k}. \\end{align*}\\] Hence, by (3.15), the tangent plane to the given surface \\(S\\) at the point \\((2,1,2)\\) has the vector equation \\[\\begin{align*} \\langle x, y, z \\rangle \\cdot \\langle 4, 8, -4 \\rangle = \\langle 2,1,2 \\rangle \\cdot \\langle 4, 8, -4 \\rangle, \\end{align*}\\] which yields that \\[\\begin{align*} 4x + 8y - 4z = 8 + 8 - 8, \\end{align*}\\] or equivalently, \\[\\begin{align*} x + 2y - z = 2. \\end{align*}\\] Solution (part b). Let \\(f \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) denote the function \\(f(x,y,z) = xy^2+3x-z^2-4\\), so that the given surface \\(S\\) is the level surface of \\(f\\) at height zero. Further, we observe that \\(f(p)=f(2,1,-2)=2\\cdot 1^{2}+3\\cdot 2-(-2)^{2}-4 =0\\) and so \\(p\\in S\\). Noting that, \\[\\begin{align*} \\nabla f(x,y,z) = \\frac{\\partial}{\\partial x}f(x,y,z)\\mathbf{i} + \\frac{\\partial}{\\partial y}f(x,y,z)\\mathbf{j} + \\frac{\\partial}{\\partial z}f(x,y,z)\\mathbf{k} = (y^{2} + 3)\\mathbf{i} + 2xy\\mathbf{j} - 2z\\mathbf{k}, \\end{align*}\\] we have that \\[\\begin{align*} \\nabla f(2,1,-2) = 4\\mathbf{i} + 4\\mathbf{j} + 4\\mathbf{k}. \\end{align*}\\] Hence, by (3.15), the tangent plane to the given surface \\(S\\) at the point \\((2, 1, -2)\\) has the vector equation \\[\\begin{align*} \\langle x, y, z \\rangle \\cdot \\langle 4, 4, 4 \\rangle = \\langle 2, 1, -2 \\rangle \\cdot \\langle 4, 4, 4 \\rangle, \\end{align*}\\] which yields that \\[\\begin{align*} 4x + 4y + 4z = 8 + 4 - 8, \\end{align*}\\] or equivalently, \\[\\begin{align*} x + y + z = 1. \\end{align*}\\] Solution (part c). Let \\(f \\colon \\mathbb{R}^{3} \\to \\mathbb{R}\\) denote the function \\(f(x,y,z) = \\mathrm{e}^{xy^2} - z\\), so that the given surface \\(S\\) is the level surface of \\(f\\) at height zero. Further, we observe that \\(f(p)=f(1,1,\\mathrm{e}^{1})=\\mathrm{e}^{1\\cdot 1^{2}}-\\mathrm{e}^{1}=0\\) and so \\(p\\in S\\). Noting that, \\[\\begin{align*} \\nabla f(x,y,z) = \\frac{\\partial}{\\partial x}f(x,y,z)\\mathbf{i} + \\frac{\\partial}{\\partial y}f(x,y,z)\\mathbf{j} + \\frac{\\partial}{\\partial z}f(x,y,z)\\mathbf{k} = y^{2} \\mathrm{e}^{xy^{2}}\\mathbf{i} + 2xy\\mathrm{e}^{xy^{2}}\\mathbf{j} - \\mathbf{k}, \\end{align*}\\] we have that \\[\\begin{align*} \\nabla f(1,1,\\mathrm{e}^{1}) = \\mathrm{e}^{1}\\mathbf{i} + 2\\mathrm{e}^{1}\\mathbf{j} - \\mathbf{k}. \\end{align*}\\] Hence, by (3.15), the tangent plane to the given surface \\(S\\) at the point \\((1,1,\\mathrm{e}^{1})\\) has the vector equation \\[\\begin{align*} \\langle x,y,z \\rangle \\cdot \\langle \\mathrm{e}^{1},2\\mathrm{e}^{1},-1 \\rangle = \\langle 1,1,\\mathrm{e}^{1} \\rangle \\cdot \\langle \\mathrm{e}^{1},2\\mathrm{e}^{1},-1 \\rangle \\end{align*}\\] which yields that \\[\\begin{align*} x\\mathrm{e}^{1} + 2y\\mathrm{e}^{1} - z = \\mathrm{e}^{1} + 2\\mathrm{e}^{1} - \\mathrm{e}^{1}, \\end{align*}\\] or equivalently, \\[\\begin{align*} x\\mathrm{e}^{1}+2y\\mathrm{e}^{1}-z=2\\mathrm{e}^{1}. \\end{align*}\\] Exercise 3.20 Let \\(a \\in \\mathbb{R}^{+}\\) be fixed and fix \\((r, s, t) \\in \\mathbb{R}^{3}\\) such that \\(rst = a^{3}\\). Let \\(S\\) denote the surface consisting of the set of points \\((x, y, z) \\in \\mathbb{R}^{3}\\) satisfying \\(xyz = a^3\\), and let \\(P = P_{r, s, t}\\) be the plane tangent to \\(S\\) at the point \\((r, s, t)\\). Find a Cartesian equation which describes \\(P\\). Let \\(T\\) be the tetrahedron formed by the coordinate planes and the tangent plane \\(P\\). Show that the volume of \\(T\\) is independent of the point \\((r,s,t)\\). Recall that the volume of a tetrahedron is \\((\\text{area of base}\\times\\text{height})/3\\). "],["references.html", "References", " References "]]
